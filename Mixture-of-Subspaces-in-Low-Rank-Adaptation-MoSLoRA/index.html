<!DOCTYPE html>



<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Chen Kai">
    
    <title>
        
            Mixture-of-Subspaces in Low-Rank Adaptation (MoSLoRA) |
        
        Chen Kai Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/logo.svg">
    
<link rel="stylesheet" href="/css/font-awesome.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"chenk.top","root":"/","language":"zh-CN","default_language":"zh-CN","languages":["zh-CN","en"],"path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":true},"style":{"primary_color":"#0066CC","avatar":"/images/avatar.svg","favicon":"/images/logo.svg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":false,"scale":false},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"Keep writing and Keep loving."},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":true,"style":"default"},"pjax":{"enable":true},"lazyload":{"enable":false},"version":"3.4.5"};
    KEEP.language_ago = {"second":"%s 秒前","minute":"%s 分钟前","hour":"%s 小时前","day":"%s 天前","week":"%s 周前","month":"%s 个月前","year":"%s 年前"};
  </script>
<meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Chen Kai Blog" type="application/atom+xml">
<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    
    
    
    
    

    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                Chen Kai Blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/"
                            >
                                首页
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/archives"
                            >
                                归档
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/categories"
                            >
                                分类
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/tags"
                            >
                                标签
                            </a>
                        </li>
                    
                    <li class="menu-item lang-switch lang-switch-trigger" title="Language">
                        <i class="fas fa-globe"></i>
                    </li>
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item lang-switch-trigger"><i class="fas fa-globe"></i></div>
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/">首页</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/archives">归档</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/categories">分类</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/tags">标签</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    
    
    
    

    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">Mixture-of-Subspaces in Low-Rank Adaptation (MoSLoRA)</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/avatar.svg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Chen Kai</span>
                        
                            <span class="author-label">BOSS</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    
    
    
    
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;
        <span class="pc">2024-10-01 00:00:00</span>
        <span class="mobile">2024-10-01 00:00</span>
    </span>
    
        <span class="article-categories article-meta-item">
            <i class="fas fa-folder"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/categories/Paper/">Paper</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/PEFT/">PEFT</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fas fa-file-word"></i>&nbsp;<span>3.1k 字</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fas fa-clock"></i>&nbsp;<span>11 分钟</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <p>LoRA
把“全量微调”压缩成一个低秩更新，但它也引入了一个直觉上的限制：单个低秩子空间未必足以覆盖任务所需的多样变化；而
MoE
虽然能增加容量，却常带来路由开销、训练不充分与推理不可合并等工程代价。MoSLoRA
的思路更像是把“多专家”做成“多子空间”：把 LoRA
的更新拆成多个小子空间，再用一个可学习的 Mixer
在这些子空间之间做融合，从而在几乎不增加推理复杂度的前提下提升表达能力，并尽量保留
LoRA
的可合并性。下面我会按“动机—结构—训练/推理行为—实验结论”的顺序拆解这篇工作，重点看它的
Mixer 设计到底带来了哪些收益，以及它与 LoRA/MoE 的边界在哪里。</p>
<span id="more"></span>
<h1 id="背景介绍">背景介绍</h1>
<p><strong>LoRA方法简介：</strong> LoRA（Low-Rank
Adaptation）是一种用于大型语言模型的参数高效微调方法，其核心思想是通过添加低秩分支（由两个低秩矩阵组成）来近似权重的更新，从而显著减少需要微调的参数数量。Hu等人
(2022)
的研究表明，LoRA在不影响模型性能的前提下，将参数更新的数量从全连接层的
<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="7.094ex" height="1.91ex" role="img" focusable="false" viewbox="0 -694 3135.6 844"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></g><g data-mml-node="mn" transform="translate(553,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g></g><g data-mml-node="mo" transform="translate(1178.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"/></g><g data-mml-node="msub" transform="translate(2179,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></g><g data-mml-node="mn" transform="translate(553,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"/></g></g></g></g></svg></mjx-container></span> 降低到 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="9.875ex" height="2.262ex" role="img" focusable="false" viewbox="0 -750 4364.6 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></g><g data-mml-node="mn" transform="translate(553,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g></g><g data-mml-node="mo" transform="translate(1567.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"/></g><g data-mml-node="msub" transform="translate(2568,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></g><g data-mml-node="mn" transform="translate(553,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"/></g></g><g data-mml-node="mo" transform="translate(3524.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g><g data-mml-node="mi" transform="translate(3913.6,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g></g></g></svg></mjx-container></span>，其中 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.02ex" height="1.025ex" role="img" focusable="false" viewbox="0 -442 451 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g></g></g></svg></mjx-container></span> 是低秩矩阵的秩，通常远小于<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.164ex" height="1.91ex" role="img" focusable="false" viewbox="0 -694 956.6 844"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></g><g data-mml-node="mn" transform="translate(553,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g></g></g></g></svg></mjx-container></span> 和 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.164ex" height="1.91ex" role="img" focusable="false" viewbox="0 -694 956.6 844"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></g><g data-mml-node="mn" transform="translate(553,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"/></g></g></g></g></svg></mjx-container></span>。</p>
<p><strong>MoE方法简介：</strong> Mixture-of-Experts (MoE)
是一种通过引入多个专家模型，并通过一个门控机制 (gate router)
来动态选择部分专家参与计算的方法。MoE的设计目标是在增加模型容量的同时，保持计算效率。通常情况下，MoE的gate
router会根据输入生成专家的选择权重，选取Top-K个专家参与计算，从而在不显著增加计算开销的前提下提升模型的性能
(Fedus et al., 2022a)。</p>
<p><strong>研究动机：</strong>
早期的研究尝试将LoRA与MoE结合，但这些尝试通常是将LoRA作为MoE的专家模块，嵌入到MoE结构中。这样的设计有几个问题：</p>
<ol type="1">
<li><strong>缺乏理论动机</strong>：直接将LoRA作为专家模块并没有明确的理论支持，缺少对两种方法结合后新特性的分析。</li>
<li><strong>影响LoRA的可合并性</strong>：由于MoE的gate
router引入了选择机制，使得这些LoRA模块在推理阶段无法合并回原始权重中，增加了推理延迟。</li>
<li><strong>训练效率低</strong>：MoE的选择机制导致部分参数得不到充分训练，影响了整体效率。</li>
</ol>
<p>为了解决这些问题，作者提出了反其道而行之的设计思路，即将MoE的思想融入到LoRA中，而不是将LoRA作为MoE的组件。</p>
<p><img src="https://pic.imgdb.cn/item/66d9e3dcd9c307b7e931ffde.jpg"></p>
<h1 id="具体细节">具体细节</h1>
<p>MoSLoRA的核心思想是通过引入一个可学习的Mixer矩阵来融合多个子空间，而不是采用MoE的gate机制来选择专家。具体来说，MoSLoRA将LoRA中的低秩矩阵进一步分解为多个子空间，并通过一个可学习的矩阵来对这些子空间进行加权组合。这样一来，每个子空间的输出都参与了最终的结果计算，既避免了传统MoE选择机制带来的推理延迟问题，又充分利用了LoRA的低秩优势。</p>
<ol type="1">
<li><strong>去掉Gate机制</strong>： MoE的gate
router机制虽然能够选择部分专家进行计算，但在LoRA的框架下并不适用。原因是LoRA的核心优势在于其低秩结构能够实现参数高效的模型微调，而引入gate机制会破坏这一优势。因此，MoSLoRA选择去掉gate机制，直接在所有子空间上进行加权求和，确保所有子空间的输出都能被利用。</li>
<li><strong>引入可学习的Mixer矩阵</strong>：
为了更灵活地融合子空间信息，MoSLoRA引入了一个可学习的Mixer矩阵，而不是固定的组合权重。这样做的好处是，模型可以在训练过程中学习到最佳的子空间组合方式，从而提升模型的适应能力和表现力。</li>
<li><strong>子空间的多样性与组合</strong>： 在传统的LoRA中，低秩矩阵的秩
<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.02ex" height="1.025ex" role="img" focusable="false" viewbox="0 -442 451 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g></g></g></svg></mjx-container></span>
通常较小，为了进一步提升模型的表示能力，MoSLoRA将低秩矩阵分解为多个子空间，每个子空间的秩更小（例如，将一个秩为
<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.02ex" height="1.025ex" role="img" focusable="false" viewbox="0 -442 451 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g></g></g></svg></mjx-container></span> 的矩阵分解为两个秩为 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="3.283ex" height="2.262ex" role="img" focusable="false" viewbox="0 -750 1451 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(451,0)"><g data-mml-node="mo"><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"/></g></g><g data-mml-node="mn" transform="translate(951,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"/></g></g></g></svg></mjx-container></span>
的子矩阵）。这种分解方式类似于多头注意力机制中的多头结构，通过并行处理不同的子空间并在最终阶段进行组合，能够更好地捕捉数据中的多样性信息。</li>
<li><strong>实验与性能</strong>：
作者在多种下游任务（如常识推理、视觉指令调优、图像生成等）上对MoSLoRA进行了实验验证，结果表明，与传统的LoRA和其他PEFT方法相比，MoSLoRA在多个基准上均取得了更好的性能，特别是在细粒度子空间视角下，其能够更灵活地融合信息，提升模型的复杂信息建模能力。</li>
</ol>
<p><img src="https://pic.imgdb.cn/item/66d9e3dcd9c307b7e931ff5e.jpg"></p>
<h1 id="代码实现">代码实现</h1>
<p>为了在实践中实现MoSLoRA，首先需要对标准的LoRA方法进行扩展，将其权重矩阵的低秩分解替换为多个子空间的组合。以下是实现MoSLoRA的一些关键步骤和代码片段。</p>
<ol type="1">
<li><p><strong>定义子空间</strong>：我们首先将LoRA中的权重矩阵分解为多个子空间矩阵，这些子空间的秩通常更小。例如，将一个原始的低秩矩阵分解为两个更小的低秩子空间。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LoRABase</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, original_matrix, rank=<span class="number">4</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(LoRABase, self).__init__()</span><br><span class="line">        self.rank = rank</span><br><span class="line">        self.low_rank_A = nn.Parameter(torch.randn(original_matrix.size(<span class="number">0</span>), rank))</span><br><span class="line">        self.low_rank_B = nn.Parameter(torch.randn(rank, original_matrix.size(<span class="number">1</span>)))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> x @ self.low_rank_A @ self.low_rank_B</span><br></pre></td></tr></table></figure></li>
<li><p><strong>引入可学习的Mixer矩阵</strong>：接下来，我们定义一个可学习的Mixer矩阵，用于对各子空间的输出进行加权组合。这个矩阵的大小取决于子空间的数量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MoSLoRA</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, original_matrix, num_subspaces=<span class="number">2</span>, rank=<span class="number">4</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(MoSLoRA, self).__init__()</span><br><span class="line">        self.subspaces = nn.ModuleList([LoRABase(original_matrix, rank=rank//num_subspaces) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_subspaces)])</span><br><span class="line">        self.mixer = nn.Parameter(torch.randn(num_subspaces, <span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        outputs = [subspace(x) <span class="keyword">for</span> subspace <span class="keyword">in</span> self.subspaces]</span><br><span class="line">        weighted_outputs = [output * self.mixer[i] <span class="keyword">for</span> i, output <span class="keyword">in</span> <span class="built_in">enumerate</span>(outputs)]</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(weighted_outputs)</span><br></pre></td></tr></table></figure></li>
<li><p><strong>训练和推理</strong>：在训练过程中，模型会学习最佳的Mixer矩阵参数，以优化子空间的组合权重。在推理过程中，我们可以直接使用学习到的Mixer矩阵来组合子空间的输出，从而得到最终的结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">original_matrix = torch.randn(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line">model = MoSLoRA(original_matrix, num_subspaces=<span class="number">2</span>, rank=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    output = model(input_data)</span><br><span class="line">    loss = criterion(output, target_data)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure></li>
</ol>
<p>以上代码演示了MoSLoRA的基本实现流程。通过这种方式，我们可以将原始LoRA的低秩矩阵分解为多个子空间，并通过可学习的Mixer矩阵进行优化组合。</p>
<h1 id="基于场景的创新">基于场景的创新</h1>
<h2 id="多模态任务">多模态任务</h2>
<p>在处理多模态任务时，MoSLoRA的子空间组合机制确实具有优势。不同模态的数据（如文本、图像、视频等）通常有不同的特征空间，传统方法需要单独微调每个模态的模型或者使用巨大的联合模型来处理所有模态。而MoSLoRA通过引入多个子空间并使用可学习的Mixer矩阵对这些子空间进行加权组合，可以更灵活地适应多模态数据。这种方法可以通过以下步骤实现：</p>
<ol type="1">
<li><strong>定义子空间</strong>：针对每种模态的数据特征，定义不同的子空间。例如，文本数据可以使用一个低秩子空间，图像数据使用另一个子空间。</li>
<li><strong>训练子空间</strong>：使用各自模态的数据分别训练这些子空间。在此阶段，可以选择只训练与当前模态相关的参数，而冻结其他模态的参数，减少训练时间和资源消耗。</li>
<li><strong>融合子空间</strong>：引入可学习的Mixer矩阵，动态调整各子空间的权重，使得模型能够根据任务需求和输入数据的模态类型，优化不同子空间的组合方式。</li>
<li><strong>推理阶段</strong>：在推理阶段，使用训练好的Mixer矩阵，根据输入数据的模态类型，自动调整各子空间的权重，进行推理计算。</li>
</ol>
<h2 id="领域适应">领域适应</h2>
<p>在跨领域任务中，MoSLoRA的多子空间策略同样适用，因为它允许为不同领域定制专门的子空间，并通过训练学习最佳组合方式。例如，在金融和医疗两个完全不同的领域，可以设置两个独立的子空间，一个针对金融数据优化，另一个针对医疗数据优化。MoSLoRA在训练过程中会学习如何最优地融合这些子空间，以便在混合数据集或跨领域应用中取得最佳效果。</p>
<ol type="1">
<li><strong>数据预处理</strong>：将数据划分为不同领域，并根据领域特征对数据进行标准化和处理。</li>
<li><strong>子空间构建</strong>：为每个领域创建单独的子空间，并初始化这些子空间的参数。</li>
<li><strong>联合训练</strong>：在训练时，使用每个领域的训练数据，分别优化其相关的子空间，同时训练可学习的Mixer矩阵，使得各子空间在联合任务中的表现得到优化。</li>
<li><strong>适应性调整</strong>：通过训练过程中的损失函数和性能指标反馈，动态调整各子空间的权重和Mixer矩阵的参数。</li>
</ol>
<h2 id="个性化推荐系统">个性化推荐系统</h2>
<p>对于个性化推荐系统，MoSLoRA可以利用其子空间来捕获不同用户的偏好。通过多个子空间表示用户的不同行为模式，并在推理阶段根据用户的历史行为动态调整Mixer矩阵的权重，可以更精确地生成个性化推荐。</p>
<ol type="1">
<li><strong>用户行为建模</strong>：收集用户的历史行为数据，如浏览记录、点击记录、购买记录等。</li>
<li><strong>子空间学习</strong>：根据不同的用户行为模式，定义多个子空间，并分别训练这些子空间以捕获特定的行为特征。</li>
<li><strong>动态Mixer矩阵</strong>：在推理阶段，使用用户的历史行为数据，动态调整Mixer矩阵的权重，使得推荐模型能够根据当前用户的偏好，选择合适的子空间组合进行推理。</li>
<li><strong>实时推荐</strong>：在推理时，通过动态调整的Mixer矩阵生成个性化推荐列表，提高推荐的相关性和用户满意度。</li>
</ol>
<h2 id="实现方案与潜在问题">实现方案与潜在问题</h2>
<p><strong>实现方案</strong>：基于上述不同的场景，MoSLoRA的实现需要针对特定任务进行细致的配置和优化。首先，需要确定适合的子空间数量和类型，其次是选择合适的初始化策略（如使用Kaiming初始化来提高模型收敛速度），最后是动态调整Mixer矩阵的训练策略（可以采用Adam或RMSprop等优化算法）。</p>
<p><strong>潜在问题</strong>：在实际应用中，可能会面临以下几个问题：</p>
<ul>
<li><strong>模型复杂性增加</strong>：引入多个子空间和Mixer矩阵会增加模型的复杂性，可能导致训练时间延长和内存消耗增加。</li>
<li><strong>子空间选择困难</strong>：需要精心选择子空间的数量和类型，以确保它们能够有效地捕获数据特征。</li>
<li><strong>融合策略优化</strong>：如何有效地训练和优化Mixer矩阵，以实现最佳的子空间组合，也是一个挑战。</li>
</ul>
<p>针对这些问题，可以通过以下方式解决：</p>
<ul>
<li><strong>模型压缩技术</strong>：使用模型压缩技术，如剪枝和量化，减少模型参数量。</li>
<li><strong>自动化子空间选择</strong>：利用自动化机器学习技术（如AutoML），帮助选择最佳的子空间数量和类型。</li>
<li><strong>优化算法调整</strong>：尝试不同的优化算法和学习率策略，寻找最适合的训练设置。</li>
</ul>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    
    
    
    
    
    
    <ul>
        <li>本文标题：Mixture-of-Subspaces in Low-Rank Adaptation (MoSLoRA)</li>
        <li>本文作者：Chen Kai</li>
        <li>创建时间：2024-10-01 00:00:00</li>
        <li>
            本文链接：https://www.chenk.top/Mixture-of-Subspaces-in-Low-Rank-Adaptation-MoSLoRA/
        </li>
        <li>
            版权声明：本博客所有文章除特别声明外，均采用 <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> 许可协议。转载请注明出处！
        </li>
    </ul>
</div>

            </div>
        

        
            <ul class="post-tags-box">
                
                    <li class="tag-item">
                        <a href="/tags/PEFT/">#PEFT</a>&nbsp;
                    </li>
                
            </ul>
        

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/Solving-Constrained-Mean-Variance-Portfolio-Optimization-Problems-Using-Spiral-Optimization-Algorithm/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Solving Constrained Mean-Variance Portfolio Optimization Problems Using Spiral Optimization Algorithm</span>
                                <span class="post-nav-item">上一篇</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/Prefix-Tuning-Optimizing-Continuous-Prompts-for-Generation/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Prefix Tuning —— Optimizing Continuous Prompts for Generation</span>
                                <span class="post-nav-item">下一篇</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
            <div class="comment-container">
                <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fas fa-comments">&nbsp;评论</i>
    </div>
    

        
            
    <div class="valine-container">
        <script data-pjax
                src="//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script>
        <div id="vcomments"></div>
        <script data-pjax>
            function loadValine() {
                new Valine({
                    el: '#vcomments',
                    appId: 'p2Cu9MgjoKzo3VmulhNLIusH-gzGzoHsz',
                    appKey: 'QThQHg3c8sVwGpzg9lu8zEG3',
                    meta: ['nick', 'mail', 'link'],
                    avatar: 'wavatar',
                    enableQQ: true,
                    placeholder: '😜 尽情赞美帅气伟大的ck吧~',
                    lang: 'zh-CN'.toLowerCase()
                });

                function getAuthor(language) {
                    switch (language) {
                        case 'en':
                            return 'Author';
                        case 'zh-CN':
                            return '博主';
                        default:
                            return 'Master';
                    }
                }

                // Add "Author" identify
                const getValineDomTimer = setInterval(() => {
                    const vcards = document.querySelectorAll('#vcomments .vcards .vcard');
                    if (vcards.length > 0) {
                        let author = 'Chen Kai';

                        if (author) {
                            for (let vcard of vcards) {
                                const vnick_dom = vcard.querySelector('.vhead .vnick');
                                const vnick = vnick_dom.innerHTML;
                                if (vnick === author) {
                                    vnick_dom.innerHTML = `${vnick} <span class="author">${getAuthor(KEEP.hexo_config.language)}</span>`
                                }
                            }
                        }
                        clearInterval(getValineDomTimer);
                    } else {
                        clearInterval(getValineDomTimer);
                    }
                }, 2000);
            }

            if ('true') {
                const loadValineTimeout = setTimeout(() => {
                    loadValine();
                    clearTimeout(loadValineTimeout);
                }, 1000);
            } else {
                window.addEventListener('DOMContentLoaded', loadValine);
            }
        </script>
    </div>



        
    
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2020</span>
              -
            
            2026&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Chen Kai</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        访问人数&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
            </div>
        
        <div class="theme-info info-item">
            <!-- 由 <a target="_blank" href="https://hexo.io">Hexo</a> 驱动&nbsp;|&nbsp;主题&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.5</a> -->
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fas fa-comment"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        
            <li class="tools-item rss flex-center">
                <a class="flex-center"
                   href="/atom.xml"
                   target="_blank"
                >
                    <i class="fas fa-rss"></i>
                </a>
            </li>
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.</span> <span class="nav-text">背景介绍</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%85%B7%E4%BD%93%E7%BB%86%E8%8A%82"><span class="nav-number">2.</span> <span class="nav-text">具体细节</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="nav-number">3.</span> <span class="nav-text">代码实现</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E5%9C%BA%E6%99%AF%E7%9A%84%E5%88%9B%E6%96%B0"><span class="nav-number">4.</span> <span class="nav-text">基于场景的创新</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1"><span class="nav-number">4.1.</span> <span class="nav-text">多模态任务</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%A2%86%E5%9F%9F%E9%80%82%E5%BA%94"><span class="nav-number">4.2.</span> <span class="nav-text">领域适应</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%AA%E6%80%A7%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F"><span class="nav-number">4.3.</span> <span class="nav-text">个性化推荐系统</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88%E4%B8%8E%E6%BD%9C%E5%9C%A8%E9%97%AE%E9%A2%98"><span class="nav-number">4.4.</span> <span class="nav-text">实现方案与潜在问题</span></a></li></ol></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="搜索..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>

<script src="/js/lang-switch.js"></script>



    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-copy.js"></script>





<div class="post-scripts pjax">
    
        
<script src="/js/left-side-toggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/toc.js"></script>

    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
