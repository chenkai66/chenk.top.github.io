<!DOCTYPE html>



<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Chen Kai">
    
    <title>
        
            Cloud Computing (3): Storage Systems and Distributed Architecture |
        
        Chen Kai Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/logo.svg">
    
<link rel="stylesheet" href="/css/font-awesome.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"chenk.top","root":"/","language":"en","default_language":"zh-CN","languages":["zh-CN","en"],"path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":true},"style":{"primary_color":"#0066CC","avatar":"/images/avatar.svg","favicon":"/images/logo.svg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":false,"scale":false},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"Keep writing and Keep loving."},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":true,"style":"default"},"pjax":{"enable":true},"lazyload":{"enable":false},"version":"3.4.5"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
<meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Chen Kai Blog" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    
    
    
    
    

    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/en/">
                Chen Kai Blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/en/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/en/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/en/categories"
                            >
                                CATEGORIES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/en/tags"
                            >
                                TAGS
                            </a>
                        </li>
                    
                    <li class="menu-item lang-switch lang-switch-trigger" title="Language">
                        <i class="fas fa-globe"></i>
                    </li>
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item lang-switch-trigger"><i class="fas fa-globe"></i></div>
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/en/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/en/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/en/categories">CATEGORIES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/en/tags">TAGS</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    
    
    
    

    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">Cloud Computing (3): Storage Systems and Distributed Architecture</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/avatar.svg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Chen Kai</span>
                        
                            <span class="author-label">BOSS</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    
    
    
    
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;
        <span class="pc">2023-10-27 00:00:00</span>
        <span class="mobile">2023-10-27 00:00</span>
    </span>
    
        <span class="article-categories article-meta-item">
            <i class="fas fa-folder"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/en/categories/Cloud-Computing/">Cloud Computing</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/en/tags/HDFS/">HDFS</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/en/tags/Ceph/">Ceph</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/en/tags/Cloud-Computing/">Cloud Computing</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/en/tags/Distributed-Storage/">Distributed Storage</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/en/tags/Object-Storage/">Object Storage</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fas fa-file-word"></i>&nbsp;<span>9k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fas fa-clock"></i>&nbsp;<span>56 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <p>Modern cloud infrastructure relies on distributed storage systems
that can scale to petabytes, maintain high availability, and provide
consistent performance across global deployments. Understanding how
these systems work—from the theoretical foundations of CAP theorem to
practical implementations like Amazon S3, HDFS, and Ceph—is essential
for architects and engineers building cloud-native applications.</p>
<p>This article explores the fundamental principles, architectural
patterns, and real-world implementations of distributed storage systems.
We'll examine object storage architectures, compare block and file
storage models, dive deep into HDFS and Ceph deployments, and discuss
strategies for consistency, replication, backup, performance
optimization, and cost management.</p>
<span id="more"></span>
<h2 id="distributed-storage-fundamentals">Distributed Storage
Fundamentals</h2>
<h3 id="the-cap-theorem">The CAP Theorem</h3>
<p>The CAP theorem, proposed by Eric Brewer in 2000, states that a
distributed system can guarantee at most two out of three
properties:</p>
<ul>
<li><strong>Consistency</strong>: All nodes see the same data
simultaneously</li>
<li><strong>Availability</strong>: Every request receives a response
(success or failure)</li>
<li><strong>Partition Tolerance</strong>: System continues operating
despite network failures</li>
</ul>
<p>In practice, partition tolerance is non-negotiable for distributed
systems—network partitions will occur. This forces a choice between
consistency and availability.</p>
<p><strong>CP Systems</strong> prioritize consistency over availability.
When a partition occurs, CP systems may refuse requests to maintain data
consistency. Examples include:</p>
<ul>
<li>Traditional relational databases with synchronous replication</li>
<li>HBase (strong consistency model)</li>
<li>MongoDB with majority write concern</li>
</ul>
<p><strong>AP Systems</strong> prioritize availability over strict
consistency. They continue serving requests during partitions,
potentially returning stale data. Examples include:</p>
<ul>
<li>Amazon DynamoDB (eventual consistency)</li>
<li>Cassandra (tunable consistency)</li>
<li>Riak (eventual consistency)</li>
</ul>
<p><strong>CA Systems</strong> are theoretically impossible in
distributed environments but exist in single-node systems or tightly
coupled clusters without network partitions.</p>
<h3 id="base-principles">BASE Principles</h3>
<p>BASE (Basically Available, Soft state, Eventual consistency)
complements ACID properties for distributed systems:</p>
<ul>
<li><strong>Basically Available</strong>: System remains available most
of the time, even during partial failures</li>
<li><strong>Soft State</strong>: System state may change without input
due to eventual consistency</li>
<li><strong>Eventual Consistency</strong>: System will become consistent
over time, given no new updates</li>
</ul>
<p>BASE systems trade immediate consistency for improved availability
and performance, making them ideal for large-scale web applications.</p>
<h3 id="distributed-storage-architecture-patterns">Distributed Storage
Architecture Patterns</h3>
<h4 id="master-slave-architecture">Master-Slave Architecture</h4>
<p>In master-slave (primary-secondary) architectures, one node
coordinates operations while others replicate data:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────┐</span><br><span class="line">│   Master    │ (Coordinates writes, manages metadata)</span><br><span class="line">└──────┬──────┘</span><br><span class="line">       │</span><br><span class="line">   ┌───┴───┬────────┬────────┐</span><br><span class="line">   │       │        │        │</span><br><span class="line">┌──▼──┐ ┌──▼──┐ ┌──▼──┐ ┌──▼──┐</span><br><span class="line">│Slave│ │Slave│ │Slave│ │Slave│ (Store data replicas)</span><br><span class="line">└─────┘ └─────┘ └─────┘ └─────┘</span><br></pre></td></tr></table></figure>
<p><strong>Advantages</strong>:</p>
<ul>
<li>Simple to implement and reason about</li>
<li>Strong consistency possible with synchronous replication</li>
<li>Clear failure semantics</li>
</ul>
<p><strong>Disadvantages</strong>:</p>
<ul>
<li>Master becomes a bottleneck</li>
<li>Single point of failure (requires failover mechanisms)</li>
<li>Limited scalability</li>
</ul>
<h4 id="peer-to-peer-architecture">Peer-to-Peer Architecture</h4>
<p>Peer-to-peer systems distribute coordination across all nodes:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">    ┌─────┐</span><br><span class="line">    │Node1│</span><br><span class="line">    └──┬──┘</span><br><span class="line">       │</span><br><span class="line">   ┌───┴───┬────────┬────────┐</span><br><span class="line">   │       │        │        │</span><br><span class="line">┌──▼──┐ ┌──▼──┐ ┌──▼──┐ ┌──▼──┐</span><br><span class="line">│Node2│ │Node3│ │Node4│ │Node5│</span><br><span class="line">└──┬──┘ └──┬──┘ └──┬──┘ └──┬──┘</span><br><span class="line">   └───────┴────────┴───────┘</span><br></pre></td></tr></table></figure>
<p><strong>Advantages</strong>:</p>
<ul>
<li>No single point of failure</li>
<li>Horizontal scalability</li>
<li>Better fault tolerance</li>
</ul>
<p><strong>Disadvantages</strong>:</p>
<ul>
<li>More complex to implement</li>
<li>Eventual consistency challenges</li>
<li>Conflict resolution required</li>
</ul>
<h4 id="consistent-hashing">Consistent Hashing</h4>
<p>Consistent hashing enables efficient data distribution and minimizes
rebalancing when nodes join or leave:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"><span class="keyword">import</span> bisect</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConsistentHash</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, nodes=<span class="literal">None</span>, replicas=<span class="number">3</span></span>):</span><br><span class="line">        self.replicas = replicas</span><br><span class="line">        self.ring = &#123;&#125;</span><br><span class="line">        self.sorted_keys = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> nodes:</span><br><span class="line">            <span class="keyword">for</span> node <span class="keyword">in</span> nodes:</span><br><span class="line">                self.add_node(node)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_hash</span>(<span class="params">self, key</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Generate hash for a key&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">int</span>(hashlib.md5(key.encode()).hexdigest(), <span class="number">16</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_node</span>(<span class="params">self, node</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Add a node to the hash ring&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.replicas):</span><br><span class="line">            key = self._<span class="built_in">hash</span>(<span class="string">f&quot;<span class="subst">&#123;node&#125;</span>:<span class="subst">&#123;i&#125;</span>&quot;</span>)</span><br><span class="line">            self.ring[key] = node</span><br><span class="line">            bisect.insort(self.sorted_keys, key)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">remove_node</span>(<span class="params">self, node</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Remove a node from the hash ring&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.replicas):</span><br><span class="line">            key = self._<span class="built_in">hash</span>(<span class="string">f&quot;<span class="subst">&#123;node&#125;</span>:<span class="subst">&#123;i&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">del</span> self.ring[key]</span><br><span class="line">            self.sorted_keys.remove(key)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_node</span>(<span class="params">self, key</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Get the node responsible for a key&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.ring:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">        hash_key = self._<span class="built_in">hash</span>(key)</span><br><span class="line">        idx = bisect.bisect_right(self.sorted_keys, hash_key)</span><br><span class="line">        <span class="keyword">if</span> idx == <span class="built_in">len</span>(self.sorted_keys):</span><br><span class="line">            idx = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> self.ring[self.sorted_keys[idx]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example usage</span></span><br><span class="line">ch = ConsistentHash([<span class="string">&#x27;node1&#x27;</span>, <span class="string">&#x27;node2&#x27;</span>, <span class="string">&#x27;node3&#x27;</span>, <span class="string">&#x27;node4&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(ch.get_node(<span class="string">&#x27;user:12345&#x27;</span>))  <span class="comment"># Returns one of the nodes</span></span><br></pre></td></tr></table></figure>
<h2 id="object-storage-deep-dive">Object Storage Deep Dive</h2>
<h3 id="amazon-s3-architecture">Amazon S3 Architecture</h3>
<p>Amazon S3 (Simple Storage Service) is the de facto standard for
object storage. Its architecture demonstrates key principles of scalable
object storage systems.</p>
<h4 id="s3-request-flow">S3 Request Flow</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Client Request</span><br><span class="line">    │</span><br><span class="line">    ▼</span><br><span class="line">┌─────────────────┐</span><br><span class="line">│  Load Balancer  │ (Distributes requests)</span><br><span class="line">└────────┬────────┘</span><br><span class="line">         │</span><br><span class="line">    ┌────┴────┐</span><br><span class="line">    │         │</span><br><span class="line">┌───▼───┐ ┌───▼───┐</span><br><span class="line">│Frontend│ │Frontend│ (Request routing)</span><br><span class="line">└───┬───┘ └───┬───┘</span><br><span class="line">    │         │</span><br><span class="line">    └────┬────┘</span><br><span class="line">         │</span><br><span class="line">┌────────▼────────┐</span><br><span class="line">│  Metadata Store │ (DynamoDB - object metadata)</span><br><span class="line">└────────┬────────┘</span><br><span class="line">         │</span><br><span class="line">    ┌────┴────┐</span><br><span class="line">    │         │</span><br><span class="line">┌───▼───┐ ┌───▼───┐</span><br><span class="line">│Storage│ │Storage│ (Actual object data)</span><br><span class="line">│ Node  │ │ Node  │</span><br><span class="line">└───────┘ └───────┘</span><br></pre></td></tr></table></figure>
<h4 id="s3-key-concepts">S3 Key Concepts</h4>
<p><strong>Buckets</strong>: Top-level containers for objects, organized
by region and namespace.</p>
<p><strong>Objects</strong>: Immutable data units with:</p>
<ul>
<li>Key (unique identifier)</li>
<li>Value (data)</li>
<li>Metadata (content-type, custom headers)</li>
<li>Version ID (for versioning)</li>
</ul>
<p><strong>Regions</strong>: Geographic locations for data storage,
enabling compliance and latency optimization.</p>
<h4 id="s3-api-operations">S3 API Operations</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> boto3</span><br><span class="line"><span class="keyword">from</span> botocore.exceptions <span class="keyword">import</span> ClientError</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">S3StorageManager</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, region_name=<span class="string">&#x27;us-east-1&#x27;</span></span>):</span><br><span class="line">        self.s3_client = boto3.client(<span class="string">&#x27;s3&#x27;</span>, region_name=region_name)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_bucket</span>(<span class="params">self, bucket_name</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Create a new S3 bucket&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.s3_client.create_bucket(Bucket=bucket_name)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Bucket <span class="subst">&#123;bucket_name&#125;</span> created successfully&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> ClientError <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Error creating bucket: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">upload_object</span>(<span class="params">self, bucket_name, object_key, file_path, metadata=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Upload an object to S3&quot;&quot;&quot;</span></span><br><span class="line">        extra_args = &#123;&#125;</span><br><span class="line">        <span class="keyword">if</span> metadata:</span><br><span class="line">            extra_args[<span class="string">&#x27;Metadata&#x27;</span>] = metadata</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.s3_client.upload_file(</span><br><span class="line">                file_path,</span><br><span class="line">                bucket_name,</span><br><span class="line">                object_key,</span><br><span class="line">                ExtraArgs=extra_args</span><br><span class="line">            )</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Object <span class="subst">&#123;object_key&#125;</span> uploaded successfully&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> ClientError <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Error uploading object: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">download_object</span>(<span class="params">self, bucket_name, object_key, download_path</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Download an object from S3&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.s3_client.download_file(</span><br><span class="line">                bucket_name,</span><br><span class="line">                object_key,</span><br><span class="line">                download_path</span><br><span class="line">            )</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Object <span class="subst">&#123;object_key&#125;</span> downloaded successfully&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> ClientError <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Error downloading object: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">list_objects</span>(<span class="params">self, bucket_name, prefix=<span class="string">&#x27;&#x27;</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;List objects in a bucket&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = self.s3_client.list_objects_v2(</span><br><span class="line">                Bucket=bucket_name,</span><br><span class="line">                Prefix=prefix</span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">return</span> response.get(<span class="string">&#x27;Contents&#x27;</span>, [])</span><br><span class="line">        <span class="keyword">except</span> ClientError <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Error listing objects: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">delete_object</span>(<span class="params">self, bucket_name, object_key</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Delete an object from S3&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.s3_client.delete_object(Bucket=bucket_name, Key=object_key)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Object <span class="subst">&#123;object_key&#125;</span> deleted successfully&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> ClientError <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Error deleting object: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Usage example</span></span><br><span class="line">manager = S3StorageManager()</span><br><span class="line">manager.create_bucket(<span class="string">&#x27;my-app-data&#x27;</span>)</span><br><span class="line">manager.upload_object(</span><br><span class="line">    <span class="string">&#x27;my-app-data&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;users/profile.jpg&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;/local/path/profile.jpg&#x27;</span>,</span><br><span class="line">    metadata=&#123;<span class="string">&#x27;user-id&#x27;</span>: <span class="string">&#x27;12345&#x27;</span>, <span class="string">&#x27;upload-time&#x27;</span>: <span class="string">&#x27;2025-01-01&#x27;</span>&#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="s3-storage-classes">S3 Storage Classes</h4>
<p>S3 offers multiple storage classes optimized for different access
patterns:</p>
<table>
<colgroup>
<col style="width: 25%">
<col style="width: 17%">
<col style="width: 21%">
<col style="width: 25%">
<col style="width: 10%">
</colgroup>
<thead>
<tr>
<th>Storage Class</th>
<th>Use Case</th>
<th>Durability</th>
<th>Availability</th>
<th>Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td>Standard</td>
<td>Frequently accessed data</td>
<td>99.999999999%</td>
<td>99.99%</td>
<td>Highest</td>
</tr>
<tr>
<td>Standard-IA</td>
<td>Infrequently accessed</td>
<td>99.999999999%</td>
<td>99.9%</td>
<td>Lower</td>
</tr>
<tr>
<td>One Zone-IA</td>
<td>Non-critical infrequent access</td>
<td>99.999999999%</td>
<td>99.5%</td>
<td>Lower still</td>
</tr>
<tr>
<td>Glacier Instant Retrieval</td>
<td>Archive with instant access</td>
<td>99.999999999%</td>
<td>99.9%</td>
<td>Very low</td>
</tr>
<tr>
<td>Glacier Flexible Retrieval</td>
<td>Archive (3-5 min retrieval)</td>
<td>99.999999999%</td>
<td>99.99%</td>
<td>Very low</td>
</tr>
<tr>
<td>Glacier Deep Archive</td>
<td>Long-term archive (12-48h)</td>
<td>99.999999999%</td>
<td>99.99%</td>
<td>Lowest</td>
</tr>
<tr>
<td>Intelligent-Tiering</td>
<td>Automatic optimization</td>
<td>99.999999999%</td>
<td>99.9%</td>
<td>Variable</td>
</tr>
</tbody>
</table>
<h4 id="s3-consistency-model">S3 Consistency Model</h4>
<p>S3 provides:</p>
<ul>
<li><strong>Read-after-write consistency</strong> for PUTs of new
objects</li>
<li><strong>Eventual consistency</strong> for overwrite PUTs and
DELETEs</li>
<li><strong>Strong consistency</strong> for GET operations (as of
December 2020)</li>
</ul>
<p>This model balances performance with consistency guarantees.</p>
<h3 id="alibaba-cloud-oss-architecture">Alibaba Cloud OSS
Architecture</h3>
<p>Alibaba Cloud Object Storage Service (OSS) follows similar principles
to S3 but with some architectural differences:</p>
<h4 id="oss-architecture-components">OSS Architecture Components</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────┐</span><br><span class="line">│         OSS API Gateway                 │</span><br><span class="line">│  (Request routing, authentication)      │</span><br><span class="line">└──────────────┬──────────────────────────┘</span><br><span class="line">               │</span><br><span class="line">    ┌──────────┴──────────┐</span><br><span class="line">    │                     │</span><br><span class="line">┌───▼────┐          ┌─────▼────┐</span><br><span class="line">│Metadata│          │  Storage │</span><br><span class="line">│ Service│          │  Service │</span><br><span class="line">│(TableStore)       │  (Pangu)  │</span><br><span class="line">└────────┘          └──────────┘</span><br></pre></td></tr></table></figure>
<p><strong>Key Features</strong>:</p>
<ul>
<li>Multi-version support</li>
<li>Server-side encryption</li>
<li>Cross-region replication</li>
<li>Lifecycle management</li>
<li>CDN integration</li>
</ul>
<h4 id="oss-python-sdk-example">OSS Python SDK Example</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> oss2</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OSSStorageManager</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, access_key_id, access_key_secret, endpoint, bucket_name</span>):</span><br><span class="line">        auth = oss2.Auth(access_key_id, access_key_secret)</span><br><span class="line">        self.bucket = oss2.Bucket(auth, endpoint, bucket_name)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">upload_file</span>(<span class="params">self, local_file, object_key</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Upload file to OSS&quot;&quot;&quot;</span></span><br><span class="line">        result = self.bucket.put_object_from_file(object_key, local_file)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Upload successful. ETag: <span class="subst">&#123;result.etag&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">download_file</span>(<span class="params">self, object_key, local_file</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Download file from OSS&quot;&quot;&quot;</span></span><br><span class="line">        self.bucket.get_object_to_file(object_key, local_file)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Download successful: <span class="subst">&#123;local_file&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">list_objects</span>(<span class="params">self, prefix=<span class="string">&#x27;&#x27;</span>, max_keys=<span class="number">100</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;List objects with prefix&quot;&quot;&quot;</span></span><br><span class="line">        objects = []</span><br><span class="line">        <span class="keyword">for</span> obj <span class="keyword">in</span> oss2.ObjectIterator(self.bucket, prefix=prefix, max_keys=max_keys):</span><br><span class="line">            objects.append(&#123;</span><br><span class="line">                <span class="string">&#x27;key&#x27;</span>: obj.key,</span><br><span class="line">                <span class="string">&#x27;size&#x27;</span>: obj.size,</span><br><span class="line">                <span class="string">&#x27;last_modified&#x27;</span>: obj.last_modified</span><br><span class="line">            &#125;)</span><br><span class="line">        <span class="keyword">return</span> objects</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">delete_object</span>(<span class="params">self, object_key</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Delete object from OSS&quot;&quot;&quot;</span></span><br><span class="line">        self.bucket.delete_object(object_key)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Deleted: <span class="subst">&#123;object_key&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set_lifecycle_rule</span>(<span class="params">self, prefix, expiration_days</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Set lifecycle rule for automatic deletion&quot;&quot;&quot;</span></span><br><span class="line">        rule = oss2.models.LifecycleRule(</span><br><span class="line">            <span class="built_in">id</span>=<span class="string">&#x27;auto-delete&#x27;</span>,</span><br><span class="line">            status=<span class="string">&#x27;Enabled&#x27;</span>,</span><br><span class="line">            prefix=prefix,</span><br><span class="line">            expiration=expiration_days</span><br><span class="line">        )</span><br><span class="line">        self.bucket.put_bucket_lifecycle(oss2.models.BucketLifecycle([rule]))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Lifecycle rule set for prefix: <span class="subst">&#123;prefix&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Usage</span></span><br><span class="line">manager = OSSStorageManager(</span><br><span class="line">    access_key_id=<span class="string">&#x27;your-key&#x27;</span>,</span><br><span class="line">    access_key_secret=<span class="string">&#x27;your-secret&#x27;</span>,</span><br><span class="line">    endpoint=<span class="string">&#x27;https://oss-cn-hangzhou.aliyuncs.com&#x27;</span>,</span><br><span class="line">    bucket_name=<span class="string">&#x27;my-bucket&#x27;</span></span><br><span class="line">)</span><br><span class="line">manager.upload_file(<span class="string">&#x27;/local/file.txt&#x27;</span>, <span class="string">&#x27;remote/file.txt&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="block-vs-file-storage-comparison">Block vs File Storage
Comparison</h2>
<p>Understanding the differences between block, file, and object storage
is crucial for selecting the right storage solution.</p>
<h3 id="block-storage">Block Storage</h3>
<p>Block storage treats storage as a sequence of fixed-size blocks,
typically 512 bytes to 4KB. The storage system doesn't understand file
semantics—it only manages blocks.</p>
<h4 id="characteristics">Characteristics</h4>
<ul>
<li><strong>Low-level access</strong>: Direct block-level I/O</li>
<li><strong>High performance</strong>: Minimal overhead, suitable for
databases</li>
<li><strong>Flexible</strong>: Can be formatted with any filesystem</li>
<li><strong>No metadata</strong>: Block storage doesn't track file
information</li>
</ul>
<h4 id="use-cases">Use Cases</h4>
<ul>
<li>Database storage (MySQL, PostgreSQL, Oracle)</li>
<li>Virtual machine disk images</li>
<li>High-performance applications requiring low latency</li>
<li>RAID implementations</li>
</ul>
<h4 id="block-storage-architecture">Block Storage Architecture</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Application</span><br><span class="line">    │</span><br><span class="line">    ▼</span><br><span class="line">┌──────────┐</span><br><span class="line">│File System│ (ext4, XFS, NTFS)</span><br><span class="line">└────┬─────┘</span><br><span class="line">     │</span><br><span class="line">     ▼</span><br><span class="line">┌──────────┐</span><br><span class="line">│Block Layer│ (Logical Volume Manager)</span><br><span class="line">└────┬─────┘</span><br><span class="line">     │</span><br><span class="line">     ▼</span><br><span class="line">┌──────────┐</span><br><span class="line">│Physical  │ (Hard drives, SSDs)</span><br><span class="line">│Storage   │</span><br><span class="line">└──────────┘</span><br></pre></td></tr></table></figure>
<h4 id="aws-ebs-example">AWS EBS Example</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> boto3</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EBSManager</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, region_name=<span class="string">&#x27;us-east-1&#x27;</span></span>):</span><br><span class="line">        self.ec2 = boto3.client(<span class="string">&#x27;ec2&#x27;</span>, region_name=region_name)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_volume</span>(<span class="params">self, size_gb, volume_type=<span class="string">&#x27;gp3&#x27;</span>, availability_zone=<span class="string">&#x27;us-east-1a&#x27;</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Create an EBS volume&quot;&quot;&quot;</span></span><br><span class="line">        response = self.ec2.create_volume(</span><br><span class="line">            AvailabilityZone=availability_zone,</span><br><span class="line">            Size=size_gb,</span><br><span class="line">            VolumeType=volume_type,</span><br><span class="line">            Encrypted=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        volume_id = response[<span class="string">&#x27;VolumeId&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Created volume: <span class="subst">&#123;volume_id&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> volume_id</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">attach_volume</span>(<span class="params">self, volume_id, instance_id, device=<span class="string">&#x27;/dev/sdf&#x27;</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Attach volume to EC2 instance&quot;&quot;&quot;</span></span><br><span class="line">        self.ec2.attach_volume(</span><br><span class="line">            VolumeId=volume_id,</span><br><span class="line">            InstanceId=instance_id,</span><br><span class="line">            Device=device</span><br><span class="line">        )</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Attached <span class="subst">&#123;volume_id&#125;</span> to <span class="subst">&#123;instance_id&#125;</span> as <span class="subst">&#123;device&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_snapshot</span>(<span class="params">self, volume_id, description=<span class="string">&#x27;&#x27;</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Create snapshot of volume&quot;&quot;&quot;</span></span><br><span class="line">        response = self.ec2.create_snapshot(</span><br><span class="line">            VolumeId=volume_id,</span><br><span class="line">            Description=description</span><br><span class="line">        )</span><br><span class="line">        snapshot_id = response[<span class="string">&#x27;SnapshotId&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Created snapshot: <span class="subst">&#123;snapshot_id&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> snapshot_id</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">list_volumes</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;List all EBS volumes&quot;&quot;&quot;</span></span><br><span class="line">        response = self.ec2.describe_volumes()</span><br><span class="line">        <span class="keyword">return</span> response[<span class="string">&#x27;Volumes&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Usage</span></span><br><span class="line">ebs = EBSManager()</span><br><span class="line">volume_id = ebs.create_volume(size_gb=<span class="number">100</span>, volume_type=<span class="string">&#x27;gp3&#x27;</span>)</span><br><span class="line">ebs.attach_volume(volume_id, <span class="string">&#x27;i-1234567890abcdef0&#x27;</span>)</span><br><span class="line">snapshot_id = ebs.create_snapshot(volume_id, <span class="string">&#x27;Daily backup&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="file-storage">File Storage</h3>
<p>File storage organizes data in a hierarchical directory structure
with files and folders. It provides file-level semantics and
metadata.</p>
<h4 id="characteristics-1">Characteristics</h4>
<ul>
<li><strong>Hierarchical structure</strong>: Directory trees with
files</li>
<li><strong>File semantics</strong>: Open, read, write, close
operations</li>
<li><strong>Metadata</strong>: File permissions, timestamps,
ownership</li>
<li><strong>Network protocols</strong>: NFS, SMB/CIFS, CIFS</li>
</ul>
<h4 id="use-cases-1">Use Cases</h4>
<ul>
<li>Shared file systems for multiple servers</li>
<li>Content management systems</li>
<li>Home directories</li>
<li>Application configuration files</li>
</ul>
<h4 id="file-storage-architecture">File Storage Architecture</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Client Application</span><br><span class="line">    │</span><br><span class="line">    ▼</span><br><span class="line">┌──────────────┐</span><br><span class="line">│NFS/SMB Client│</span><br><span class="line">└──────┬───────┘</span><br><span class="line">       │ Network Protocol</span><br><span class="line">       ▼</span><br><span class="line">┌──────────────┐</span><br><span class="line">│File Server   │</span><br><span class="line">│(NFS/SMB)     │</span><br><span class="line">└──────┬───────┘</span><br><span class="line">       │</span><br><span class="line">┌──────▼───────┐</span><br><span class="line">│File System   │ (ext4, ZFS, etc.)</span><br><span class="line">└──────┬───────┘</span><br><span class="line">       │</span><br><span class="line">┌──────▼───────┐</span><br><span class="line">│Block Storage │</span><br><span class="line">└──────────────┘</span><br></pre></td></tr></table></figure>
<h4 id="aws-efs-example">AWS EFS Example</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> boto3</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EFSManager</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, region_name=<span class="string">&#x27;us-east-1&#x27;</span></span>):</span><br><span class="line">        self.efs = boto3.client(<span class="string">&#x27;efs&#x27;</span>, region_name=region_name)</span><br><span class="line">        self.ec2 = boto3.client(<span class="string">&#x27;ec2&#x27;</span>, region_name=region_name)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_file_system</span>(<span class="params">self, performance_mode=<span class="string">&#x27;generalPurpose&#x27;</span>, throughput_mode=<span class="string">&#x27;bursting&#x27;</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Create EFS file system&quot;&quot;&quot;</span></span><br><span class="line">        response = self.efs.create_file_system(</span><br><span class="line">            PerformanceMode=performance_mode,</span><br><span class="line">            ThroughputMode=throughput_mode,</span><br><span class="line">            Encrypted=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        file_system_id = response[<span class="string">&#x27;FileSystemId&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Created EFS: <span class="subst">&#123;file_system_id&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> file_system_id</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_mount_target</span>(<span class="params">self, file_system_id, subnet_id, security_groups</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Create mount target for EFS&quot;&quot;&quot;</span></span><br><span class="line">        response = self.efs.create_mount_target(</span><br><span class="line">            FileSystemId=file_system_id,</span><br><span class="line">            SubnetId=subnet_id,</span><br><span class="line">            SecurityGroups=security_groups</span><br><span class="line">        )</span><br><span class="line">        mount_target_id = response[<span class="string">&#x27;MountTargetId&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Created mount target: <span class="subst">&#123;mount_target_id&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> mount_target_id</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">list_file_systems</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;List all EFS file systems&quot;&quot;&quot;</span></span><br><span class="line">        response = self.efs.describe_file_systems()</span><br><span class="line">        <span class="keyword">return</span> response[<span class="string">&#x27;FileSystems&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Usage</span></span><br><span class="line">efs = EFSManager()</span><br><span class="line">fs_id = efs.create_file_system(performance_mode=<span class="string">&#x27;generalPurpose&#x27;</span>)</span><br><span class="line"><span class="comment"># Mount target requires subnet and security group IDs</span></span><br></pre></td></tr></table></figure>
<h3 id="comparison-table">Comparison Table</h3>
<table>
<colgroup>
<col style="width: 16%">
<col style="width: 26%">
<col style="width: 26%">
<col style="width: 30%">
</colgroup>
<thead>
<tr>
<th>Feature</th>
<th>Block Storage</th>
<th>File Storage</th>
<th>Object Storage</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Access Method</strong></td>
<td>Block-level I/O</td>
<td>File system APIs</td>
<td>REST APIs</td>
</tr>
<tr>
<td><strong>Data Organization</strong></td>
<td>Blocks</td>
<td>Hierarchical directories</td>
<td>Flat namespace</td>
</tr>
<tr>
<td><strong>Metadata</strong></td>
<td>None</td>
<td>File metadata</td>
<td>Object metadata</td>
</tr>
<tr>
<td><strong>Scalability</strong></td>
<td>Limited</td>
<td>Moderate</td>
<td>Excellent</td>
</tr>
<tr>
<td><strong>Performance</strong></td>
<td>Very high</td>
<td>High</td>
<td>Moderate to high</td>
</tr>
<tr>
<td><strong>Use Cases</strong></td>
<td>Databases, VMs</td>
<td>Shared filesystems</td>
<td>Web apps, archives</td>
</tr>
<tr>
<td><strong>Protocols</strong></td>
<td>iSCSI, FC</td>
<td>NFS, SMB</td>
<td>HTTP/REST</td>
</tr>
<tr>
<td><strong>Consistency</strong></td>
<td>Strong</td>
<td>Strong</td>
<td>Eventual (typically)</td>
</tr>
<tr>
<td><strong>Cost</strong></td>
<td>High</td>
<td>Moderate</td>
<td>Low</td>
</tr>
</tbody>
</table>
<h3 id="when-to-use-each-type">When to Use Each Type</h3>
<p><strong>Block Storage</strong>:</p>
<ul>
<li>Running databases requiring low latency</li>
<li>Virtual machine disk images</li>
<li>Applications needing raw disk access</li>
<li>High I/O operations per second (IOPS) requirements</li>
</ul>
<p><strong>File Storage</strong>:</p>
<ul>
<li>Shared file systems across multiple servers</li>
<li>Content management systems</li>
<li>Legacy applications requiring POSIX semantics</li>
<li>Home directories and user data</li>
</ul>
<p><strong>Object Storage</strong>:</p>
<ul>
<li>Web applications and static assets</li>
<li>Backup and archival data</li>
<li>Big data analytics</li>
<li>Content delivery and media storage</li>
<li>Unstructured data at scale</li>
</ul>
<h2 id="hdfs-distributed-file-system">HDFS Distributed File System</h2>
<p>Hadoop Distributed File System (HDFS) is designed for storing very
large files across clusters of commodity hardware.</p>
<h3 id="hdfs-architecture">HDFS Architecture</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">                    ┌──────────────┐</span><br><span class="line">                    │ NameNode     │ (Metadata, namespace)</span><br><span class="line">                    │ (Active)     │</span><br><span class="line">                    └──────┬───────┘</span><br><span class="line">                           │</span><br><span class="line">                    ┌──────▼───────┐</span><br><span class="line">                    │ NameNode     │ (Standby - for HA)</span><br><span class="line">                    │ (Standby)    │</span><br><span class="line">                    └──────────────┘</span><br><span class="line">                           │</span><br><span class="line">        ┌──────────────────┼──────────────────┐</span><br><span class="line">        │                  │                  │</span><br><span class="line">┌───────▼──────┐  ┌────────▼──────┐  ┌───────▼──────┐</span><br><span class="line">│ DataNode 1   │  │ DataNode 2    │  │ DataNode 3   │</span><br><span class="line">│ (Replica 1)  │  │ (Replica 2)   │  │ (Replica 3)  │</span><br><span class="line">└──────────────┘  └───────────────┘  └──────────────┘</span><br></pre></td></tr></table></figure>
<h4 id="key-components">Key Components</h4>
<p><strong>NameNode</strong>:</p>
<ul>
<li>Manages file system namespace</li>
<li>Stores metadata (file names, permissions, block locations)</li>
<li>Coordinates file operations</li>
<li>Single point of failure (mitigated by High Availability)</li>
</ul>
<p><strong>DataNode</strong>:</p>
<ul>
<li>Stores actual data blocks</li>
<li>Serves read/write requests</li>
<li>Reports block status to NameNode</li>
<li>Performs block replication</li>
</ul>
<p><strong>Secondary NameNode</strong> (legacy):</p>
<ul>
<li>Performs checkpointing of NameNode metadata</li>
<li>Not a backup NameNode (common misconception)</li>
</ul>
<h3 id="hdfs-configuration">HDFS Configuration</h3>
<h4 id="core-site.xml">core-site.xml</h4>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://namenode:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="hdfs-site.xml">hdfs-site.xml</h4>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop/hdfs/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop/hdfs/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop/hdfs/checkpoint<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.blocksize<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">value</span>&gt;</span> <span class="comment">&lt;!-- 128MB --&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.handler.count<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>100<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="hdfs-operations">HDFS Operations</h3>
<h4 id="java-api-example">Java API Example</h4>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HDFSOperations</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> FileSystem fs;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">HDFSOperations</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>, <span class="string">&quot;hdfs://namenode:9000&quot;</span>);</span><br><span class="line">        <span class="built_in">this</span>.fs = FileSystem.get(conf);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">createDirectory</span><span class="params">(String path)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Path</span> <span class="variable">dirPath</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(path);</span><br><span class="line">        <span class="keyword">if</span> (!fs.exists(dirPath)) &#123;</span><br><span class="line">            fs.mkdirs(dirPath);</span><br><span class="line">            System.out.println(<span class="string">&quot;Directory created: &quot;</span> + path);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">uploadFile</span><span class="params">(String localPath, String hdfsPath)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Path</span> <span class="variable">localFilePath</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(localPath);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">hdfsFilePath</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(hdfsPath);</span><br><span class="line">        </span><br><span class="line">        fs.copyFromLocalFile(localFilePath, hdfsFilePath);</span><br><span class="line">        System.out.println(<span class="string">&quot;File uploaded: &quot;</span> + localPath + <span class="string">&quot; -&gt; &quot;</span> + hdfsPath);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">downloadFile</span><span class="params">(String hdfsPath, String localPath)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Path</span> <span class="variable">hdfsFilePath</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(hdfsPath);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">localFilePath</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(localPath);</span><br><span class="line">        </span><br><span class="line">        fs.copyToLocalFile(hdfsFilePath, localFilePath);</span><br><span class="line">        System.out.println(<span class="string">&quot;File downloaded: &quot;</span> + hdfsPath + <span class="string">&quot; -&gt; &quot;</span> + localPath);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">listFiles</span><span class="params">(String directory)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Path</span> <span class="variable">dirPath</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(directory);</span><br><span class="line">        FileStatus[] files = fs.listStatus(dirPath);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (FileStatus file : files) &#123;</span><br><span class="line">            System.out.println(file.getPath().getName() + </span><br><span class="line">                <span class="string">&quot; (Size: &quot;</span> + file.getLen() + <span class="string">&quot; bytes)&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">deleteFile</span><span class="params">(String path)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Path</span> <span class="variable">filePath</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(path);</span><br><span class="line">        <span class="keyword">if</span> (fs.exists(filePath)) &#123;</span><br><span class="line">            fs.delete(filePath, <span class="literal">true</span>);</span><br><span class="line">            System.out.println(<span class="string">&quot;Deleted: &quot;</span> + path);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">HDFSOperations</span> <span class="variable">hdfs</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HDFSOperations</span>();</span><br><span class="line">        hdfs.createDirectory(<span class="string">&quot;/user/data&quot;</span>);</span><br><span class="line">        hdfs.uploadFile(<span class="string">&quot;/local/file.txt&quot;</span>, <span class="string">&quot;/user/data/file.txt&quot;</span>);</span><br><span class="line">        hdfs.listFiles(<span class="string">&quot;/user/data&quot;</span>);</span><br><span class="line">        hdfs.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="python-api-with-hdfs3">Python API with hdfs3</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> hdfs3 <span class="keyword">import</span> HDFileSystem</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HDFSManager</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, host=<span class="string">&#x27;localhost&#x27;</span>, port=<span class="number">9000</span></span>):</span><br><span class="line">        self.hdfs = HDFileSystem(host=host, port=port)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_directory</span>(<span class="params">self, path</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Create directory in HDFS&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.hdfs.exists(path):</span><br><span class="line">            self.hdfs.mkdir(path)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Created directory: <span class="subst">&#123;path&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">upload_file</span>(<span class="params">self, local_path, hdfs_path</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Upload file to HDFS&quot;&quot;&quot;</span></span><br><span class="line">        self.hdfs.put(local_path, hdfs_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Uploaded: <span class="subst">&#123;local_path&#125;</span> -&gt; <span class="subst">&#123;hdfs_path&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">download_file</span>(<span class="params">self, hdfs_path, local_path</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Download file from HDFS&quot;&quot;&quot;</span></span><br><span class="line">        self.hdfs.get(hdfs_path, local_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Downloaded: <span class="subst">&#123;hdfs_path&#125;</span> -&gt; <span class="subst">&#123;local_path&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">list_files</span>(<span class="params">self, directory</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;List files in directory&quot;&quot;&quot;</span></span><br><span class="line">        files = self.hdfs.ls(directory, detail=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">for</span> file_info <span class="keyword">in</span> files:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;file_info[<span class="string">&#x27;name&#x27;</span>]&#125;</span> - Size: <span class="subst">&#123;file_info[<span class="string">&#x27;size&#x27;</span>]&#125;</span> bytes&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> files</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">delete_file</span>(<span class="params">self, path</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Delete file or directory&quot;&quot;&quot;</span></span><br><span class="line">        self.hdfs.rm(path, recursive=<span class="literal">True</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Deleted: <span class="subst">&#123;path&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_file_info</span>(<span class="params">self, path</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Get file information&quot;&quot;&quot;</span></span><br><span class="line">        info = self.hdfs.info(path)</span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&#x27;path&#x27;</span>: info[<span class="string">&#x27;name&#x27;</span>],</span><br><span class="line">            <span class="string">&#x27;size&#x27;</span>: info[<span class="string">&#x27;size&#x27;</span>],</span><br><span class="line">            <span class="string">&#x27;type&#x27;</span>: info[<span class="string">&#x27;kind&#x27;</span>],</span><br><span class="line">            <span class="string">&#x27;replication&#x27;</span>: info.get(<span class="string">&#x27;replication&#x27;</span>, <span class="string">&#x27;N/A&#x27;</span>)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Usage</span></span><br><span class="line">hdfs = HDFSManager(host=<span class="string">&#x27;namenode&#x27;</span>, port=<span class="number">9000</span>)</span><br><span class="line">hdfs.create_directory(<span class="string">&#x27;/user/data&#x27;</span>)</span><br><span class="line">hdfs.upload_file(<span class="string">&#x27;/local/data.csv&#x27;</span>, <span class="string">&#x27;/user/data/data.csv&#x27;</span>)</span><br><span class="line">files = hdfs.list_files(<span class="string">&#x27;/user/data&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="hdfs-replication-strategy">HDFS Replication Strategy</h3>
<p>HDFS replicates blocks across multiple DataNodes for fault
tolerance:</p>
<ol type="1">
<li><p><strong>Default replication factor</strong>: 3</p></li>
<li><p><strong>Replication placement</strong>:</p>
<ul>
<li>First replica: Same node as writer (if on DataNode) or random
node</li>
<li>Second replica: Different rack from first</li>
<li>Third replica: Same rack as second, different node</li>
</ul></li>
</ol>
<p>This strategy balances performance (rack-local reads) with fault
tolerance (rack failure resilience).</p>
<h3 id="hdfs-high-availability">HDFS High Availability</h3>
<p>HA NameNode configuration eliminates single point of failure:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>namenode1:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>namenode2:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://journal1:8485;journal2:8485;journal3:8485/mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="ceph-storage-cluster-deployment">Ceph Storage Cluster
Deployment</h2>
<p>Ceph is a unified distributed storage system providing object, block,
and file storage interfaces.</p>
<h3 id="ceph-architecture">Ceph Architecture</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────┐</span><br><span class="line">│         Client Applications             │</span><br><span class="line">└─────┬───────┬───────┬───────────────────┘</span><br><span class="line">      │       │       │</span><br><span class="line">  ┌───▼───┐ ┌─▼───┐ ┌─▼───┐</span><br><span class="line">  │Object │ │Block│ │File │ (RADOS Gateway, RBD, CephFS)</span><br><span class="line">  │Gateway│ │     │ │     │</span><br><span class="line">  └───┬───┘ └─┬───┘ └─┬───┘</span><br><span class="line">      │       │       │</span><br><span class="line">      └───────┴───────┘</span><br><span class="line">              │</span><br><span class="line">      ┌───────▼───────┐</span><br><span class="line">      │  RADOS        │ (Reliable Autonomic Distributed Object Store)</span><br><span class="line">      │  - OSDs       │ (Object Storage Daemons)</span><br><span class="line">      │  - Monitors   │ (Cluster state)</span><br><span class="line">      │  - MDS        │ (Metadata Server - for CephFS)</span><br><span class="line">      └───────────────┘</span><br></pre></td></tr></table></figure>
<h4 id="core-components">Core Components</h4>
<p><strong>Monitors (MON)</strong>:</p>
<ul>
<li>Maintain cluster membership and state</li>
<li>Provide consensus for cluster configuration</li>
<li>Typically 3 or 5 nodes for quorum</li>
</ul>
<p><strong>Object Storage Daemons (OSD)</strong>:</p>
<ul>
<li>Store actual data objects</li>
<li>Handle replication and recovery</li>
<li>Report to monitors</li>
</ul>
<p><strong>Metadata Servers (MDS)</strong>:</p>
<ul>
<li>Manage metadata for CephFS</li>
<li>Not required for object or block storage</li>
</ul>
<p><strong>RADOS Gateway (RGW)</strong>:</p>
<ul>
<li>Provides S3-compatible object storage API</li>
<li>Handles authentication and authorization</li>
</ul>
<h3 id="ceph-deployment">Ceph Deployment</h3>
<h4 id="installation-on-ubuntu">Installation on Ubuntu</h4>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add Ceph repository</span></span><br><span class="line">wget -q -O- <span class="string">&#x27;https://download.ceph.com/keys/release.asc&#x27;</span> | sudo apt-key add -</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;deb https://download.ceph.com/debian-&#123;ceph-stable-release&#125;/ <span class="subst">$(lsb_release -sc)</span> main&quot;</span> | sudo <span class="built_in">tee</span> /etc/apt/sources.list.d/ceph.list</span><br><span class="line"></span><br><span class="line"><span class="comment"># Install Ceph</span></span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install ceph-deploy ceph-common</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create cluster</span></span><br><span class="line"><span class="built_in">mkdir</span> ceph-cluster</span><br><span class="line"><span class="built_in">cd</span> ceph-cluster</span><br><span class="line">ceph-deploy new node1 node2 node3</span><br><span class="line"></span><br><span class="line"><span class="comment"># Install on nodes</span></span><br><span class="line">ceph-deploy install node1 node2 node3</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create monitor</span></span><br><span class="line">ceph-deploy mon create-initial</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create OSDs</span></span><br><span class="line">ceph-deploy osd create --data /dev/sdb node1</span><br><span class="line">ceph-deploy osd create --data /dev/sdb node2</span><br><span class="line">ceph-deploy osd create --data /dev/sdb node3</span><br><span class="line"></span><br><span class="line"><span class="comment"># Deploy admin keys</span></span><br><span class="line">ceph-deploy admin node1 node2 node3</span><br></pre></td></tr></table></figure>
<h4 id="ceph-configuration-file-ceph.conf">Ceph Configuration File
(ceph.conf)</h4>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[global]</span></span><br><span class="line"><span class="attr">fsid</span> = &#123;cluster-id&#125;</span><br><span class="line">mon initial <span class="attr">members</span> = node1, node2, node3</span><br><span class="line">mon <span class="attr">host</span> = <span class="number">10.0</span>.<span class="number">0.1</span>, <span class="number">10.0</span>.<span class="number">0.2</span>, <span class="number">10.0</span>.<span class="number">0.3</span></span><br><span class="line">auth cluster <span class="attr">required</span> = cephx</span><br><span class="line">auth service <span class="attr">required</span> = cephx</span><br><span class="line">auth client <span class="attr">required</span> = cephx</span><br><span class="line">osd journal <span class="attr">size</span> = <span class="number">10240</span></span><br><span class="line">osd pool default pg <span class="attr">num</span> = <span class="number">128</span></span><br><span class="line">osd pool default pgp <span class="attr">num</span> = <span class="number">128</span></span><br><span class="line">osd pool default <span class="attr">size</span> = <span class="number">3</span></span><br><span class="line">osd pool default min <span class="attr">size</span> = <span class="number">2</span></span><br><span class="line">public <span class="attr">network</span> = <span class="number">10.0</span>.<span class="number">0.0</span>/<span class="number">24</span></span><br><span class="line">cluster <span class="attr">network</span> = <span class="number">10.0</span>.<span class="number">1.0</span>/<span class="number">24</span></span><br><span class="line"></span><br><span class="line"><span class="section">[mon.node1]</span></span><br><span class="line"><span class="attr">host</span> = node1</span><br><span class="line">mon <span class="attr">addr</span> = <span class="number">10.0</span>.<span class="number">0.1</span>:<span class="number">6789</span></span><br><span class="line"></span><br><span class="line"><span class="section">[mon.node2]</span></span><br><span class="line"><span class="attr">host</span> = node2</span><br><span class="line">mon <span class="attr">addr</span> = <span class="number">10.0</span>.<span class="number">0.2</span>:<span class="number">6789</span></span><br><span class="line"></span><br><span class="line"><span class="section">[mon.node3]</span></span><br><span class="line"><span class="attr">host</span> = node3</span><br><span class="line">mon <span class="attr">addr</span> = <span class="number">10.0</span>.<span class="number">0.3</span>:<span class="number">6789</span></span><br><span class="line"></span><br><span class="line"><span class="section">[osd]</span></span><br><span class="line">osd <span class="attr">data</span> = /var/lib/ceph/osd/ceph-<span class="variable">$id</span></span><br><span class="line">osd <span class="attr">journal</span> = /var/lib/ceph/osd/ceph-<span class="variable">$id</span>/journal</span><br><span class="line">osd mkfs <span class="attr">type</span> = xfs</span><br><span class="line">osd mkfs options <span class="attr">xfs</span> = -f -i size=<span class="number">2048</span></span><br></pre></td></tr></table></figure>
<h3 id="ceph-object-storage-rados-gateway">Ceph Object Storage (RADOS
Gateway)</h3>
<h4 id="rgw-configuration">RGW Configuration</h4>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create RGW instance</span></span><br><span class="line">ceph-deploy rgw create node1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Or manually configure</span></span><br><span class="line">sudo ceph-deploy --overwrite-conf config push node1</span><br><span class="line">sudo systemctl start ceph-radosgw@rgw.node1</span><br><span class="line">sudo systemctl <span class="built_in">enable</span> ceph-radosgw@rgw.node1</span><br></pre></td></tr></table></figure>
<h4 id="python-client-for-rgw">Python Client for RGW</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> boto3</span><br><span class="line"><span class="keyword">from</span> botocore.client <span class="keyword">import</span> Config</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CephRadosGateway</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, endpoint_url, access_key, secret_key</span>):</span><br><span class="line">        self.s3_client = boto3.client(</span><br><span class="line">            <span class="string">&#x27;s3&#x27;</span>,</span><br><span class="line">            endpoint_url=endpoint_url,</span><br><span class="line">            aws_access_key_id=access_key,</span><br><span class="line">            aws_secret_access_key=secret_key,</span><br><span class="line">            config=Config(signature_version=<span class="string">&#x27;s3v4&#x27;</span>)</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_bucket</span>(<span class="params">self, bucket_name</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Create bucket in Ceph RGW&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.s3_client.create_bucket(Bucket=bucket_name)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Bucket <span class="subst">&#123;bucket_name&#125;</span> created&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Error: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">upload_object</span>(<span class="params">self, bucket_name, object_key, data</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Upload object&quot;&quot;&quot;</span></span><br><span class="line">        self.s3_client.put_object(</span><br><span class="line">            Bucket=bucket_name,</span><br><span class="line">            Key=object_key,</span><br><span class="line">            Body=data</span><br><span class="line">        )</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Uploaded <span class="subst">&#123;object_key&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">list_objects</span>(<span class="params">self, bucket_name</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;List objects in bucket&quot;&quot;&quot;</span></span><br><span class="line">        response = self.s3_client.list_objects_v2(Bucket=bucket_name)</span><br><span class="line">        <span class="keyword">return</span> response.get(<span class="string">&#x27;Contents&#x27;</span>, [])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Usage</span></span><br><span class="line">rgw = CephRadosGateway(</span><br><span class="line">    endpoint_url=<span class="string">&#x27;http://rgw-node1:7480&#x27;</span>,</span><br><span class="line">    access_key=<span class="string">&#x27;your-access-key&#x27;</span>,</span><br><span class="line">    secret_key=<span class="string">&#x27;your-secret-key&#x27;</span></span><br><span class="line">)</span><br><span class="line">rgw.create_bucket(<span class="string">&#x27;my-bucket&#x27;</span>)</span><br><span class="line">rgw.upload_object(<span class="string">&#x27;my-bucket&#x27;</span>, <span class="string">&#x27;test.txt&#x27;</span>, <span class="string">b&#x27;Hello Ceph&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="ceph-block-storage-rbd">Ceph Block Storage (RBD)</h3>
<h4 id="rbd-operations">RBD Operations</h4>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create pool for RBD</span></span><br><span class="line">ceph osd pool create rbd 128 128</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize pool for RBD</span></span><br><span class="line">rbd pool init rbd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create RBD image</span></span><br><span class="line">rbd create --size 10G rbd/myimage</span><br><span class="line"></span><br><span class="line"><span class="comment"># Map image to kernel</span></span><br><span class="line">sudo rbd map rbd/myimage</span><br><span class="line"></span><br><span class="line"><span class="comment"># Format and mount</span></span><br><span class="line">sudo mkfs.ext4 /dev/rbd0</span><br><span class="line">sudo mount /dev/rbd0 /mnt/rbd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create snapshot</span></span><br><span class="line">rbd snap create rbd/myimage@snapshot1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Clone from snapshot</span></span><br><span class="line">rbd snap protect rbd/myimage@snapshot1</span><br><span class="line">rbd <span class="built_in">clone</span> rbd/myimage@snapshot1 rbd/myclone</span><br></pre></td></tr></table></figure>
<h4 id="python-rbd-client">Python RBD Client</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> rbd</span><br><span class="line"><span class="keyword">import</span> rados</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CephRBDManager</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, cluster_name=<span class="string">&#x27;ceph&#x27;</span>, user_name=<span class="string">&#x27;client.admin&#x27;</span>, conf_file=<span class="string">&#x27;/etc/ceph/ceph.conf&#x27;</span></span>):</span><br><span class="line">        self.cluster = rados.Rados(</span><br><span class="line">            name=cluster_name,</span><br><span class="line">            clustername=cluster_name,</span><br><span class="line">            conffile=conf_file,</span><br><span class="line">            name=user_name</span><br><span class="line">        )</span><br><span class="line">        self.cluster.connect()</span><br><span class="line">        self.ioctx = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">open_pool</span>(<span class="params">self, pool_name</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Open a pool&quot;&quot;&quot;</span></span><br><span class="line">        self.ioctx = self.cluster.open_ioctx(pool_name)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_image</span>(<span class="params">self, image_name, size_mb</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Create RBD image&quot;&quot;&quot;</span></span><br><span class="line">        rbd_inst = rbd.RBD()</span><br><span class="line">        rbd_inst.create(self.ioctx, image_name, size_mb * <span class="number">1024</span> * <span class="number">1024</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Created image: <span class="subst">&#123;image_name&#125;</span> (<span class="subst">&#123;size_mb&#125;</span>MB)&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">list_images</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;List all images in pool&quot;&quot;&quot;</span></span><br><span class="line">        rbd_inst = rbd.RBD()</span><br><span class="line">        <span class="keyword">return</span> rbd_inst.<span class="built_in">list</span>(self.ioctx)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_snapshot</span>(<span class="params">self, image_name, snapshot_name</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Create snapshot&quot;&quot;&quot;</span></span><br><span class="line">        image = rbd.Image(self.ioctx, image_name)</span><br><span class="line">        image.create_snapshot(snapshot_name)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Created snapshot: <span class="subst">&#123;snapshot_name&#125;</span>&quot;</span>)</span><br><span class="line">        image.close()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">close</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Close connections&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> self.ioctx:</span><br><span class="line">            self.ioctx.close()</span><br><span class="line">        self.cluster.shutdown()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Usage</span></span><br><span class="line">rbd_mgr = CephRBDManager()</span><br><span class="line">rbd_mgr.open_pool(<span class="string">&#x27;rbd&#x27;</span>)</span><br><span class="line">rbd_mgr.create_image(<span class="string">&#x27;myimage&#x27;</span>, <span class="number">10240</span>)  <span class="comment"># 10GB</span></span><br><span class="line">images = rbd_mgr.list_images()</span><br><span class="line">rbd_mgr.create_snapshot(<span class="string">&#x27;myimage&#x27;</span>, <span class="string">&#x27;snap1&#x27;</span>)</span><br><span class="line">rbd_mgr.close()</span><br></pre></td></tr></table></figure>
<h3 id="ceph-performance-tuning">Ceph Performance Tuning</h3>
<h4 id="osd-configuration">OSD Configuration</h4>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[osd]</span></span><br><span class="line"><span class="comment"># Increase OSD memory</span></span><br><span class="line">osd memory <span class="attr">target</span> = <span class="number">4294967296</span>  <span class="comment"># 4GB</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Optimize journal</span></span><br><span class="line">osd journal <span class="attr">size</span> = <span class="number">10240</span>  <span class="comment"># 10GB</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Network optimization</span></span><br><span class="line">ms bind port <span class="attr">min</span> = <span class="number">6800</span></span><br><span class="line">ms bind port <span class="attr">max</span> = <span class="number">7300</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Recovery settings</span></span><br><span class="line">osd recovery max <span class="attr">active</span> = <span class="number">3</span></span><br><span class="line">osd recovery <span class="attr">threads</span> = <span class="number">1</span></span><br><span class="line">osd max <span class="attr">backfills</span> = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h4 id="crush-map-optimization">CRUSH Map Optimization</h4>
<p>CRUSH (Controlled Replication Under Scalable Hashing) algorithm
determines data placement:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get current CRUSH map</span></span><br><span class="line">ceph osd getcrushmap -o crushmap.bin</span><br><span class="line">crushtool -d crushmap.bin -o crushmap.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Edit crushmap.txt to optimize placement</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Compile and set</span></span><br><span class="line">crushtool -c crushmap.txt -o crushmap-new.bin</span><br><span class="line">ceph osd setcrushmap -i crushmap-new.bin</span><br></pre></td></tr></table></figure>
<h2 id="data-consistency-and-replication-strategies">Data Consistency
and Replication Strategies</h2>
<h3 id="consistency-models">Consistency Models</h3>
<h4 id="strong-consistency">Strong Consistency</h4>
<p>All reads return the most recent write. Achieved through:</p>
<ul>
<li>Synchronous replication</li>
<li>Quorum-based reads/writes</li>
<li>Two-phase commit protocols</li>
</ul>
<p><strong>Trade-offs</strong>:</p>
<ul>
<li>Higher latency (wait for all replicas)</li>
<li>Lower availability (fails if quorum unavailable)</li>
<li>Higher cost (more network round-trips)</li>
</ul>
<h4 id="eventual-consistency">Eventual Consistency</h4>
<p>System will become consistent over time if no new updates.
Characteristics:</p>
<ul>
<li>Reads may return stale data temporarily</li>
<li>All replicas converge to same state eventually</li>
<li>High availability and performance</li>
</ul>
<p><strong>Use cases</strong>:</p>
<ul>
<li>Social media feeds</li>
<li>DNS systems</li>
<li>CDN content distribution</li>
</ul>
<h4 id="causal-consistency">Causal Consistency</h4>
<p>Preserves causal relationships between operations. If operation A
causally precedes operation B, all nodes see A before B.</p>
<h4 id="read-your-writes-consistency">Read-Your-Writes Consistency</h4>
<p>User always sees their own writes, even if others see stale data.</p>
<h3 id="replication-strategies">Replication Strategies</h3>
<h4 id="master-slave-replication">Master-Slave Replication</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Write Request</span><br><span class="line">    │</span><br><span class="line">    ▼</span><br><span class="line">┌─────────┐</span><br><span class="line">│ Master  │ ────┐</span><br><span class="line">└────┬────┘     │ Sync/Async</span><br><span class="line">     │          │</span><br><span class="line">     │      ┌───▼───┐</span><br><span class="line">     │      │Slave 1│</span><br><span class="line">     │      └───────┘</span><br><span class="line">     │</span><br><span class="line">     └──────┐</span><br><span class="line">            │</span><br><span class="line">       ┌────▼────┐</span><br><span class="line">       │ Slave 2 │</span><br><span class="line">       └─────────┘</span><br></pre></td></tr></table></figure>
<p><strong>Synchronous Replication</strong>:</p>
<ul>
<li>Write completes only after all replicas acknowledge</li>
<li>Strong consistency guaranteed</li>
<li>Higher latency, lower throughput</li>
</ul>
<p><strong>Asynchronous Replication</strong>:</p>
<ul>
<li>Write completes after master acknowledges</li>
<li>Better performance</li>
<li>Risk of data loss if master fails</li>
</ul>
<h4 id="multi-master-replication">Multi-Master Replication</h4>
<p>Multiple nodes can accept writes:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Write Request 1 ──┐</span><br><span class="line">                  ├──► Node 1 ──┐</span><br><span class="line">Write Request 2 ──┤             │</span><br><span class="line">                  │             ├──► Conflict Resolution</span><br><span class="line">Write Request 3 ──┘             │</span><br><span class="line">                                │</span><br><span class="line">                            Node 2 ──┐</span><br><span class="line">                                │    │</span><br><span class="line">                            Node 3 ──┘</span><br></pre></td></tr></table></figure>
<p><strong>Challenges</strong>:</p>
<ul>
<li>Conflict resolution required</li>
<li>More complex consistency models</li>
<li>Vector clocks or timestamps for ordering</li>
</ul>
<h4 id="quorum-based-replication">Quorum-Based Replication</h4>
<p>Requires majority of replicas to agree:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">QuorumReplication</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, replicas, read_quorum=<span class="literal">None</span>, write_quorum=<span class="literal">None</span></span>):</span><br><span class="line">        self.replicas = replicas</span><br><span class="line">        self.read_quorum = read_quorum <span class="keyword">or</span> (<span class="built_in">len</span>(replicas) // <span class="number">2</span> + <span class="number">1</span>)</span><br><span class="line">        self.write_quorum = write_quorum <span class="keyword">or</span> (<span class="built_in">len</span>(replicas) // <span class="number">2</span> + <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">write</span>(<span class="params">self, key, value</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Write with quorum&quot;&quot;&quot;</span></span><br><span class="line">        responses = []</span><br><span class="line">        <span class="keyword">for</span> replica <span class="keyword">in</span> self.replicas:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                result = replica.write(key, value)</span><br><span class="line">                responses.append(result)</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(responses) &gt;= self.write_quorum:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Replica <span class="subst">&#123;replica&#125;</span> failed: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(responses) &gt;= self.write_quorum</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">read</span>(<span class="params">self, key</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Read with quorum&quot;&quot;&quot;</span></span><br><span class="line">        responses = []</span><br><span class="line">        <span class="keyword">for</span> replica <span class="keyword">in</span> self.replicas:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                value = replica.read(key)</span><br><span class="line">                responses.append(value)</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(responses) &gt;= self.read_quorum:</span><br><span class="line">                    <span class="comment"># Return most recent value (by timestamp)</span></span><br><span class="line">                    <span class="keyword">return</span> <span class="built_in">max</span>(responses, key=<span class="keyword">lambda</span> x: x.timestamp)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Replica <span class="subst">&#123;replica&#125;</span> failed: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<h3 id="vector-clocks">Vector Clocks</h3>
<p>Vector clocks track causal relationships in distributed systems:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">VectorClock</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, node_id, num_nodes</span>):</span><br><span class="line">        self.node_id = node_id</span><br><span class="line">        self.clock = [<span class="number">0</span>] * num_nodes</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">tick</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Increment own clock&quot;&quot;&quot;</span></span><br><span class="line">        self.clock[self.node_id] += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, other_clock</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Update with received clock&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.clock)):</span><br><span class="line">            self.clock[i] = <span class="built_in">max</span>(self.clock[i], other_clock[i])</span><br><span class="line">        self.tick()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">happens_before</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Check if this event happens before other&quot;&quot;&quot;</span></span><br><span class="line">        less_than = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.clock)):</span><br><span class="line">            <span class="keyword">if</span> self.clock[i] &gt; other.clock[i]:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            <span class="keyword">if</span> self.clock[i] &lt; other.clock[i]:</span><br><span class="line">                less_than = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> less_than</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">concurrent</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Check if events are concurrent&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">not</span> self.happens_before(other) <span class="keyword">and</span> <span class="keyword">not</span> other.happens_before(self)</span><br></pre></td></tr></table></figure>
<h3 id="anti-entropy-and-merkle-trees">Anti-Entropy and Merkle
Trees</h3>
<p>Merkle trees efficiently detect inconsistencies:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MerkleTree</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data</span>):</span><br><span class="line">        self.data = data</span><br><span class="line">        self.root = self.build_tree(data)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">hash_data</span>(<span class="params">self, data</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Hash data&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> hashlib.sha256(<span class="built_in">str</span>(data).encode()).hexdigest()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">build_tree</span>(<span class="params">self, data</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Build Merkle tree&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(data) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> self.hash_data(data[<span class="number">0</span>])</span><br><span class="line">        </span><br><span class="line">        mid = <span class="built_in">len</span>(data) // <span class="number">2</span></span><br><span class="line">        left = self.build_tree(data[:mid])</span><br><span class="line">        right = self.build_tree(data[mid:])</span><br><span class="line">        <span class="keyword">return</span> self.hash_data(left + right)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_root_hash</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Get root hash&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.root</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compare_trees</span>(<span class="params">self, other_tree</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Compare with another tree&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.root == other_tree.root</span><br></pre></td></tr></table></figure>
<h2 id="backup-and-disaster-recovery">Backup and Disaster Recovery</h2>
<h3 id="backup-strategies">Backup Strategies</h3>
<h4 id="full-backup">Full Backup</h4>
<p>Complete copy of all data at a point in time.</p>
<p><strong>Advantages</strong>:</p>
<ul>
<li>Simple restore process</li>
<li>Complete data recovery</li>
<li>Independent of other backups</li>
</ul>
<p><strong>Disadvantages</strong>:</p>
<ul>
<li>Time-consuming</li>
<li>High storage requirements</li>
<li>Network bandwidth intensive</li>
</ul>
<h4 id="incremental-backup">Incremental Backup</h4>
<p>Only backs up changes since last backup (full or incremental).</p>
<p><strong>Advantages</strong>:</p>
<ul>
<li>Faster backup process</li>
<li>Lower storage requirements</li>
<li>Less network bandwidth</li>
</ul>
<p><strong>Disadvantages</strong>:</p>
<ul>
<li>Slower restore (requires full + all incrementals)</li>
<li>More complex restore process</li>
<li>Dependency chain</li>
</ul>
<h4 id="differential-backup">Differential Backup</h4>
<p>Backs up changes since last full backup.</p>
<p><strong>Advantages</strong>:</p>
<ul>
<li>Faster restore than incremental (only full + latest
differential)</li>
<li>Moderate storage requirements</li>
</ul>
<p><strong>Disadvantages</strong>:</p>
<ul>
<li>Slower than incremental backups</li>
<li>Storage grows over time</li>
</ul>
<h3 id="backup-implementation">Backup Implementation</h3>
<h4 id="s3-lifecycle-policies">S3 Lifecycle Policies</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> boto3</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">setup_backup_lifecycle</span>(<span class="params">bucket_name</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Setup S3 lifecycle policy for automated backups&quot;&quot;&quot;</span></span><br><span class="line">    s3_client = boto3.client(<span class="string">&#x27;s3&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    lifecycle_config = &#123;</span><br><span class="line">        <span class="string">&#x27;Rules&#x27;</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&#x27;Id&#x27;</span>: <span class="string">&#x27;DailyBackups&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;Status&#x27;</span>: <span class="string">&#x27;Enabled&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;Prefix&#x27;</span>: <span class="string">&#x27;backups/daily/&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;Transitions&#x27;</span>: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">&#x27;Days&#x27;</span>: <span class="number">30</span>,</span><br><span class="line">                        <span class="string">&#x27;StorageClass&#x27;</span>: <span class="string">&#x27;STANDARD_IA&#x27;</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">&#x27;Days&#x27;</span>: <span class="number">90</span>,</span><br><span class="line">                        <span class="string">&#x27;StorageClass&#x27;</span>: <span class="string">&#x27;GLACIER&#x27;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                ],</span><br><span class="line">                <span class="string">&#x27;Expiration&#x27;</span>: &#123;</span><br><span class="line">                    <span class="string">&#x27;Days&#x27;</span>: <span class="number">365</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&#x27;Id&#x27;</span>: <span class="string">&#x27;ArchiveOldData&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;Status&#x27;</span>: <span class="string">&#x27;Enabled&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;Prefix&#x27;</span>: <span class="string">&#x27;data/&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;Transitions&#x27;</span>: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">&#x27;Days&#x27;</span>: <span class="number">180</span>,</span><br><span class="line">                        <span class="string">&#x27;StorageClass&#x27;</span>: <span class="string">&#x27;GLACIER&#x27;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    s3_client.put_bucket_lifecycle_configuration(</span><br><span class="line">        Bucket=bucket_name,</span><br><span class="line">        LifecycleConfiguration=lifecycle_config</span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Lifecycle policy configured for <span class="subst">&#123;bucket_name&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="automated-backup-script">Automated Backup Script</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tarfile</span><br><span class="line"><span class="keyword">import</span> boto3</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BackupManager</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, s3_bucket, backup_prefix=<span class="string">&#x27;backups&#x27;</span></span>):</span><br><span class="line">        self.s3_client = boto3.client(<span class="string">&#x27;s3&#x27;</span>)</span><br><span class="line">        self.bucket = s3_bucket</span><br><span class="line">        self.prefix = backup_prefix</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_backup</span>(<span class="params">self, source_paths, backup_name=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Create compressed backup&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> backup_name <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            backup_name = <span class="string">f&quot;backup_<span class="subst">&#123;datetime.now().strftime(<span class="string">&#x27;%Y%m%d_%H%M%S&#x27;</span>)&#125;</span>.tar.gz&quot;</span></span><br><span class="line">        </span><br><span class="line">        backup_path = <span class="string">f&quot;/tmp/<span class="subst">&#123;backup_name&#125;</span>&quot;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Create tar archive</span></span><br><span class="line">        <span class="keyword">with</span> tarfile.<span class="built_in">open</span>(backup_path, <span class="string">&#x27;w:gz&#x27;</span>) <span class="keyword">as</span> tar:</span><br><span class="line">            <span class="keyword">for</span> path <span class="keyword">in</span> source_paths:</span><br><span class="line">                <span class="keyword">if</span> os.path.isfile(path):</span><br><span class="line">                    tar.add(path, arcname=os.path.basename(path))</span><br><span class="line">                <span class="keyword">elif</span> os.path.isdir(path):</span><br><span class="line">                    tar.add(path, arcname=os.path.basename(path))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Upload to S3</span></span><br><span class="line">        s3_key = <span class="string">f&quot;<span class="subst">&#123;self.prefix&#125;</span>/<span class="subst">&#123;backup_name&#125;</span>&quot;</span></span><br><span class="line">        self.s3_client.upload_file(</span><br><span class="line">            backup_path,</span><br><span class="line">            self.bucket,</span><br><span class="line">            s3_key,</span><br><span class="line">            ExtraArgs=&#123;<span class="string">&#x27;StorageClass&#x27;</span>: <span class="string">&#x27;STANDARD_IA&#x27;</span>&#125;</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Cleanup</span></span><br><span class="line">        os.remove(backup_path)</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Backup created: <span class="subst">&#123;s3_key&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> s3_key</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">restore_backup</span>(<span class="params">self, s3_key, restore_path</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Restore backup from S3&quot;&quot;&quot;</span></span><br><span class="line">        backup_file = <span class="string">f&quot;/tmp/<span class="subst">&#123;os.path.basename(s3_key)&#125;</span>&quot;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Download from S3</span></span><br><span class="line">        self.s3_client.download_file(self.bucket, s3_key, backup_file)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Extract</span></span><br><span class="line">        <span class="keyword">with</span> tarfile.<span class="built_in">open</span>(backup_file, <span class="string">&#x27;r:gz&#x27;</span>) <span class="keyword">as</span> tar:</span><br><span class="line">            tar.extractall(restore_path)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Cleanup</span></span><br><span class="line">        os.remove(backup_file)</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Backup restored to: <span class="subst">&#123;restore_path&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Usage</span></span><br><span class="line">backup_mgr = BackupManager(<span class="string">&#x27;my-backup-bucket&#x27;</span>)</span><br><span class="line">backup_mgr.create_backup([<span class="string">&#x27;/var/www&#x27;</span>, <span class="string">&#x27;/etc/nginx&#x27;</span>])</span><br></pre></td></tr></table></figure>
<h3 id="disaster-recovery-strategies">Disaster Recovery Strategies</h3>
<h4 id="rto-and-rpo">RTO and RPO</h4>
<ul>
<li><strong>RTO (Recovery Time Objective)</strong>: Maximum acceptable
downtime</li>
<li><strong>RPO (Recovery Point Objective)</strong>: Maximum acceptable
data loss</li>
</ul>
<table>
<thead>
<tr>
<th>Strategy</th>
<th>RTO</th>
<th>RPO</th>
<th>Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hot standby</td>
<td>Minutes</td>
<td>Seconds</td>
<td>Very High</td>
</tr>
<tr>
<td>Warm standby</td>
<td>Hours</td>
<td>Minutes</td>
<td>High</td>
</tr>
<tr>
<td>Cold standby</td>
<td>Days</td>
<td>Hours</td>
<td>Moderate</td>
</tr>
<tr>
<td>Backup only</td>
<td>Days</td>
<td>Days</td>
<td>Low</td>
</tr>
</tbody>
</table>
<h4 id="multi-region-replication">Multi-Region Replication</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> boto3</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiRegionReplication</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, primary_region, replica_regions</span>):</span><br><span class="line">        self.primary_region = primary_region</span><br><span class="line">        self.replica_regions = replica_regions</span><br><span class="line">        self.primary_s3 = boto3.client(<span class="string">&#x27;s3&#x27;</span>, region_name=primary_region)</span><br><span class="line">        self.replica_clients = &#123;</span><br><span class="line">            region: boto3.client(<span class="string">&#x27;s3&#x27;</span>, region_name=region)</span><br><span class="line">            <span class="keyword">for</span> region <span class="keyword">in</span> replica_regions</span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">setup_cross_region_replication</span>(<span class="params">self, bucket_name</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Setup cross-region replication&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> region <span class="keyword">in</span> self.replica_regions:</span><br><span class="line">            replica_bucket = <span class="string">f&quot;<span class="subst">&#123;bucket_name&#125;</span>-<span class="subst">&#123;region&#125;</span>&quot;</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Create replica bucket</span></span><br><span class="line">            self.replica_clients[region].create_bucket(</span><br><span class="line">                Bucket=replica_bucket,</span><br><span class="line">                CreateBucketConfiguration=&#123;<span class="string">&#x27;LocationConstraint&#x27;</span>: region&#125;</span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Enable versioning</span></span><br><span class="line">            self.primary_s3.put_bucket_versioning(</span><br><span class="line">                Bucket=bucket_name,</span><br><span class="line">                VersioningConfiguration=&#123;<span class="string">&#x27;Status&#x27;</span>: <span class="string">&#x27;Enabled&#x27;</span>&#125;</span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            self.replica_clients[region].put_bucket_versioning(</span><br><span class="line">                Bucket=replica_bucket,</span><br><span class="line">                VersioningConfiguration=&#123;<span class="string">&#x27;Status&#x27;</span>: <span class="string">&#x27;Enabled&#x27;</span>&#125;</span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Configure replication</span></span><br><span class="line">            replication_config = &#123;</span><br><span class="line">                <span class="string">&#x27;Role&#x27;</span>: <span class="string">&#x27;arn:aws:iam::account:role/replication-role&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;Rules&#x27;</span>: [&#123;</span><br><span class="line">                    <span class="string">&#x27;Status&#x27;</span>: <span class="string">&#x27;Enabled&#x27;</span>,</span><br><span class="line">                    <span class="string">&#x27;Priority&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">                    <span class="string">&#x27;Destination&#x27;</span>: &#123;</span><br><span class="line">                        <span class="string">&#x27;Bucket&#x27;</span>: <span class="string">f&#x27;arn:aws:s3:::<span class="subst">&#123;replica_bucket&#125;</span>&#x27;</span>,</span><br><span class="line">                        <span class="string">&#x27;StorageClass&#x27;</span>: <span class="string">&#x27;STANDARD&#x27;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;]</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            self.primary_s3.put_bucket_replication(</span><br><span class="line">                Bucket=bucket_name,</span><br><span class="line">                ReplicationConfiguration=replication_config</span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Replication configured: <span class="subst">&#123;bucket_name&#125;</span> -&gt; <span class="subst">&#123;replica_bucket&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Usage</span></span><br><span class="line">replication = MultiRegionReplication(</span><br><span class="line">    primary_region=<span class="string">&#x27;us-east-1&#x27;</span>,</span><br><span class="line">    replica_regions=[<span class="string">&#x27;us-west-2&#x27;</span>, <span class="string">&#x27;eu-west-1&#x27;</span>]</span><br><span class="line">)</span><br><span class="line">replication.setup_cross_region_replication(<span class="string">&#x27;my-data-bucket&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="storage-performance-optimization">Storage Performance
Optimization</h2>
<h3 id="performance-metrics">Performance Metrics</h3>
<p>Key metrics for storage systems:</p>
<ul>
<li><strong>IOPS (Input/Output Operations Per Second)</strong>: Number
of read/write operations per second</li>
<li><strong>Throughput</strong>: Data transfer rate (MB/s, GB/s)</li>
<li><strong>Latency</strong>: Time to complete a single operation
(ms)</li>
<li><strong>Bandwidth</strong>: Maximum data transfer capacity</li>
</ul>
<h3 id="optimization-techniques">Optimization Techniques</h3>
<h4 id="caching-strategies">Caching Strategies</h4>
<p><strong>Read Cache</strong>:</p>
<ul>
<li>Frequently accessed data stored in faster storage (RAM, SSD)</li>
<li>Reduces latency for hot data</li>
<li>LRU (Least Recently Used) eviction policy</li>
</ul>
<p><strong>Write Cache</strong>:</p>
<ul>
<li>Buffer writes before committing to persistent storage</li>
<li>Improves write throughput</li>
<li>Risk of data loss if cache fails</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LRUCache</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, capacity</span>):</span><br><span class="line">        self.cache = OrderedDict()</span><br><span class="line">        self.capacity = capacity</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get</span>(<span class="params">self, key</span>):</span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">not</span> <span class="keyword">in</span> self.cache:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="comment"># Move to end (most recently used)</span></span><br><span class="line">        self.cache.move_to_end(key)</span><br><span class="line">        <span class="keyword">return</span> self.cache[key]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">put</span>(<span class="params">self, key, value</span>):</span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">in</span> self.cache:</span><br><span class="line">            self.cache.move_to_end(key)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(self.cache) &gt;= self.capacity:</span><br><span class="line">                <span class="comment"># Remove least recently used</span></span><br><span class="line">                self.cache.popitem(last=<span class="literal">False</span>)</span><br><span class="line">        self.cache[key] = value</span><br></pre></td></tr></table></figure>
<h4 id="data-locality">Data Locality</h4>
<p>Place data close to computation:</p>
<ul>
<li><strong>HDFS</strong>: Data stored on same nodes as compute
tasks</li>
<li><strong>S3 Select</strong>: Push-down predicates to storage
layer</li>
<li><strong>Edge caching</strong>: CDN placement near users</li>
</ul>
<h4 id="compression">Compression</h4>
<p>Reduce storage and transfer costs:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"><span class="keyword">import</span> bz2</span><br><span class="line"><span class="keyword">import</span> lzma</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CompressionManager</span>:</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compress_gzip</span>(<span class="params">data</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Compress with gzip&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> gzip.compress(data)</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decompress_gzip</span>(<span class="params">compressed_data</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Decompress gzip&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> gzip.decompress(compressed_data)</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compress_bz2</span>(<span class="params">data</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Compress with bzip2&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> bz2.compress(data)</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compress_lzma</span>(<span class="params">data</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Compress with LZMA&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> lzma.compress(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compression ratios (typical)</span></span><br><span class="line"><span class="comment"># gzip: 2-4x</span></span><br><span class="line"><span class="comment"># bzip2: 3-5x</span></span><br><span class="line"><span class="comment"># lzma: 4-6x</span></span><br></pre></td></tr></table></figure>
<h4 id="parallel-io">Parallel I/O</h4>
<p>Distribute I/O across multiple streams:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> concurrent.futures</span><br><span class="line"><span class="keyword">import</span> boto3</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ParallelS3Upload</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, bucket_name, max_workers=<span class="number">10</span></span>):</span><br><span class="line">        self.s3_client = boto3.client(<span class="string">&#x27;s3&#x27;</span>)</span><br><span class="line">        self.bucket = bucket_name</span><br><span class="line">        self.max_workers = max_workers</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">upload_file_part</span>(<span class="params">self, file_path, object_key, part_number, part_size, offset</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Upload a single part&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.seek(offset)</span><br><span class="line">            data = f.read(part_size)</span><br><span class="line">        </span><br><span class="line">        response = self.s3_client.upload_part(</span><br><span class="line">            Bucket=self.bucket,</span><br><span class="line">            Key=object_key,</span><br><span class="line">            PartNumber=part_number,</span><br><span class="line">            UploadId=self.upload_id,</span><br><span class="line">            Body=data</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&#x27;PartNumber&#x27;</span>: part_number, <span class="string">&#x27;ETag&#x27;</span>: response[<span class="string">&#x27;ETag&#x27;</span>]&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">upload_large_file</span>(<span class="params">self, file_path, object_key, part_size_mb=<span class="number">5</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Upload large file using multipart upload&quot;&quot;&quot;</span></span><br><span class="line">        file_size = os.path.getsize(file_path)</span><br><span class="line">        part_size = part_size_mb * <span class="number">1024</span> * <span class="number">1024</span></span><br><span class="line">        num_parts = (file_size + part_size - <span class="number">1</span>) // part_size</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Initiate multipart upload</span></span><br><span class="line">        response = self.s3_client.create_multipart_upload(</span><br><span class="line">            Bucket=self.bucket,</span><br><span class="line">            Key=object_key</span><br><span class="line">        )</span><br><span class="line">        self.upload_id = response[<span class="string">&#x27;UploadId&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Upload parts in parallel</span></span><br><span class="line">        parts = []</span><br><span class="line">        <span class="keyword">with</span> concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) <span class="keyword">as</span> executor:</span><br><span class="line">            futures = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_parts):</span><br><span class="line">                offset = i * part_size</span><br><span class="line">                future = executor.submit(</span><br><span class="line">                    self.upload_file_part,</span><br><span class="line">                    file_path, object_key, i + <span class="number">1</span>, part_size, offset</span><br><span class="line">                )</span><br><span class="line">                futures.append(future)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> future <span class="keyword">in</span> concurrent.futures.as_completed(futures):</span><br><span class="line">                parts.append(future.result())</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Complete multipart upload</span></span><br><span class="line">        parts.sort(key=<span class="keyword">lambda</span> x: x[<span class="string">&#x27;PartNumber&#x27;</span>])</span><br><span class="line">        self.s3_client.complete_multipart_upload(</span><br><span class="line">            Bucket=self.bucket,</span><br><span class="line">            Key=object_key,</span><br><span class="line">            UploadId=self.upload_id,</span><br><span class="line">            MultipartUpload=&#123;<span class="string">&#x27;Parts&#x27;</span>: parts&#125;</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Uploaded <span class="subst">&#123;object_key&#125;</span> (<span class="subst">&#123;file_size&#125;</span> bytes)&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="benchmarking-storage-performance">Benchmarking Storage
Performance</h3>
<h4 id="s3-performance-test">S3 Performance Test</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> boto3</span><br><span class="line"><span class="keyword">import</span> statistics</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">S3PerformanceBenchmark</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, bucket_name</span>):</span><br><span class="line">        self.s3_client = boto3.client(<span class="string">&#x27;s3&#x27;</span>)</span><br><span class="line">        self.bucket = bucket_name</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">benchmark_write</span>(<span class="params">self, object_key, data_size_kb, num_iterations=<span class="number">100</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Benchmark write performance&quot;&quot;&quot;</span></span><br><span class="line">        data = <span class="string">b&#x27;x&#x27;</span> * (data_size_kb * <span class="number">1024</span>)</span><br><span class="line">        latencies = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_iterations):</span><br><span class="line">            key = <span class="string">f&quot;<span class="subst">&#123;object_key&#125;</span>_<span class="subst">&#123;i&#125;</span>&quot;</span></span><br><span class="line">            start = time.time()</span><br><span class="line">            self.s3_client.put_object(Bucket=self.bucket, Key=key, Body=data)</span><br><span class="line">            latency = (time.time() - start) * <span class="number">1000</span>  <span class="comment"># ms</span></span><br><span class="line">            latencies.append(latency)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&#x27;avg_latency_ms&#x27;</span>: statistics.mean(latencies),</span><br><span class="line">            <span class="string">&#x27;p50_latency_ms&#x27;</span>: statistics.median(latencies),</span><br><span class="line">            <span class="string">&#x27;p99_latency_ms&#x27;</span>: statistics.quantiles(latencies, n=<span class="number">100</span>)[<span class="number">98</span>],</span><br><span class="line">            <span class="string">&#x27;throughput_mbps&#x27;</span>: (data_size_kb * num_iterations * <span class="number">8</span>) / (<span class="built_in">sum</span>(latencies) / <span class="number">1000</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">benchmark_read</span>(<span class="params">self, object_key_prefix, num_iterations=<span class="number">100</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Benchmark read performance&quot;&quot;&quot;</span></span><br><span class="line">        latencies = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_iterations):</span><br><span class="line">            key = <span class="string">f&quot;<span class="subst">&#123;object_key_prefix&#125;</span>_<span class="subst">&#123;i&#125;</span>&quot;</span></span><br><span class="line">            start = time.time()</span><br><span class="line">            response = self.s3_client.get_object(Bucket=self.bucket, Key=key)</span><br><span class="line">            data = response[<span class="string">&#x27;Body&#x27;</span>].read()</span><br><span class="line">            latency = (time.time() - start) * <span class="number">1000</span>  <span class="comment"># ms</span></span><br><span class="line">            latencies.append(latency)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&#x27;avg_latency_ms&#x27;</span>: statistics.mean(latencies),</span><br><span class="line">            <span class="string">&#x27;p50_latency_ms&#x27;</span>: statistics.median(latencies),</span><br><span class="line">            <span class="string">&#x27;p99_latency_ms&#x27;</span>: statistics.quantiles(latencies, n=<span class="number">100</span>)[<span class="number">98</span>]</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Usage</span></span><br><span class="line">benchmark = S3PerformanceBenchmark(<span class="string">&#x27;test-bucket&#x27;</span>)</span><br><span class="line">write_stats = benchmark.benchmark_write(<span class="string">&#x27;test-object&#x27;</span>, data_size_kb=<span class="number">1024</span>)</span><br><span class="line">read_stats = benchmark.benchmark_read(<span class="string">&#x27;test-object&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Write: <span class="subst">&#123;write_stats&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Read: <span class="subst">&#123;read_stats&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="cost-optimization-strategies">Cost Optimization Strategies</h2>
<h3 id="storage-cost-factors">Storage Cost Factors</h3>
<ol type="1">
<li><strong>Storage volume</strong>: Amount of data stored</li>
<li><strong>Storage class</strong>: Performance tier (Standard, IA,
Glacier)</li>
<li><strong>Request costs</strong>: PUT, GET, LIST operations</li>
<li><strong>Data transfer</strong>: Egress bandwidth</li>
<li><strong>Lifecycle management</strong>: Automated tiering</li>
</ol>
<h3 id="optimization-techniques-1">Optimization Techniques</h3>
<h4 id="lifecycle-management">Lifecycle Management</h4>
<p>Automatically move data to cheaper storage classes:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">optimize_storage_lifecycle</span>(<span class="params">bucket_name</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Setup cost-optimized lifecycle policy&quot;&quot;&quot;</span></span><br><span class="line">    s3_client = boto3.client(<span class="string">&#x27;s3&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    lifecycle_config = &#123;</span><br><span class="line">        <span class="string">&#x27;Rules&#x27;</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&#x27;Id&#x27;</span>: <span class="string">&#x27;MoveToIA&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;Status&#x27;</span>: <span class="string">&#x27;Enabled&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;Prefix&#x27;</span>: <span class="string">&#x27;data/&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;Transitions&#x27;</span>: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">&#x27;Days&#x27;</span>: <span class="number">30</span>,</span><br><span class="line">                        <span class="string">&#x27;StorageClass&#x27;</span>: <span class="string">&#x27;STANDARD_IA&#x27;</span>  <span class="comment"># 50% cheaper</span></span><br><span class="line">                    &#125;</span><br><span class="line">                ]</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&#x27;Id&#x27;</span>: <span class="string">&#x27;MoveToGlacier&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;Status&#x27;</span>: <span class="string">&#x27;Enabled&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;Prefix&#x27;</span>: <span class="string">&#x27;archive/&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;Transitions&#x27;</span>: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">&#x27;Days&#x27;</span>: <span class="number">90</span>,</span><br><span class="line">                        <span class="string">&#x27;StorageClass&#x27;</span>: <span class="string">&#x27;GLACIER&#x27;</span>  <span class="comment"># 80% cheaper</span></span><br><span class="line">                    &#125;</span><br><span class="line">                ]</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&#x27;Id&#x27;</span>: <span class="string">&#x27;DeleteOldVersions&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;Status&#x27;</span>: <span class="string">&#x27;Enabled&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;NoncurrentVersionTransitions&#x27;</span>: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="string">&#x27;NoncurrentDays&#x27;</span>: <span class="number">30</span>,</span><br><span class="line">                        <span class="string">&#x27;StorageClass&#x27;</span>: <span class="string">&#x27;GLACIER&#x27;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                ],</span><br><span class="line">                <span class="string">&#x27;NoncurrentVersionExpiration&#x27;</span>: &#123;</span><br><span class="line">                    <span class="string">&#x27;NoncurrentDays&#x27;</span>: <span class="number">365</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    s3_client.put_bucket_lifecycle_configuration(</span><br><span class="line">        Bucket=bucket_name,</span><br><span class="line">        LifecycleConfiguration=lifecycle_config</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<h4 id="deduplication">Deduplication</h4>
<p>Eliminate duplicate data:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DeduplicationManager</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, storage_backend</span>):</span><br><span class="line">        self.storage = storage_backend</span><br><span class="line">        self.content_hash_index = &#123;&#125;  <span class="comment"># hash -&gt; object_key</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">store_with_dedup</span>(<span class="params">self, data, object_key</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Store object with deduplication&quot;&quot;&quot;</span></span><br><span class="line">        content_hash = hashlib.sha256(data).hexdigest()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> content_hash <span class="keyword">in</span> self.content_hash_index:</span><br><span class="line">            <span class="comment"># Create reference instead of storing duplicate</span></span><br><span class="line">            existing_key = self.content_hash_index[content_hash]</span><br><span class="line">            self.storage.create_reference(object_key, existing_key)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Deduplicated: <span class="subst">&#123;object_key&#125;</span> -&gt; <span class="subst">&#123;existing_key&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># Store new object</span></span><br><span class="line">            self.storage.put_object(object_key, data)</span><br><span class="line">            self.content_hash_index[content_hash] = object_key</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Stored: <span class="subst">&#123;object_key&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="compression-analysis">Compression Analysis</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">analyze_compression_savings</span>(<span class="params">file_paths</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Analyze potential savings from compression&quot;&quot;&quot;</span></span><br><span class="line">    total_original = <span class="number">0</span></span><br><span class="line">    total_compressed = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> file_path <span class="keyword">in</span> file_paths:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            original_data = f.read()</span><br><span class="line">            compressed_data = gzip.compress(original_data)</span><br><span class="line">            </span><br><span class="line">            original_size = <span class="built_in">len</span>(original_data)</span><br><span class="line">            compressed_size = <span class="built_in">len</span>(compressed_data)</span><br><span class="line">            </span><br><span class="line">            total_original += original_size</span><br><span class="line">            total_compressed += compressed_size</span><br><span class="line">            </span><br><span class="line">            savings = (<span class="number">1</span> - compressed_size / original_size) * <span class="number">100</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;file_path&#125;</span>: <span class="subst">&#123;original_size&#125;</span> -&gt; <span class="subst">&#123;compressed_size&#125;</span> bytes (<span class="subst">&#123;savings:<span class="number">.1</span>f&#125;</span>% savings)&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    total_savings = (<span class="number">1</span> - total_compressed / total_original) * <span class="number">100</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\nTotal: <span class="subst">&#123;total_original&#125;</span> -&gt; <span class="subst">&#123;total_compressed&#125;</span> bytes (<span class="subst">&#123;total_savings:<span class="number">.1</span>f&#125;</span>% savings)&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="cost-calculator">Cost Calculator</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">StorageCostCalculator</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># AWS S3 pricing (example, adjust for your region)</span></span><br><span class="line">        self.pricing = &#123;</span><br><span class="line">            <span class="string">&#x27;STANDARD&#x27;</span>: &#123;<span class="string">&#x27;storage&#x27;</span>: <span class="number">0.023</span>, <span class="string">&#x27;requests&#x27;</span>: <span class="number">0.0004</span>&#125;,  <span class="comment"># per GB/month, per 1000 requests</span></span><br><span class="line">            <span class="string">&#x27;STANDARD_IA&#x27;</span>: &#123;<span class="string">&#x27;storage&#x27;</span>: <span class="number">0.0125</span>, <span class="string">&#x27;requests&#x27;</span>: <span class="number">0.001</span>&#125;,</span><br><span class="line">            <span class="string">&#x27;GLACIER&#x27;</span>: &#123;<span class="string">&#x27;storage&#x27;</span>: <span class="number">0.004</span>, <span class="string">&#x27;retrieval&#x27;</span>: <span class="number">0.01</span>&#125;,  <span class="comment"># per GB retrieval</span></span><br><span class="line">            <span class="string">&#x27;data_transfer_out&#x27;</span>: <span class="number">0.09</span>  <span class="comment"># per GB</span></span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">calculate_monthly_cost</span>(<span class="params">self, storage_gb, storage_class=<span class="string">&#x27;STANDARD&#x27;</span>, </span></span><br><span class="line"><span class="params">                              requests=<span class="number">0</span>, data_transfer_gb=<span class="number">0</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Calculate monthly storage cost&quot;&quot;&quot;</span></span><br><span class="line">        storage_cost = storage_gb * self.pricing[storage_class][<span class="string">&#x27;storage&#x27;</span>]</span><br><span class="line">        request_cost = (requests / <span class="number">1000</span>) * self.pricing[storage_class][<span class="string">&#x27;requests&#x27;</span>]</span><br><span class="line">        transfer_cost = data_transfer_gb * self.pricing[<span class="string">&#x27;data_transfer_out&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        total = storage_cost + request_cost + transfer_cost</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&#x27;storage_cost&#x27;</span>: storage_cost,</span><br><span class="line">            <span class="string">&#x27;request_cost&#x27;</span>: request_cost,</span><br><span class="line">            <span class="string">&#x27;transfer_cost&#x27;</span>: transfer_cost,</span><br><span class="line">            <span class="string">&#x27;total_cost&#x27;</span>: total</span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compare_storage_classes</span>(<span class="params">self, storage_gb, requests=<span class="number">0</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Compare costs across storage classes&quot;&quot;&quot;</span></span><br><span class="line">        results = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> storage_class <span class="keyword">in</span> [<span class="string">&#x27;STANDARD&#x27;</span>, <span class="string">&#x27;STANDARD_IA&#x27;</span>, <span class="string">&#x27;GLACIER&#x27;</span>]:</span><br><span class="line">            results[storage_class] = self.calculate_monthly_cost(</span><br><span class="line">                storage_gb, storage_class, requests</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line"><span class="comment"># Usage</span></span><br><span class="line">calculator = StorageCostCalculator()</span><br><span class="line">costs = calculator.compare_storage_classes(storage_gb=<span class="number">1000</span>, requests=<span class="number">100000</span>)</span><br><span class="line"><span class="keyword">for</span> class_name, cost_info <span class="keyword">in</span> costs.items():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;class_name&#125;</span>: $<span class="subst">&#123;cost_info[<span class="string">&#x27;total_cost&#x27;</span>]:<span class="number">.2</span>f&#125;</span>/month&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="case-studies">Case Studies</h2>
<h3 id="case-study-1-e-commerce-platform-migration">Case Study 1:
E-Commerce Platform Migration</h3>
<p><strong>Scenario</strong>: A large e-commerce platform needs to
migrate from on-premises storage to cloud object storage.</p>
<p><strong>Requirements</strong>:</p>
<ul>
<li>50TB of product images and videos</li>
<li>10 million objects</li>
<li>Global CDN integration</li>
<li>99.99% availability</li>
<li>Cost optimization</li>
</ul>
<p><strong>Solution</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ECommerceStorageMigration</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, source_path, s3_bucket, cdn_distribution_id</span>):</span><br><span class="line">        self.source_path = source_path</span><br><span class="line">        self.s3_bucket = s3_bucket</span><br><span class="line">        self.cdn_id = cdn_distribution_id</span><br><span class="line">        self.s3_client = boto3.client(<span class="string">&#x27;s3&#x27;</span>)</span><br><span class="line">        self.cloudfront = boto3.client(<span class="string">&#x27;cloudfront&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">migrate_with_optimization</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Migrate with storage class optimization&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Images: Standard (frequently accessed)</span></span><br><span class="line">        <span class="comment"># Videos: Standard-IA (less frequent)</span></span><br><span class="line">        <span class="comment"># Old products: Glacier (archive)</span></span><br><span class="line">        </span><br><span class="line">        image_extensions = [<span class="string">&#x27;.jpg&#x27;</span>, <span class="string">&#x27;.jpeg&#x27;</span>, <span class="string">&#x27;.png&#x27;</span>, <span class="string">&#x27;.gif&#x27;</span>, <span class="string">&#x27;.webp&#x27;</span>]</span><br><span class="line">        video_extensions = [<span class="string">&#x27;.mp4&#x27;</span>, <span class="string">&#x27;.webm&#x27;</span>, <span class="string">&#x27;.mov&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(self.source_path):</span><br><span class="line">            <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">                file_path = os.path.join(root, file)</span><br><span class="line">                relative_path = os.path.relpath(file_path, self.source_path)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># Determine storage class</span></span><br><span class="line">                ext = os.path.splitext(file)[<span class="number">1</span>].lower()</span><br><span class="line">                <span class="keyword">if</span> ext <span class="keyword">in</span> image_extensions:</span><br><span class="line">                    storage_class = <span class="string">&#x27;STANDARD&#x27;</span></span><br><span class="line">                    prefix = <span class="string">&#x27;images/&#x27;</span></span><br><span class="line">                <span class="keyword">elif</span> ext <span class="keyword">in</span> video_extensions:</span><br><span class="line">                    storage_class = <span class="string">&#x27;STANDARD_IA&#x27;</span></span><br><span class="line">                    prefix = <span class="string">&#x27;videos/&#x27;</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    storage_class = <span class="string">&#x27;STANDARD&#x27;</span></span><br><span class="line">                    prefix = <span class="string">&#x27;assets/&#x27;</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment"># Upload with appropriate storage class</span></span><br><span class="line">                self.s3_client.upload_file(</span><br><span class="line">                    file_path,</span><br><span class="line">                    self.s3_bucket,</span><br><span class="line">                    <span class="string">f&quot;<span class="subst">&#123;prefix&#125;</span><span class="subst">&#123;relative_path&#125;</span>&quot;</span>,</span><br><span class="line">                    ExtraArgs=&#123;<span class="string">&#x27;StorageClass&#x27;</span>: storage_class&#125;</span><br><span class="line">                )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Setup lifecycle policies</span></span><br><span class="line">        self.setup_lifecycle_policies()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Invalidate CDN cache</span></span><br><span class="line">        self.cloudfront.create_invalidation(</span><br><span class="line">            DistributionId=self.cdn_id,</span><br><span class="line">            InvalidationBatch=&#123;</span><br><span class="line">                <span class="string">&#x27;Paths&#x27;</span>: &#123;<span class="string">&#x27;Quantity&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;Items&#x27;</span>: [<span class="string">&#x27;/*&#x27;</span>]&#125;,</span><br><span class="line">                <span class="string">&#x27;CallerReference&#x27;</span>: <span class="built_in">str</span>(time.time())</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">setup_lifecycle_policies</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Setup automated lifecycle management&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Move old images to IA after 90 days</span></span><br><span class="line">        <span class="comment"># Archive videos after 180 days</span></span><br><span class="line">        lifecycle_config = &#123;</span><br><span class="line">            <span class="string">&#x27;Rules&#x27;</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="string">&#x27;Id&#x27;</span>: <span class="string">&#x27;ImageLifecycle&#x27;</span>,</span><br><span class="line">                    <span class="string">&#x27;Status&#x27;</span>: <span class="string">&#x27;Enabled&#x27;</span>,</span><br><span class="line">                    <span class="string">&#x27;Prefix&#x27;</span>: <span class="string">&#x27;images/&#x27;</span>,</span><br><span class="line">                    <span class="string">&#x27;Transitions&#x27;</span>: [</span><br><span class="line">                        &#123;<span class="string">&#x27;Days&#x27;</span>: <span class="number">90</span>, <span class="string">&#x27;StorageClass&#x27;</span>: <span class="string">&#x27;STANDARD_IA&#x27;</span>&#125;,</span><br><span class="line">                        &#123;<span class="string">&#x27;Days&#x27;</span>: <span class="number">365</span>, <span class="string">&#x27;StorageClass&#x27;</span>: <span class="string">&#x27;GLACIER&#x27;</span>&#125;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="string">&#x27;Id&#x27;</span>: <span class="string">&#x27;VideoLifecycle&#x27;</span>,</span><br><span class="line">                    <span class="string">&#x27;Status&#x27;</span>: <span class="string">&#x27;Enabled&#x27;</span>,</span><br><span class="line">                    <span class="string">&#x27;Prefix&#x27;</span>: <span class="string">&#x27;videos/&#x27;</span>,</span><br><span class="line">                    <span class="string">&#x27;Transitions&#x27;</span>: [</span><br><span class="line">                        &#123;<span class="string">&#x27;Days&#x27;</span>: <span class="number">180</span>, <span class="string">&#x27;StorageClass&#x27;</span>: <span class="string">&#x27;GLACIER&#x27;</span>&#125;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        self.s3_client.put_bucket_lifecycle_configuration(</span><br><span class="line">            Bucket=self.s3_bucket,</span><br><span class="line">            LifecycleConfiguration=lifecycle_config</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"><span class="comment"># Results:</span></span><br><span class="line"><span class="comment"># - Migration completed in 2 weeks</span></span><br><span class="line"><span class="comment"># - 40% cost reduction vs on-premises</span></span><br><span class="line"><span class="comment"># - 99.99% availability achieved</span></span><br><span class="line"><span class="comment"># - CDN integration reduced latency by 60%</span></span><br></pre></td></tr></table></figure>
<h3 id="case-study-2-big-data-analytics-platform">Case Study 2: Big Data
Analytics Platform</h3>
<p><strong>Scenario</strong>: A company needs distributed storage for
Hadoop-based analytics workloads processing 100TB daily.</p>
<p><strong>Requirements</strong>:</p>
<ul>
<li>HDFS cluster for Hadoop workloads</li>
<li>High throughput for MapReduce jobs</li>
<li>Fault tolerance (3x replication)</li>
<li>Integration with S3 for archival</li>
</ul>
<p><strong>Solution</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BigDataStorageArchitecture</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.hdfs_cluster = <span class="literal">None</span></span><br><span class="line">        self.s3_archive_bucket = <span class="string">&#x27;analytics-archive&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">setup_hdfs_cluster</span>(<span class="params">self, namenodes, datanodes</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Setup HDFS cluster configuration&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># NameNode HA configuration</span></span><br><span class="line">        hdfs_config = &#123;</span><br><span class="line">            <span class="string">&#x27;dfs.nameservices&#x27;</span>: <span class="string">&#x27;analytics-cluster&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;dfs.ha.namenodes.analytics-cluster&#x27;</span>: <span class="string">&#x27;nn1,nn2&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;dfs.replication&#x27;</span>: <span class="number">3</span>,</span><br><span class="line">            <span class="string">&#x27;dfs.blocksize&#x27;</span>: <span class="number">268435456</span>,  <span class="comment"># 256MB for large files</span></span><br><span class="line">            <span class="string">&#x27;dfs.namenode.handler.count&#x27;</span>: <span class="number">200</span>,  <span class="comment"># High concurrency</span></span><br><span class="line">            <span class="string">&#x27;dfs.datanode.max.xcievers&#x27;</span>: <span class="number">4096</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># DataNode optimization</span></span><br><span class="line">        datanode_config = &#123;</span><br><span class="line">            <span class="string">&#x27;dfs.datanode.data.dir&#x27;</span>: <span class="string">&#x27;/data1,/data2,/data3&#x27;</span>,  <span class="comment"># Multiple disks</span></span><br><span class="line">            <span class="string">&#x27;dfs.datanode.balance.bandwidthPerSec&#x27;</span>: <span class="number">104857600</span>  <span class="comment"># 100MB/s</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> &#123;**hdfs_config, **datanode_config&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">archive_to_s3</span>(<span class="params">self, hdfs_path, retention_days=<span class="number">90</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Archive old data from HDFS to S3&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># DistCp for efficient transfer</span></span><br><span class="line">        distcp_command = <span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        hadoop distcp \</span></span><br><span class="line"><span class="string">            -D fs.s3a.access.key=$AWS_ACCESS_KEY \</span></span><br><span class="line"><span class="string">            -D fs.s3a.secret.key=$AWS_SECRET_KEY \</span></span><br><span class="line"><span class="string">            hdfs://namenode:9000<span class="subst">&#123;hdfs_path&#125;</span> \</span></span><br><span class="line"><span class="string">            s3a://<span class="subst">&#123;self.s3_archive_bucket&#125;</span>/archive/</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># After successful copy, delete from HDFS</span></span><br><span class="line">        <span class="comment"># hdfs dfs -rm -r &#123;hdfs_path&#125;</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> distcp_command</span><br><span class="line"></span><br><span class="line"><span class="comment"># Results:</span></span><br><span class="line"><span class="comment"># - 3x replication provides 99.9% durability</span></span><br><span class="line"><span class="comment"># - 256MB blocks optimized for large files</span></span><br><span class="line"><span class="comment"># - S3 archival reduces HDFS storage by 70%</span></span><br><span class="line"><span class="comment"># - DistCp enables efficient bulk transfers</span></span><br></pre></td></tr></table></figure>
<h3 id="case-study-3-multi-region-content-delivery">Case Study 3:
Multi-Region Content Delivery</h3>
<p><strong>Scenario</strong>: A media streaming service needs to serve
content globally with low latency and high availability.</p>
<p><strong>Requirements</strong>:</p>
<ul>
<li>Content stored in multiple regions</li>
<li>Automatic failover</li>
<li>Low latency for global users</li>
<li>Cost-effective storage</li>
</ul>
<p><strong>Solution</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MultiRegionContentDelivery</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, primary_region=<span class="string">&#x27;us-east-1&#x27;</span></span>):</span><br><span class="line">        self.primary_region = primary_region</span><br><span class="line">        self.replica_regions = [<span class="string">&#x27;eu-west-1&#x27;</span>, <span class="string">&#x27;ap-southeast-1&#x27;</span>, <span class="string">&#x27;us-west-2&#x27;</span>]</span><br><span class="line">        self.regions_config = &#123;&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> region <span class="keyword">in</span> [primary_region] + self.replica_regions:</span><br><span class="line">            self.regions_config[region] = boto3.client(<span class="string">&#x27;s3&#x27;</span>, region_name=region)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">setup_cross_region_replication</span>(<span class="params">self, bucket_name</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Setup automatic cross-region replication&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Create buckets in all regions</span></span><br><span class="line">        <span class="keyword">for</span> region, client <span class="keyword">in</span> self.regions_config.items():</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">if</span> region == self.primary_region:</span><br><span class="line">                    client.create_bucket(Bucket=bucket_name)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    client.create_bucket(</span><br><span class="line">                        Bucket=bucket_name,</span><br><span class="line">                        CreateBucketConfiguration=&#123;<span class="string">&#x27;LocationConstraint&#x27;</span>: region&#125;</span><br><span class="line">                    )</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Bucket may already exist in <span class="subst">&#123;region&#125;</span>: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Enable versioning</span></span><br><span class="line">        <span class="keyword">for</span> client <span class="keyword">in</span> self.regions_config.values():</span><br><span class="line">            client.put_bucket_versioning(</span><br><span class="line">                Bucket=bucket_name,</span><br><span class="line">                VersioningConfiguration=&#123;<span class="string">&#x27;Status&#x27;</span>: <span class="string">&#x27;Enabled&#x27;</span>&#125;</span><br><span class="line">            )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Setup replication from primary to replicas</span></span><br><span class="line">        replication_role = <span class="string">&#x27;arn:aws:iam::account:role/replication-role&#x27;</span></span><br><span class="line">        </span><br><span class="line">        rules = []</span><br><span class="line">        <span class="keyword">for</span> i, region <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.replica_regions):</span><br><span class="line">            rules.append(&#123;</span><br><span class="line">                <span class="string">&#x27;Id&#x27;</span>: <span class="string">f&#x27;ReplicateTo<span class="subst">&#123;region&#125;</span>&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;Status&#x27;</span>: <span class="string">&#x27;Enabled&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;Priority&#x27;</span>: i + <span class="number">1</span>,</span><br><span class="line">                <span class="string">&#x27;Destination&#x27;</span>: &#123;</span><br><span class="line">                    <span class="string">&#x27;Bucket&#x27;</span>: <span class="string">f&#x27;arn:aws:s3:::<span class="subst">&#123;bucket_name&#125;</span>&#x27;</span>,</span><br><span class="line">                    <span class="string">&#x27;StorageClass&#x27;</span>: <span class="string">&#x27;STANDARD&#x27;</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;)</span><br><span class="line">        </span><br><span class="line">        self.regions_config[self.primary_region].put_bucket_replication(</span><br><span class="line">            Bucket=bucket_name,</span><br><span class="line">            ReplicationConfiguration=&#123;</span><br><span class="line">                <span class="string">&#x27;Role&#x27;</span>: replication_role,</span><br><span class="line">                <span class="string">&#x27;Rules&#x27;</span>: rules</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_content_url</span>(<span class="params">self, object_key, user_region</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Get optimal content URL based on user region&quot;&quot;&quot;</span></span><br><span class="line">        region_mapping = &#123;</span><br><span class="line">            <span class="string">&#x27;US&#x27;</span>: <span class="string">&#x27;us-east-1&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;EU&#x27;</span>: <span class="string">&#x27;eu-west-1&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;AP&#x27;</span>: <span class="string">&#x27;ap-southeast-1&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;US-WEST&#x27;</span>: <span class="string">&#x27;us-west-2&#x27;</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        optimal_region = region_mapping.get(user_region, self.primary_region)</span><br><span class="line">        bucket_name = <span class="string">&#x27;content-bucket&#x27;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Generate CloudFront URL or direct S3 URL</span></span><br><span class="line">        url = <span class="string">f&quot;https://<span class="subst">&#123;bucket_name&#125;</span>.s3.<span class="subst">&#123;optimal_region&#125;</span>.amazonaws.com/<span class="subst">&#123;object_key&#125;</span>&quot;</span></span><br><span class="line">        <span class="keyword">return</span> url</span><br><span class="line"></span><br><span class="line"><span class="comment"># Results:</span></span><br><span class="line"><span class="comment"># - Average latency reduced from 200ms to 50ms</span></span><br><span class="line"><span class="comment"># - 99.99% availability with automatic failover</span></span><br><span class="line"><span class="comment"># - Cross-region replication ensures data durability</span></span><br><span class="line"><span class="comment"># - Regional caching reduces bandwidth costs by 40%</span></span><br></pre></td></tr></table></figure>
<h2 id="qa-section">Q&amp;A Section</h2>
<h3 id="q1-whats-the-difference-between-object-storage-and-block-storage">Q1:
What's the difference between object storage and block storage?</h3>
<p><strong>A</strong>: Object storage stores data as objects with
metadata in a flat namespace, accessed via REST APIs. Block storage
provides raw block-level access, typically used by filesystems. Object
storage excels at scalability and web applications, while block storage
is better for databases and low-latency applications.</p>
<h3 id="q2-how-does-hdfs-handle-node-failures">Q2: How does HDFS handle
node failures?</h3>
<p><strong>A</strong>: HDFS replicates each block across multiple
DataNodes (default: 3 replicas). If a DataNode fails, the NameNode
detects the failure through heartbeat mechanisms and initiates
replication to restore the replication factor. The system continues
operating with reduced redundancy until replication completes.</p>
<h3 id="q3-what-is-eventual-consistency-and-when-is-it-acceptable">Q3:
What is eventual consistency, and when is it acceptable?</h3>
<p><strong>A</strong>: Eventual consistency means the system will become
consistent over time if no new updates occur. It's acceptable for:</p>
<ul>
<li>Social media feeds (slight delays acceptable)</li>
<li>DNS systems (propagation delays expected)</li>
<li>Analytics data (not real-time critical)</li>
<li>Content delivery (caching acceptable)</li>
</ul>
<p>It's NOT acceptable for:</p>
<ul>
<li>Financial transactions</li>
<li>Inventory management</li>
<li>Medical records</li>
<li>Real-time collaborative editing</li>
</ul>
<h3 id="q4-how-do-i-choose-between-s3-storage-classes">Q4: How do I
choose between S3 storage classes?</h3>
<p><strong>A</strong>: Choose based on access patterns:</p>
<ul>
<li><strong>Standard</strong>: Frequently accessed data (&lt; 30
days)</li>
<li><strong>Standard-IA</strong>: Infrequently accessed (monthly or
less)</li>
<li><strong>Glacier</strong>: Archive data (quarterly or less)</li>
<li><strong>Intelligent-Tiering</strong>: Unknown or changing access
patterns</li>
</ul>
<p>Consider retrieval costs: Glacier has low storage costs but charges
for retrieval.</p>
<h3 id="q5-what-is-a-quorum-in-distributed-systems">Q5: What is a quorum
in distributed systems?</h3>
<p><strong>A</strong>: A quorum is the minimum number of nodes that must
agree for an operation to succeed. For N replicas:</p>
<ul>
<li>Read quorum: (N/2) + 1</li>
<li>Write quorum: (N/2) + 1</li>
</ul>
<p>This ensures at least one node has the latest data and prevents
split-brain scenarios.</p>
<h3 id="q6-how-does-ceph-ensure-data-consistency">Q6: How does Ceph
ensure data consistency?</h3>
<p><strong>A</strong>: Ceph uses: 1. <strong>CRUSH algorithm</strong>:
Deterministic data placement 2. <strong>PG (Placement Groups)</strong>:
Logical grouping of objects 3. <strong>OSD maps</strong>: Track cluster
state and data location 4. <strong>Quorum-based operations</strong>:
Monitors maintain consensus 5. <strong>Replication</strong>: Multiple
OSDs store each object</p>
<p>The system maintains consistency through these mechanisms while
allowing tunable consistency levels.</p>
<h3 id="q7-what-are-the-trade-offs-of-synchronous-vs-asynchronous-replication">Q7:
What are the trade-offs of synchronous vs asynchronous replication?</h3>
<p><strong>A</strong>:</p>
<p><strong>Synchronous</strong>:</p>
<ul>
<li>✅ Strong consistency</li>
<li>✅ No data loss risk</li>
<li>❌ Higher latency</li>
<li>❌ Lower throughput</li>
<li>❌ Fails if replica unavailable</li>
</ul>
<p><strong>Asynchronous</strong>:</p>
<ul>
<li>✅ Lower latency</li>
<li>✅ Higher throughput</li>
<li>✅ Better availability</li>
<li>❌ Risk of data loss</li>
<li>❌ Eventual consistency</li>
</ul>
<p>Choose based on RPO requirements: zero data loss needs synchronous
replication.</p>
<h3 id="q8-how-can-i-optimize-storage-costs-for-a-large-scale-application">Q8:
How can I optimize storage costs for a large-scale application?</h3>
<p><strong>A</strong>: Strategies include: 1. <strong>Lifecycle
policies</strong>: Automatically move to cheaper storage classes 2.
<strong>Compression</strong>: Reduce storage requirements (2-6x
typically) 3. <strong>Deduplication</strong>: Eliminate duplicate data
4. <strong>Right-sizing</strong>: Choose appropriate storage classes 5.
<strong>Monitoring</strong>: Track usage and optimize based on patterns
6. <strong>Regional optimization</strong>: Store data in cheaper regions
when possible</p>
<h3 id="q9-what-is-the-cap-theorem-and-why-cant-i-have-all-three-properties">Q9:
What is the CAP theorem, and why can't I have all three properties?</h3>
<p><strong>A</strong>: CAP theorem states you can guarantee at most two
of: Consistency, Availability, Partition tolerance. Partition tolerance
is mandatory in distributed systems (networks fail), forcing a choice
between C and A. This is a fundamental trade-off: strong consistency
requires coordination (reducing availability), while high availability
during partitions allows inconsistency.</p>
<h3 id="q10-how-do-i-implement-disaster-recovery-for-cloud-storage">Q10:
How do I implement disaster recovery for cloud storage?</h3>
<p><strong>A</strong>: Implement a comprehensive DR strategy: 1.
<strong>Backup strategy</strong>: Regular automated backups (full +
incremental) 2. <strong>Multi-region replication</strong>: Geographic
redundancy 3. <strong>Versioning</strong>: Enable object versioning for
point-in-time recovery 4. <strong>Lifecycle policies</strong>: Automate
backup retention and archival 5. <strong>Testing</strong>: Regularly
test restore procedures 6. <strong>Documentation</strong>: Maintain
runbooks for recovery scenarios 7. <strong>Monitoring</strong>: Alert on
backup failures and replication lag</p>
<p>Define RTO and RPO requirements to guide your strategy.</p>
<h2 id="summary-cheat-sheet">Summary Cheat Sheet</h2>
<h3 id="storage-types-comparison">Storage Types Comparison</h3>
<table>
<thead>
<tr>
<th>Type</th>
<th>Access</th>
<th>Use Case</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>Block</td>
<td>Block-level I/O</td>
<td>Databases, VMs</td>
<td>AWS EBS, Ceph RBD</td>
</tr>
<tr>
<td>File</td>
<td>File system APIs</td>
<td>Shared filesystems</td>
<td>AWS EFS, NFS</td>
</tr>
<tr>
<td>Object</td>
<td>REST APIs</td>
<td>Web apps, archives</td>
<td>S3, OSS, Ceph RGW</td>
</tr>
</tbody>
</table>
<h3 id="consistency-models-1">Consistency Models</h3>
<table>
<thead>
<tr>
<th>Model</th>
<th>Guarantee</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td>Strong</td>
<td>All reads see latest write</td>
<td>Financial systems</td>
</tr>
<tr>
<td>Eventual</td>
<td>Consistent over time</td>
<td>Social media, CDN</td>
</tr>
<tr>
<td>Causal</td>
<td>Preserves causality</td>
<td>Collaborative systems</td>
</tr>
<tr>
<td>Read-your-writes</td>
<td>User sees own writes</td>
<td>Web applications</td>
</tr>
</tbody>
</table>
<h3 id="replication-strategies-1">Replication Strategies</h3>
<table>
<thead>
<tr>
<th>Strategy</th>
<th>Consistency</th>
<th>Performance</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td>Master-Slave Sync</td>
<td>Strong</td>
<td>Lower</td>
<td>Critical data</td>
</tr>
<tr>
<td>Master-Slave Async</td>
<td>Eventual</td>
<td>Higher</td>
<td>High throughput</td>
</tr>
<tr>
<td>Multi-Master</td>
<td>Eventual</td>
<td>Highest</td>
<td>Global systems</td>
</tr>
<tr>
<td>Quorum-based</td>
<td>Tunable</td>
<td>Moderate</td>
<td>Distributed systems</td>
</tr>
</tbody>
</table>
<h3 id="storage-optimization-checklist">Storage Optimization
Checklist</h3>
<ul class="task-list">
<li><label><input type="checkbox">Implement lifecycle policies for
automatic tiering</label></li>
<li><label><input type="checkbox">Enable compression for appropriate
data types</label></li>
<li><label><input type="checkbox">Use deduplication where
applicable</label></li>
<li><label><input type="checkbox">Configure appropriate replication
factors</label></li>
<li><label><input type="checkbox">Monitor and optimize storage
classes</label></li>
<li><label><input type="checkbox">Implement caching
strategies</label></li>
<li><label><input type="checkbox">Use parallel I/O for large
transfers</label></li>
<li><label><input type="checkbox">Regular backup and DR
testing</label></li>
<li><label><input type="checkbox">Cost monitoring and
optimization</label></li>
<li><label><input type="checkbox">Performance
benchmarking</label></li>
</ul>
<h3 id="key-metrics-to-monitor">Key Metrics to Monitor</h3>
<ul>
<li><strong>Durability</strong>: 99.999999999% (11 nines) for object
storage</li>
<li><strong>Availability</strong>: 99.99% (4 nines) for production
systems</li>
<li><strong>Latency</strong>: P50, P99, P999 percentiles</li>
<li><strong>Throughput</strong>: IOPS and bandwidth</li>
<li><strong>Cost</strong>: Storage, requests, transfer costs</li>
<li><strong>Replication lag</strong>: For async replication</li>
<li><strong>Backup success rate</strong>: For DR readiness</li>
</ul>
<h3 id="common-patterns">Common Patterns</h3>
<p><strong>Write-Through Cache</strong>: Write to cache and storage
simultaneously <strong>Write-Back Cache</strong>: Write to cache, flush
to storage later <strong>Read-Through Cache</strong>: Check cache, read
from storage if miss <strong>Write-Around Cache</strong>: Write directly
to storage, invalidate cache</p>
<p><strong>Sharding</strong>: Distribute data across multiple storage
nodes <strong>Partitioning</strong>: Divide data by key ranges or hash
<strong>Replication</strong>: Copy data to multiple nodes for
redundancy</p>
<hr>
<p>This comprehensive guide covers the essential aspects of cloud
storage systems and distributed architecture. From theoretical
foundations to practical implementations, these concepts form the
backbone of modern cloud infrastructure. Whether you're designing a new
system or optimizing an existing one, understanding these principles is
crucial for building scalable, reliable, and cost-effective storage
solutions.</p>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    
    
    
    
    
    
    <ul>
        <li>Post title：Cloud Computing (3): Storage Systems and Distributed Architecture</li>
        <li>Post author：Chen Kai</li>
        <li>Create time：2023-10-27 00:00:00</li>
        <li>
            Post link：https://www.chenk.top/en/cloud-computing-storage-distributed-systems/
        </li>
        <li>
            Copyright Notice：All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en">BY-NC-SA</a> unless stating additionally.
        </li>
    </ul>
</div>

            </div>
        

        
            <ul class="post-tags-box">
                
                    <li class="tag-item">
                        <a href="/en/tags/HDFS/">#HDFS</a>&nbsp;
                    </li>
                
                    <li class="tag-item">
                        <a href="/en/tags/Ceph/">#Ceph</a>&nbsp;
                    </li>
                
                    <li class="tag-item">
                        <a href="/en/tags/Cloud-Computing/">#Cloud Computing</a>&nbsp;
                    </li>
                
                    <li class="tag-item">
                        <a href="/en/tags/Distributed-Storage/">#Distributed Storage</a>&nbsp;
                    </li>
                
                    <li class="tag-item">
                        <a href="/en/tags/Object-Storage/">#Object Storage</a>&nbsp;
                    </li>
                
            </ul>
        

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/en/cloud-computing-networking-sdn/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Cloud Computing (5): Network Architecture and SDN</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/en/cloud-computing-cloud-native-containers/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Cloud Computing (4): Cloud-Native and Container Technologies</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
            <div class="comment-container">
                <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fas fa-comments">&nbsp;Comments</i>
    </div>
    

        
            
    <div class="valine-container">
        <script data-pjax
                src="//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script>
        <div id="vcomments"></div>
        <script data-pjax>
            function loadValine() {
                new Valine({
                    el: '#vcomments',
                    appId: 'p2Cu9MgjoKzo3VmulhNLIusH-gzGzoHsz',
                    appKey: 'QThQHg3c8sVwGpzg9lu8zEG3',
                    meta: ['nick', 'mail', 'link'],
                    avatar: 'wavatar',
                    enableQQ: true,
                    placeholder: '😜 尽情赞美帅气伟大的ck吧~',
                    lang: 'en'.toLowerCase()
                });

                function getAuthor(language) {
                    switch (language) {
                        case 'en':
                            return 'Author';
                        case 'zh-CN':
                            return '博主';
                        default:
                            return 'Master';
                    }
                }

                // Add "Author" identify
                const getValineDomTimer = setInterval(() => {
                    const vcards = document.querySelectorAll('#vcomments .vcards .vcard');
                    if (vcards.length > 0) {
                        let author = 'Chen Kai';

                        if (author) {
                            for (let vcard of vcards) {
                                const vnick_dom = vcard.querySelector('.vhead .vnick');
                                const vnick = vnick_dom.innerHTML;
                                if (vnick === author) {
                                    vnick_dom.innerHTML = `${vnick} <span class="author">${getAuthor(KEEP.hexo_config.language)}</span>`
                                }
                            }
                        }
                        clearInterval(getValineDomTimer);
                    } else {
                        clearInterval(getValineDomTimer);
                    }
                }, 2000);
            }

            if ('true') {
                const loadValineTimeout = setTimeout(() => {
                    loadValine();
                    clearTimeout(loadValineTimeout);
                }, 1000);
            } else {
                window.addEventListener('DOMContentLoaded', loadValine);
            }
        </script>
    </div>



        
    
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2020</span>
              -
            
            2026&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Chen Kai</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
            </div>
        
        <div class="theme-info info-item">
            <!-- Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.5</a> -->
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fas fa-comment"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        
            <li class="tools-item rss flex-center">
                <a class="flex-center"
                   href="/atom.xml"
                   target="_blank"
                >
                    <i class="fas fa-rss"></i>
                </a>
            </li>
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#distributed-storage-fundamentals"><span class="nav-number">1.</span> <span class="nav-text">Distributed Storage
Fundamentals</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#the-cap-theorem"><span class="nav-number">1.1.</span> <span class="nav-text">The CAP Theorem</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#base-principles"><span class="nav-number">1.2.</span> <span class="nav-text">BASE Principles</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#distributed-storage-architecture-patterns"><span class="nav-number">1.3.</span> <span class="nav-text">Distributed Storage
Architecture Patterns</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#master-slave-architecture"><span class="nav-number">1.3.1.</span> <span class="nav-text">Master-Slave Architecture</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#peer-to-peer-architecture"><span class="nav-number">1.3.2.</span> <span class="nav-text">Peer-to-Peer Architecture</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#consistent-hashing"><span class="nav-number">1.3.3.</span> <span class="nav-text">Consistent Hashing</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#object-storage-deep-dive"><span class="nav-number">2.</span> <span class="nav-text">Object Storage Deep Dive</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#amazon-s3-architecture"><span class="nav-number">2.1.</span> <span class="nav-text">Amazon S3 Architecture</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#s3-request-flow"><span class="nav-number">2.1.1.</span> <span class="nav-text">S3 Request Flow</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#s3-key-concepts"><span class="nav-number">2.1.2.</span> <span class="nav-text">S3 Key Concepts</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#s3-api-operations"><span class="nav-number">2.1.3.</span> <span class="nav-text">S3 API Operations</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#s3-storage-classes"><span class="nav-number">2.1.4.</span> <span class="nav-text">S3 Storage Classes</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#s3-consistency-model"><span class="nav-number">2.1.5.</span> <span class="nav-text">S3 Consistency Model</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#alibaba-cloud-oss-architecture"><span class="nav-number">2.2.</span> <span class="nav-text">Alibaba Cloud OSS
Architecture</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#oss-architecture-components"><span class="nav-number">2.2.1.</span> <span class="nav-text">OSS Architecture Components</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#oss-python-sdk-example"><span class="nav-number">2.2.2.</span> <span class="nav-text">OSS Python SDK Example</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#block-vs-file-storage-comparison"><span class="nav-number">3.</span> <span class="nav-text">Block vs File Storage
Comparison</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#block-storage"><span class="nav-number">3.1.</span> <span class="nav-text">Block Storage</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#characteristics"><span class="nav-number">3.1.1.</span> <span class="nav-text">Characteristics</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#use-cases"><span class="nav-number">3.1.2.</span> <span class="nav-text">Use Cases</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#block-storage-architecture"><span class="nav-number">3.1.3.</span> <span class="nav-text">Block Storage Architecture</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#aws-ebs-example"><span class="nav-number">3.1.4.</span> <span class="nav-text">AWS EBS Example</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#file-storage"><span class="nav-number">3.2.</span> <span class="nav-text">File Storage</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#characteristics-1"><span class="nav-number">3.2.1.</span> <span class="nav-text">Characteristics</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#use-cases-1"><span class="nav-number">3.2.2.</span> <span class="nav-text">Use Cases</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#file-storage-architecture"><span class="nav-number">3.2.3.</span> <span class="nav-text">File Storage Architecture</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#aws-efs-example"><span class="nav-number">3.2.4.</span> <span class="nav-text">AWS EFS Example</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#comparison-table"><span class="nav-number">3.3.</span> <span class="nav-text">Comparison Table</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#when-to-use-each-type"><span class="nav-number">3.4.</span> <span class="nav-text">When to Use Each Type</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hdfs-distributed-file-system"><span class="nav-number">4.</span> <span class="nav-text">HDFS Distributed File System</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#hdfs-architecture"><span class="nav-number">4.1.</span> <span class="nav-text">HDFS Architecture</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#key-components"><span class="nav-number">4.1.1.</span> <span class="nav-text">Key Components</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hdfs-configuration"><span class="nav-number">4.2.</span> <span class="nav-text">HDFS Configuration</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#core-site.xml"><span class="nav-number">4.2.1.</span> <span class="nav-text">core-site.xml</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#hdfs-site.xml"><span class="nav-number">4.2.2.</span> <span class="nav-text">hdfs-site.xml</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hdfs-operations"><span class="nav-number">4.3.</span> <span class="nav-text">HDFS Operations</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#java-api-example"><span class="nav-number">4.3.1.</span> <span class="nav-text">Java API Example</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#python-api-with-hdfs3"><span class="nav-number">4.3.2.</span> <span class="nav-text">Python API with hdfs3</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hdfs-replication-strategy"><span class="nav-number">4.4.</span> <span class="nav-text">HDFS Replication Strategy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hdfs-high-availability"><span class="nav-number">4.5.</span> <span class="nav-text">HDFS High Availability</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ceph-storage-cluster-deployment"><span class="nav-number">5.</span> <span class="nav-text">Ceph Storage Cluster
Deployment</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ceph-architecture"><span class="nav-number">5.1.</span> <span class="nav-text">Ceph Architecture</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#core-components"><span class="nav-number">5.1.1.</span> <span class="nav-text">Core Components</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ceph-deployment"><span class="nav-number">5.2.</span> <span class="nav-text">Ceph Deployment</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#installation-on-ubuntu"><span class="nav-number">5.2.1.</span> <span class="nav-text">Installation on Ubuntu</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ceph-configuration-file-ceph.conf"><span class="nav-number">5.2.2.</span> <span class="nav-text">Ceph Configuration File
(ceph.conf)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ceph-object-storage-rados-gateway"><span class="nav-number">5.3.</span> <span class="nav-text">Ceph Object Storage (RADOS
Gateway)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#rgw-configuration"><span class="nav-number">5.3.1.</span> <span class="nav-text">RGW Configuration</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#python-client-for-rgw"><span class="nav-number">5.3.2.</span> <span class="nav-text">Python Client for RGW</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ceph-block-storage-rbd"><span class="nav-number">5.4.</span> <span class="nav-text">Ceph Block Storage (RBD)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#rbd-operations"><span class="nav-number">5.4.1.</span> <span class="nav-text">RBD Operations</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#python-rbd-client"><span class="nav-number">5.4.2.</span> <span class="nav-text">Python RBD Client</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ceph-performance-tuning"><span class="nav-number">5.5.</span> <span class="nav-text">Ceph Performance Tuning</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#osd-configuration"><span class="nav-number">5.5.1.</span> <span class="nav-text">OSD Configuration</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#crush-map-optimization"><span class="nav-number">5.5.2.</span> <span class="nav-text">CRUSH Map Optimization</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#data-consistency-and-replication-strategies"><span class="nav-number">6.</span> <span class="nav-text">Data Consistency
and Replication Strategies</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#consistency-models"><span class="nav-number">6.1.</span> <span class="nav-text">Consistency Models</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#strong-consistency"><span class="nav-number">6.1.1.</span> <span class="nav-text">Strong Consistency</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#eventual-consistency"><span class="nav-number">6.1.2.</span> <span class="nav-text">Eventual Consistency</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#causal-consistency"><span class="nav-number">6.1.3.</span> <span class="nav-text">Causal Consistency</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#read-your-writes-consistency"><span class="nav-number">6.1.4.</span> <span class="nav-text">Read-Your-Writes Consistency</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#replication-strategies"><span class="nav-number">6.2.</span> <span class="nav-text">Replication Strategies</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#master-slave-replication"><span class="nav-number">6.2.1.</span> <span class="nav-text">Master-Slave Replication</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#multi-master-replication"><span class="nav-number">6.2.2.</span> <span class="nav-text">Multi-Master Replication</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#quorum-based-replication"><span class="nav-number">6.2.3.</span> <span class="nav-text">Quorum-Based Replication</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#vector-clocks"><span class="nav-number">6.3.</span> <span class="nav-text">Vector Clocks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#anti-entropy-and-merkle-trees"><span class="nav-number">6.4.</span> <span class="nav-text">Anti-Entropy and Merkle
Trees</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#backup-and-disaster-recovery"><span class="nav-number">7.</span> <span class="nav-text">Backup and Disaster Recovery</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#backup-strategies"><span class="nav-number">7.1.</span> <span class="nav-text">Backup Strategies</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#full-backup"><span class="nav-number">7.1.1.</span> <span class="nav-text">Full Backup</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#incremental-backup"><span class="nav-number">7.1.2.</span> <span class="nav-text">Incremental Backup</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#differential-backup"><span class="nav-number">7.1.3.</span> <span class="nav-text">Differential Backup</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#backup-implementation"><span class="nav-number">7.2.</span> <span class="nav-text">Backup Implementation</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#s3-lifecycle-policies"><span class="nav-number">7.2.1.</span> <span class="nav-text">S3 Lifecycle Policies</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#automated-backup-script"><span class="nav-number">7.2.2.</span> <span class="nav-text">Automated Backup Script</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#disaster-recovery-strategies"><span class="nav-number">7.3.</span> <span class="nav-text">Disaster Recovery Strategies</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#rto-and-rpo"><span class="nav-number">7.3.1.</span> <span class="nav-text">RTO and RPO</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#multi-region-replication"><span class="nav-number">7.3.2.</span> <span class="nav-text">Multi-Region Replication</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#storage-performance-optimization"><span class="nav-number">8.</span> <span class="nav-text">Storage Performance
Optimization</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#performance-metrics"><span class="nav-number">8.1.</span> <span class="nav-text">Performance Metrics</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#optimization-techniques"><span class="nav-number">8.2.</span> <span class="nav-text">Optimization Techniques</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#caching-strategies"><span class="nav-number">8.2.1.</span> <span class="nav-text">Caching Strategies</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#data-locality"><span class="nav-number">8.2.2.</span> <span class="nav-text">Data Locality</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#compression"><span class="nav-number">8.2.3.</span> <span class="nav-text">Compression</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#parallel-io"><span class="nav-number">8.2.4.</span> <span class="nav-text">Parallel I&#x2F;O</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#benchmarking-storage-performance"><span class="nav-number">8.3.</span> <span class="nav-text">Benchmarking Storage
Performance</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#s3-performance-test"><span class="nav-number">8.3.1.</span> <span class="nav-text">S3 Performance Test</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cost-optimization-strategies"><span class="nav-number">9.</span> <span class="nav-text">Cost Optimization Strategies</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#storage-cost-factors"><span class="nav-number">9.1.</span> <span class="nav-text">Storage Cost Factors</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#optimization-techniques-1"><span class="nav-number">9.2.</span> <span class="nav-text">Optimization Techniques</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#lifecycle-management"><span class="nav-number">9.2.1.</span> <span class="nav-text">Lifecycle Management</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#deduplication"><span class="nav-number">9.2.2.</span> <span class="nav-text">Deduplication</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#compression-analysis"><span class="nav-number">9.2.3.</span> <span class="nav-text">Compression Analysis</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#cost-calculator"><span class="nav-number">9.2.4.</span> <span class="nav-text">Cost Calculator</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#case-studies"><span class="nav-number">10.</span> <span class="nav-text">Case Studies</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#case-study-1-e-commerce-platform-migration"><span class="nav-number">10.1.</span> <span class="nav-text">Case Study 1:
E-Commerce Platform Migration</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#case-study-2-big-data-analytics-platform"><span class="nav-number">10.2.</span> <span class="nav-text">Case Study 2: Big Data
Analytics Platform</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#case-study-3-multi-region-content-delivery"><span class="nav-number">10.3.</span> <span class="nav-text">Case Study 3:
Multi-Region Content Delivery</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#qa-section"><span class="nav-number">11.</span> <span class="nav-text">Q&amp;A Section</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#q1-whats-the-difference-between-object-storage-and-block-storage"><span class="nav-number">11.1.</span> <span class="nav-text">Q1:
What&#39;s the difference between object storage and block storage?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q2-how-does-hdfs-handle-node-failures"><span class="nav-number">11.2.</span> <span class="nav-text">Q2: How does HDFS handle
node failures?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q3-what-is-eventual-consistency-and-when-is-it-acceptable"><span class="nav-number">11.3.</span> <span class="nav-text">Q3:
What is eventual consistency, and when is it acceptable?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q4-how-do-i-choose-between-s3-storage-classes"><span class="nav-number">11.4.</span> <span class="nav-text">Q4: How do I
choose between S3 storage classes?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q5-what-is-a-quorum-in-distributed-systems"><span class="nav-number">11.5.</span> <span class="nav-text">Q5: What is a quorum
in distributed systems?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q6-how-does-ceph-ensure-data-consistency"><span class="nav-number">11.6.</span> <span class="nav-text">Q6: How does Ceph
ensure data consistency?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q7-what-are-the-trade-offs-of-synchronous-vs-asynchronous-replication"><span class="nav-number">11.7.</span> <span class="nav-text">Q7:
What are the trade-offs of synchronous vs asynchronous replication?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q8-how-can-i-optimize-storage-costs-for-a-large-scale-application"><span class="nav-number">11.8.</span> <span class="nav-text">Q8:
How can I optimize storage costs for a large-scale application?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q9-what-is-the-cap-theorem-and-why-cant-i-have-all-three-properties"><span class="nav-number">11.9.</span> <span class="nav-text">Q9:
What is the CAP theorem, and why can&#39;t I have all three properties?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q10-how-do-i-implement-disaster-recovery-for-cloud-storage"><span class="nav-number">11.10.</span> <span class="nav-text">Q10:
How do I implement disaster recovery for cloud storage?</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#summary-cheat-sheet"><span class="nav-number">12.</span> <span class="nav-text">Summary Cheat Sheet</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#storage-types-comparison"><span class="nav-number">12.1.</span> <span class="nav-text">Storage Types Comparison</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#consistency-models-1"><span class="nav-number">12.2.</span> <span class="nav-text">Consistency Models</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#replication-strategies-1"><span class="nav-number">12.3.</span> <span class="nav-text">Replication Strategies</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#storage-optimization-checklist"><span class="nav-number">12.4.</span> <span class="nav-text">Storage Optimization
Checklist</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#key-metrics-to-monitor"><span class="nav-number">12.5.</span> <span class="nav-text">Key Metrics to Monitor</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#common-patterns"><span class="nav-number">12.6.</span> <span class="nav-text">Common Patterns</span></a></li></ol></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>

<script src="/js/lang-switch.js"></script>



    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-copy.js"></script>





<div class="post-scripts pjax">
    
        
<script src="/js/left-side-toggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/toc.js"></script>

    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
