<!DOCTYPE html>



<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Chen Kai">
    
    <title>
        
        Chen Kai Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/logo.svg">
    
<link rel="stylesheet" href="/css/font-awesome.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"chenk.top","root":"/","language":"en","default_language":"zh-CN","languages":["zh-CN","en"],"path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":true},"style":{"primary_color":"#0066CC","avatar":"/images/avatar.svg","favicon":"/images/logo.svg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":false,"scale":false},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"Keep writing and Keep loving."},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":true,"style":"default"},"pjax":{"enable":true},"lazyload":{"enable":false},"version":"3.4.5"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
<meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="Chen Kai Blog" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    
    
    
    
    

    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/en/">
                Chen Kai Blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/en/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/en/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/en/categories"
                            >
                                CATEGORIES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/en/tags"
                            >
                                TAGS
                            </a>
                        </li>
                    
                    <li class="menu-item lang-switch lang-switch-trigger" title="Language">
                        <i class="fas fa-globe"></i>
                    </li>
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item lang-switch-trigger"><i class="fas fa-globe"></i></div>
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/en/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/en/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/en/categories">CATEGORIES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/en/tags">TAGS</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="home-content-container fade-in-down-animation">
    
    
    

    <ul class="home-article-list">
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/transfer-learning-8-multimodal-transfer/">
                        Transfer Learning (8) - Multimodal Transfer
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>Why can CLIP achieve zero-shot image classification using natural
language descriptions? Why can DALL-E generate images from text? The
core of these breakthroughs is multimodal transfer learning—enabling
models to understand and associate information across different
modalities (vision, language, audio, etc.).</p>
<p>Multimodal transfer is not just a fusion of technologies, but a key
to cognitive intelligence. Starting from the mathematical principles of
contrastive learning, this article systematically explains
vision-language pretraining models like CLIP and ALIGN, deeply explores
cross-modal alignment, fusion strategies, and downstream task
applications, providing complete code for implementing multimodal models
from scratch.</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Thu May 14 2026 00:00:00 GMT+0800">2026-05-14</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/categories/Machine-Learning/">Machine Learning</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/tags/Contrastive-Learning/">Contrastive Learning</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/Transfer-Learning/">Transfer Learning</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/CLIP/">CLIP</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/Multimodal-Learning/">Multimodal Learning</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/Vision-Language-Models/">Vision-Language Models</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/transfer-learning-8-multimodal-transfer/">Read more&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/transfer-learning-7-zero-shot-learning/">
                        Transfer Learning (7) - Zero-Shot Learning
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>Zero-Shot Learning (ZSL) is a machine learning paradigm capable of
recognizing classes never seen during training. Humans possess powerful
zero-shot learning abilities—even without seeing a zebra before, we can
recognize it through descriptions like "looks like a horse but with
black and white stripes." Lampert et al.'s pioneering 2009 paper
"Learning to Detect Unseen Object Classes" introduced this capability to
computer vision, launching zero-shot learning research. Zero-shot
learning has important applications in long-tail distributions, rapid
new class adaptation, and low-resource scenarios, but also faces many
challenges like semantic gaps, domain shift, and hubness problems.</p>
<p>This article derives the mathematical foundations of zero-shot
learning from first principles, explains construction of attribute
representations and semantic embedding spaces, details compatibility
function design and optimization, deeply analyzes principles of
traditional discriminative ZSL and modern generative ZSL (f-CLSWGAN,
f-VAEGAN, etc.), introduces bias calibration methods for generalized
zero-shot learning (GZSL), and provides complete code implementations
(including attribute learning, visual-semantic mapping, conditional
generative models, etc.). We'll see that zero-shot learning essentially
learns a cross-modal mapping from visual space to semantic space,
bridging seen and unseen classes through auxiliary information
(attributes, word embeddings, etc.).</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Mon Apr 27 2026 10:00:00 GMT+0800">2026-04-27</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/categories/Machine-Learning/">Machine Learning</a>&nbsp;
                        </li>
                    
                    
                        <li>
                            &gt; 
                            <a href="/en/categories/Machine-Learning/Transfer-Learning/">Transfer Learning</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/tags/Transfer-Learning/">Transfer Learning</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/Zero-Shot-Learning/">Zero-Shot Learning</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/Attribute-Representation/">Attribute Representation</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/Semantic-Embedding/">Semantic Embedding</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/Generative-ZSL/">Generative ZSL</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/transfer-learning-7-zero-shot-learning/">Read more&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/transfer-learning-6-multi-task-learning/">
                        Transfer Learning (6) - Multi-Task Learning
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>Multi-Task Learning (MTL) is a machine learning paradigm that
improves model generalization by simultaneously learning multiple
related tasks. Rich Caruana's pioneering 1997 paper "Multitask Learning"
demonstrated how shared representations help models learn more robust
features. In modern deep learning, multi-task learning has achieved
tremendous success in computer vision (simultaneous detection,
segmentation, depth estimation), natural language processing (joint
entity recognition and relation extraction), and recommendation systems
(simultaneous CTR and CVR prediction). But multi-task learning is far
more than simply summing multiple loss functions—how to design shared
structures, how to balance learning across different tasks, and how to
handle negative transfer between tasks are all questions requiring deep
investigation.</p>
<p>This article derives the mathematical foundations of multi-task
learning from first principles, analyzes the pros and cons of hard vs
soft parameter sharing, explains task relationship learning and task
clustering methods in detail, deeply analyzes gradient conflict problems
and solutions (PCGrad, GradNorm, CAGrad, etc.), introduces auxiliary
task design principles, and provides a complete multi-task network
implementation (including dynamic weight adjustment, gradient
projection, task balancing and other industrial-grade techniques). We'll
see that multi-task learning essentially seeks a Pareto optimal solution
satisfying multiple optimization objectives.</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Fri Apr 10 2026 10:00:00 GMT+0800">2026-04-10</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/categories/Machine-Learning/">Machine Learning</a>&nbsp;
                        </li>
                    
                    
                        <li>
                            &gt; 
                            <a href="/en/categories/Machine-Learning/Transfer-Learning/">Transfer Learning</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/tags/Multi-Task-Learning/">Multi-Task Learning</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/Transfer-Learning/">Transfer Learning</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/PCGrad/">PCGrad</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/GradNorm/">GradNorm</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/Parameter-Sharing/">Parameter Sharing</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/transfer-learning-6-multi-task-learning/">Read more&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/transfer-learning-5-knowledge-distillation/">
                        Transfer Learning (5) - Knowledge Distillation
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>Knowledge Distillation (KD) is a model compression and transfer
learning technique that enables small models (students) to learn from
large models (teachers), maintaining performance close to teacher models
while significantly reducing parameters and computation. Hinton et al.'s
seminal 2015 paper "Distilling the Knowledge in a Neural Network"
sparked a research wave in this field. But knowledge distillation is far
more than simple "soft label" training—it involves temperature parameter
tuning, extracting knowledge at different levels, matching
student-teacher architectures, and numerous technical details.</p>
<p>This article derives the mathematical foundations of knowledge
distillation from first principles, explains why soft labels contain
more information than hard labels, details implementation of
response-based, feature-based, and relation-based distillation,
introduces methods like self-distillation, mutual learning, and online
distillation that don't require pre-trained teachers, and explores
synergistic optimization of quantization, pruning, and distillation.
We'll see that distillation is essentially "compression encoding" of
knowledge—explicitly transferring dark knowledge implicitly learned by
teacher models to student models.</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Tue Mar 24 2026 10:00:00 GMT+0800">2026-03-24</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/categories/Machine-Learning/">Machine Learning</a>&nbsp;
                        </li>
                    
                    
                        <li>
                            &gt; 
                            <a href="/en/categories/Machine-Learning/Transfer-Learning/">Transfer Learning</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/tags/Transfer-Learning/">Transfer Learning</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/Knowledge-Distillation/">Knowledge Distillation</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/Model-Compression/">Model Compression</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/Temperature-Parameter/">Temperature Parameter</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/Soft-Labels/">Soft Labels</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/transfer-learning-5-knowledge-distillation/">Read more&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/transfer-learning-4-few-shot-learning/">
                        Transfer Learning (4) - Few-Shot Learning
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>Few-shot learning represents one of the most challenging problems in
machine learning. Humans can rapidly learn new concepts from minimal
examples - recognizing new species after seeing just a few images, or
understanding new linguistic patterns from a handful of instances.
Traditional deep learning models, however, require massive amounts of
labeled data to train effectively and perform poorly in data-scarce
scenarios.</p>
<p>The goal of few-shot learning is to <strong>learn classifiers from
only a few examples per class (typically 1-10 samples)</strong>. This
requires models with powerful generalization and transfer capabilities -
the ability to learn "how to learn" from known classes and quickly adapt
to novel classes. This article derives the mathematical foundations of
metric learning and meta-learning from first principles, explains
classic methods like Siamese networks, Prototypical networks, and MAML
in detail, and provides a complete Prototypical network
implementation.</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Sat Mar 07 2026 10:00:00 GMT+0800">2026-03-07</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/categories/Machine-Learning/">Machine Learning</a>&nbsp;
                        </li>
                    
                    
                        <li>
                            &gt; 
                            <a href="/en/categories/Machine-Learning/Transfer-Learning/">Transfer Learning</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/tags/MAML/">MAML</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/Transfer-Learning/">Transfer Learning</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/Few-Shot-Learning/">Few-Shot Learning</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/Prototypical-Networks/">Prototypical Networks</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/Meta-Learning/">Meta-Learning</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/transfer-learning-4-few-shot-learning/">Read more&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
    </ul>

    <div class="home-paginator">
        <div class="paginator">
    
        <a class="prev btn"
           href="/en/page/2/"
        >Prev</a>
    

    
        <a class="next btn"
           href="/en/page/4/"
        >Next</a>
    
</div>

    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2020</span>
              -
            
            2026&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Chen Kai</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
            </div>
        
        <div class="theme-info info-item">
            <!-- Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.5</a> -->
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        
            <li class="tools-item rss flex-center">
                <a class="flex-center"
                   href="/atom.xml"
                   target="_blank"
                >
                    <i class="fas fa-rss"></i>
                </a>
            </li>
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>





<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>

<script src="/js/lang-switch.js"></script>



    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-copy.js"></script>





<div class="post-scripts pjax">
    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
