<!DOCTYPE html>



<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Chen Kai">
    
    <title>
        
        Chen Kai Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/logo.svg">
    
<link rel="stylesheet" href="/css/font-awesome.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"chenk.top","root":"/","language":"en","default_language":"zh-CN","languages":["zh-CN","en"],"path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":true},"style":{"primary_color":"#0066CC","avatar":"/images/avatar.svg","favicon":"/images/logo.svg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":false,"scale":false},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"Keep writing and Keep loving."},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":true,"style":"default"},"pjax":{"enable":true},"lazyload":{"enable":false},"version":"3.4.5"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
<meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="Chen Kai Blog" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    
        <div class="first-screen-container flex-center fade-in-down-animation">
    <div class="content flex-center">
        <div class="description">
            Keep writing and Keep loving.
        </div>
        
            <div class="s-icon-list">
                
                    
                        
                            <span class="s-icon-item github">
                                <a target="_blank" href="https://github.com/chenkai66">
                                    <i class="fab fa-github"></i>
                                </a>
                            </span>
                        
                    
                
                    
                        
                            <span class="s-icon-item weixin">
                                <a target="_blank" href="https://pic.imgdb.cn/item/66eb3235f21886ccc03a38b5.jpg">
                                    <i class="fab fa-weixin"></i>
                                </a>
                            </span>
                        
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                        
                            <span class="s-icon-item email">
                                <a href="mailto:chenkai.nb.666@gmail.com">
                                    <i class="fas fa-envelope"></i>
                                </a>
                            </span>
                        
                    
                
            </div>
        
    </div>
</div>

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    
    
    
    
    

    <div class="header-content has-first-screen">
        <div class="left">
            
            <a class="logo-title" href="/en/">
                Chen Kai Blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/en/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/en/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/en/categories"
                            >
                                CATEGORIES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/en/tags"
                            >
                                TAGS
                            </a>
                        </li>
                    
                    <li class="menu-item lang-switch lang-switch-trigger" title="Language">
                        <i class="fas fa-globe"></i>
                    </li>
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item lang-switch-trigger"><i class="fas fa-globe"></i></div>
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/en/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/en/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/en/categories">CATEGORIES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/en/tags">TAGS</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="home-content-container fade-in-down-animation">
    
    
    

    <ul class="home-article-list">
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/en/nlp-frontiers-applications/">
                        NLP (12): Frontiers and Practical Applications
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>As large language models continue to improve in capability, the NLP field is undergoing unprecedented transformation. From Agents and tool use (Function Calling, ReAct) to code generation and understanding (CodeLlama, StarCoder), to long-context modeling (LongLoRA, LongLLaMA), these cutting-edge technologies are redefining the boundaries of AI capabilities.</p>
<p>However, as model capabilities increase, challenges such as hallucination, safety, and alignment are becoming increasingly prominent. How to evaluate model performance and how to build complete NLP project deployment systems have become critical issues in practical applications. From FastAPI service deployment to Docker containerization, from monitoring systems to performance optimization, production-grade NLP applications require comprehensive consideration of technical, engineering, and business dimensions.</p>
<p>This article delves into frontier technologies in NLP, including Agents and tool use, code generation, long-context modeling, hallucination mitigation, safety and alignment, model evaluation systems, and demonstrates how to build and deploy production-grade NLP application systems through complete practical examples.</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Thu Mar 06 2025 00:00:00 GMT+0800">2025-03-06</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/categories/Natural-Language-Processing/">Natural Language Processing</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/tags/LLM/">LLM</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/NLP/">NLP</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/Applications/">Applications</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/en/nlp-frontiers-applications/">Read more&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/en/nlp-multimodal-nlp/">
                        NLP (11): Multimodal Large Language Models
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>Traditional natural language processing models can only understand and generate text, but our world is multimodal—we simultaneously process visual, auditory, textual, and other forms of information. Multimodal Large Language Models (MLLMs) break this limitation, enabling simultaneous understanding of images, audio, video, and text, achieving cross-modal comprehension and generation.</p>
<p>From CLIP’s vision-language alignment to BLIP and BLIP-2’s progressive multimodal pretraining, to GPT-4V’s general visual understanding capabilities, multimodal models are redefining the boundaries of AI capabilities. Audio-text models like Whisper achieve high-precision speech recognition, while video understanding models can analyze temporal information. These technologies not only achieve breakthroughs in academic research but also demonstrate enormous potential in practical applications—from intelligent customer service to content creation, from medical diagnosis to autonomous driving.</p>
<p>This article delves into the core technologies of multimodal large language models, including vision-language model architectures, multimodal pretraining strategies, image captioning and Visual Question Answering (VQA), cutting-edge models like GPT-4V, audio-text models, video understanding techniques, and demonstrates how to build multimodal application systems through practical examples.</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Mon Mar 03 2025 00:00:00 GMT+0800">2025-03-03</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/categories/Natural-Language-Processing/">Natural Language Processing</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/tags/LLM/">LLM</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/NLP/">NLP</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/Multimodal/">Multimodal</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/en/nlp-multimodal-nlp/">Read more&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/en/nlp-rag-knowledge-enhancement/">
                        NLP (10): RAG and Knowledge Enhancement Systems
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>As large language models become widely adopted, a core problem has emerged: how to enable models to access and utilize external knowledge? Traditional pre-trained models, despite having massive parameters and strong language understanding capabilities, have their knowledge “frozen” in training data, unable to access the latest information or private knowledge bases. Retrieval-Augmented Generation (RAG) technology addresses this by combining information retrieval with generative models, enabling LLMs to dynamically access external knowledge and generate more accurate, relevant answers.</p>
<p>The core components of RAG systems include vector database selection, Embedding model optimization, retrieval strategy design, reranking techniques, and query rewriting and expansion. An excellent RAG system requires not only efficient retrieval mechanisms but also carefully designed query optimization and result fusion strategies. This article delves deep into various components of RAG systems, from basic architecture to advanced optimization techniques, and demonstrates how to build enterprise-grade RAG systems through practical examples.</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Fri Feb 28 2025 00:00:00 GMT+0800">2025-02-28</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/categories/Natural-Language-Processing/">Natural Language Processing</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/tags/LLM/">LLM</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/NLP/">NLP</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/RAG/">RAG</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/en/nlp-rag-knowledge-enhancement/">Read more&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/en/nlp-llm-architecture-deep-dive/">
                        NLP (9): Deep Dive into LLM Architecture
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>The emergence of ChatGPT has made Large Language Models (LLMs) the most sought-after technology in artificial intelligence. However, to truly understand how LLMs work, we need to delve deep into their architectural design, long-context handling techniques, model compression methods, and inference optimization strategies. Different architectural choices (Encoder-only, Decoder-only, Encoder-Decoder) determine the model’s application scenarios; long-context techniques (ALiBi, RoPE, Flash Attention) enable models to handle longer contexts; MoE (Mixture of Experts) architecture dramatically increases model capacity through sparse activation; while quantization, KV Cache optimization, and other techniques enable large models to run efficiently in resource-constrained environments.</p>
<p>This article systematically explains the core architectural technologies of large language models, from architectural choices to long-context handling, from MoE to model compression, from KV Cache to inference optimization, and demonstrates how to deploy and optimize LLMs through practical examples. Whether you’re a researcher, engineer, or technology enthusiast, you’ll gain deep and practical knowledge from this article.</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Tue Feb 25 2025 00:00:00 GMT+0800">2025-02-25</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/categories/Natural-Language-Processing/">Natural Language Processing</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/tags/LLM/">LLM</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/NLP/">NLP</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/RAG/">RAG</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/en/nlp-llm-architecture-deep-dive/">Read more&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/en/nlp-fine-tuning-peft/">
                        NLP (8): Model Fine-tuning and PEFT
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>As large language models continue to grow in size, the cost of full fine-tuning has become increasingly prohibitive. Fine-tuning a model with billions of parameters requires updating all parameters, which not only demands massive computational resources but can also lead to catastrophic forgetting. To address these challenges, Parameter-Efficient Fine-Tuning (PEFT) techniques have emerged.</p>
<p>PEFT techniques achieve performance close to full fine-tuning by updating only a small fraction of model parameters. Methods like LoRA (Low-Rank Adaptation), QLoRA, Adapter, and Prefix-Tuning are representative examples. These approaches not only dramatically reduce computational costs but also make it possible to fine-tune large models on consumer-grade hardware.</p>
<p>This article delves into the differences between full fine-tuning and frozen fine-tuning, provides detailed explanations of PEFT techniques including LoRA, QLoRA, Adapter, Prefix-Tuning, and P-Tuning v2, introduces alignment techniques like Instruction Tuning and RLHF (Reinforcement Learning from Human Feedback), and demonstrates how to fine-tune large models using the HuggingFace PEFT library through practical examples.</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Sat Feb 22 2025 00:00:00 GMT+0800">2025-02-22</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/categories/Natural-Language-Processing/">Natural Language Processing</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/en/tags/LLM/">LLM</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/PEFT/">PEFT</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/en/tags/NLP/">NLP</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/en/nlp-fine-tuning-peft/">Read more&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
    </ul>

    <div class="home-paginator">
        <div class="paginator">
    

    
        <a class="next btn"
           href="/en/page/2/"
        >Next</a>
    
</div>

    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2020</span>
              -
            
            2026&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Chen Kai</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
            </div>
        
        <div class="theme-info info-item">
            <!-- Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.5</a> -->
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        
            <li class="tools-item rss flex-center">
                <a class="flex-center"
                   href="/atom.xml"
                   target="_blank"
                >
                    <i class="fas fa-rss"></i>
                </a>
            </li>
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>





<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>

<script src="/js/lang-switch.js"></script>



    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-copy.js"></script>





<div class="post-scripts pjax">
    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
