<!DOCTYPE html>



<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Chen Kai">
    
    <title>
        
            Recommendation Systems (13): Fairness, Debiasing, and Explainability |
        
        Chen Kai Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/logo.svg">
    
<link rel="stylesheet" href="/css/font-awesome.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"chenk.top","root":"/","language":"en","default_language":"zh-CN","languages":["zh-CN","en"],"path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":true},"style":{"primary_color":"#0066CC","avatar":"/images/avatar.svg","favicon":"/images/logo.svg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":false,"scale":false},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"Keep writing and Keep loving."},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":true,"style":"default"},"pjax":{"enable":true},"lazyload":{"enable":false},"version":"3.4.5"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
<meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="Chen Kai Blog" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    
    
    
    
    

    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/en/">
                Chen Kai Blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/en/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/en/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/en/categories"
                            >
                                CATEGORIES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/en/tags"
                            >
                                TAGS
                            </a>
                        </li>
                    
                    <li class="menu-item lang-switch lang-switch-trigger" title="Language">
                        <i class="fas fa-globe"></i>
                    </li>
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item lang-switch-trigger"><i class="fas fa-globe"></i></div>
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/en/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/en/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/en/categories">CATEGORIES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/en/tags">TAGS</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    
    
    
    

    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">Recommendation Systems (13): Fairness, Debiasing, and Explainability</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/avatar.svg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Chen Kai</span>
                        
                            <span class="author-label">BOSS</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    
    
    
    
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;
        <span class="pc">2025-11-16 00:00:00</span>
        <span class="mobile">2025-11-16 00:00</span>
    </span>
    
        <span class="article-categories article-meta-item">
            <i class="fas fa-folder"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/en/categories/Recommendation-Systems/">Recommendation Systems</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/en/tags/Recommendation-Systems/">Recommendation Systems</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/en/tags/Fairness/">Fairness</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/en/tags/Explainability/">Explainability</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fas fa-file-word"></i>&nbsp;<span>8.9k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fas fa-clock"></i>&nbsp;<span>55 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <p>When Netflix recommends "The Crown" to a user who watched "The
Queen," the system might appear to understand historical dramas, but
hidden biases could be at play: are historical dramas featuring women
being systematically under-recommended? When Amazon suggests products,
are certain demographics receiving lower-quality recommendations? These
questions highlight two critical challenges in modern recommendation
systems: fairness and explainability. As recommendation systems
increasingly influence what we watch, buy, and discover, ensuring they
are fair (treating all users and items equitably) and explainable
(providing transparent reasoning for recommendations) has become not
just an ethical imperative but a business necessity.</p>
<p>Fairness in recommendation systems addresses systematic biases that
can disadvantage certain user groups or item categories. These biases
can emerge from imbalanced training data, algorithmic design choices, or
feedback loops that amplify existing inequalities. Explainability, on
the other hand, addresses the "black box" problem: users and
stakeholders need to understand why recommendations are made, not just
accept them blindly. Together, fairness and explainability form the
foundation of trustworthy recommendation systems that users can rely on
and regulators can audit.</p>
<p>This article provides a comprehensive exploration of fairness and
explainability in recommendation systems, covering bias types and their
sources, causal inference foundations for understanding recommendation
effects, counterfactual reasoning for fair recommendation, CFairER
(Counterfactual Fairness in Recommendation), debiasing methods
(pre-processing, in-processing, and post-processing), explainable
recommendation techniques, attention visualization, LIME and SHAP for
model interpretation, trust-building strategies, and practical
implementations with 10+ code examples and detailed Q&amp;A sections
addressing common challenges and design decisions.</p>
<span id="more"></span>
<h2 id="understanding-bias-in-recommendation-systems">Understanding Bias
in Recommendation Systems</h2>
<h3 id="types-of-bias-in-recommendation-systems">Types of Bias in
Recommendation Systems</h3>
<p>Bias in recommendation systems manifests in multiple forms, each with
distinct causes and consequences:</p>
<p><strong>1. Popularity Bias</strong></p>
<p>Popularity bias occurs when recommendation systems disproportionately
favor popular items, creating a "rich get richer" effect where popular
items receive even more exposure while less popular items remain
obscure.</p>
<p>Mathematically, if <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="3.679ex" height="2.262ex" role="img" focusable="false" viewbox="0 -750 1626 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/></g><g data-mml-node="mo" transform="translate(503,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mi" transform="translate(892,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mo" transform="translate(1237,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g></g></g></svg></mjx-container></span> is the
popularity of item <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.781ex" height="1.52ex" role="img" focusable="false" viewbox="0 -661 345 672"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g></g></g></svg></mjx-container></span> (e.g., number
of interactions), and <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.675ex" height="2.19ex" role="img" focusable="false" viewbox="0 -810 1182.4 967.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mo" transform="translate(281.1,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"/></g></g></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(572,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g></g></g></g></g></svg></mjx-container></span>
is the predicted rating, popularity bias can be measured as:</p>
<p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.17ex;" xmlns="http://www.w3.org/2000/svg" width="42.726ex" height="5.805ex" role="img" focusable="false" viewbox="0 -1606.9 18884.7 2565.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="50" d="M130 622Q123 629 119 631T103 634T60 637H27V683H214Q237 683 276 683T331 684Q419 684 471 671T567 616Q624 563 624 489Q624 421 573 372T451 307Q429 302 328 301H234V181Q234 62 237 58Q245 47 304 46H337V0H326Q305 3 182 3Q47 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM507 488Q507 514 506 528T500 564T483 597T450 620T397 635Q385 637 307 637H286Q237 637 234 628Q231 624 231 483V342H302H339Q390 342 423 349T481 382Q507 411 507 488Z"/><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(681,0)"/><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" transform="translate(1181,0)"/><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(1737,0)"/><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(2293,0)"/><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2571,0)"/><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(3071,0)"/><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(3463,0)"/><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(3741,0)"/><path data-c="79" d="M69 -66Q91 -66 104 -80T118 -116Q118 -134 109 -145T91 -160Q84 -163 97 -166Q104 -168 111 -168Q131 -168 148 -159T175 -138T197 -106T213 -75T225 -43L242 0L170 183Q150 233 125 297Q101 358 96 368T80 381Q79 382 78 382Q66 385 34 385H19V431H26L46 430Q65 430 88 429T122 428Q129 428 142 428T171 429T200 430T224 430L233 431H241V385H232Q183 385 185 366L286 112Q286 113 332 227L376 341V350Q376 365 366 373T348 383T334 385H331V431H337H344Q351 431 361 431T382 430T405 429T422 429Q477 429 503 431H508V385H497Q441 380 422 345Q420 343 378 235T289 9T227 -131Q180 -204 113 -204Q69 -204 44 -177T19 -116Q19 -89 35 -78T69 -66Z" transform="translate(4130,0)"/><path data-c="20" d="" transform="translate(4658,0)"/><path data-c="42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z" transform="translate(4908,0)"/><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(5616,0)"/><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(5894,0)"/><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(6394,0)"/></g><g data-mml-node="mo" transform="translate(7065.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="mfrac" transform="translate(8121.6,0)"><g data-mml-node="mrow" transform="translate(220,856.9)"><g data-mml-node="munder"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"/></g><g data-mml-node="TeXAtom" transform="translate(1089,-285.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"/></g><g data-mml-node="msub" transform="translate(1012,0)"><g data-mml-node="mi"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"/></g><g data-mml-node="TeXAtom" transform="translate(473,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"/><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(392,0)"/><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(836,0)"/></g></g></g></g></g><g data-mml-node="mi" transform="translate(3031.1,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/></g><g data-mml-node="mo" transform="translate(3534.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mi" transform="translate(3923.1,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mo" transform="translate(4268.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g></g><g data-mml-node="mrow" transform="translate(1556.5,-709.5)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"/></g><g data-mml-node="msub" transform="translate(278,0)"><g data-mml-node="mi"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"/></g><g data-mml-node="TeXAtom" transform="translate(473,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"/><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(392,0)"/><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(836,0)"/></g></g></g><g data-mml-node="mo" transform="translate(1706.1,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"/></g></g><rect width="4857.1" height="60" x="120" y="220"/></g><g data-mml-node="mo" transform="translate(13440.9,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"/></g><g data-mml-node="mfrac" transform="translate(14441.1,0)"><g data-mml-node="mrow" transform="translate(220,773.6)"><g data-mml-node="munder"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"/></g><g data-mml-node="TeXAtom" transform="translate(1089,-285.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"/></g><g data-mml-node="mi" transform="translate(1012,0)"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"/></g></g></g><g data-mml-node="mi" transform="translate(2377.6,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/></g><g data-mml-node="mo" transform="translate(2880.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mi" transform="translate(3269.6,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mo" transform="translate(3614.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g></g><g data-mml-node="mrow" transform="translate(1691.8,-709.5)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"/></g><g data-mml-node="mi" transform="translate(278,0)"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"/></g><g data-mml-node="mo" transform="translate(782,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"/></g></g><rect width="4203.6" height="60" x="120" y="220"/></g></g></g></svg></mjx-container></span></p>
<p>where <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="3.231ex" height="1.902ex" role="img" focusable="false" viewbox="0 -683 1428.1 840.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"/></g><g data-mml-node="TeXAtom" transform="translate(473,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"/><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(392,0)"/><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(836,0)"/></g></g></g></g></g></svg></mjx-container></span> is the set
of recommended items and <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.14ex" height="1.545ex" role="img" focusable="false" viewbox="0 -683 504 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"/></g></g></g></svg></mjx-container></span> is the
entire item catalog.</p>
<p><strong>2. Gender Bias</strong></p>
<p>Gender bias occurs when recommendations systematically differ based
on user gender or when items associated with certain genders receive
unequal treatment. For example, a system might recommend action movies
more frequently to male users and romance movies to female users,
reinforcing stereotypes.</p>
<p><strong>3. Demographic Bias</strong></p>
<p>Demographic bias extends beyond gender to include race, age,
location, and other protected attributes. Systems may provide
lower-quality recommendations to certain demographic groups due to
imbalanced training data or algorithmic design.</p>
<p><strong>4. Confirmation Bias</strong></p>
<p>Confirmation bias occurs when systems reinforce users' existing
preferences without introducing diversity, creating "filter bubbles"
that limit exposure to new content.</p>
<p><strong>5. Position Bias</strong></p>
<p>Position bias refers to the tendency of users to interact more with
items shown at the top of recommendation lists, regardless of relevance.
This creates a feedback loop where top positions become
self-reinforcing.</p>
<p><strong>6. Selection Bias</strong></p>
<p>Selection bias arises from the fact that observed interactions are
not randomâ€”users only interact with items they're exposed to, creating a
biased sample of true preferences.</p>
<p><strong>7. Exposure Bias</strong></p>
<p>Exposure bias occurs when certain items or user groups receive
systematically less exposure in recommendations, leading to unfair
treatment.</p>
<h3 id="sources-of-bias">Sources of Bias</h3>
<p>Bias can originate from multiple sources:</p>
<p><strong>Data-Level Bias</strong>: - Historical discrimination
reflected in training data - Imbalanced representation of user groups or
item categories - Missing data from underrepresented groups</p>
<p><strong>Algorithm-Level Bias</strong>: - Optimization objectives that
favor popular items - Collaborative filtering amplifying existing
patterns - Lack of diversity constraints</p>
<p><strong>Feedback Loop Bias</strong>: - Users interact more with
recommended items - These interactions reinforce the recommendation
patterns - Creates a self-perpetuating cycle</p>
<p><strong>Evaluation Bias</strong>: - Metrics that don't account for
fairness - Test sets that don't represent all user groups - Offline
metrics that don't reflect real-world fairness</p>
<h3 id="measuring-bias">Measuring Bias</h3>
<p>To address bias, we must first measure it. Here's a comprehensive
bias measurement framework:</p>
<p><strong>Code Purpose:</strong> This code implements a comprehensive
bias measurement framework for recommendation systems. It provides
multiple metrics to quantify different types of biases (popularity bias,
demographic bias, diversity, etc.), enabling systematic evaluation of
fairness in recommendation systems.</p>
<p><strong>Overall Approach:</strong> 1. <strong>Multiple Bias
Metrics</strong>: Implements various bias measurement methods including
popularity bias, Gini coefficient, demographic parity, item coverage,
and diversity 2. <strong>Flexible Input</strong>: Accepts
recommendations, item popularity, and optional user/item group
information 3. <strong>Quantitative Analysis</strong>: Provides
numerical scores for each bias type, enabling comparison and tracking
over time 4. <strong>Comprehensive Coverage</strong>: Measures both
item-level biases (popularity, coverage) and user-level biases
(demographic parity)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Dict</span>, <span class="type">Set</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BiasMetrics</span>:</span><br><span class="line">    <span class="string">"""Comprehensive bias measurement for recommendation systems"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, recommendations: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="type">List</span>[<span class="built_in">int</span>]], </span></span><br><span class="line"><span class="params">                 item_popularity: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">                 user_groups: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">str</span>] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 item_groups: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">str</span>] = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            recommendations: {user_id: [item_id, ...]} - recommendations per user</span></span><br><span class="line"><span class="string">            item_popularity: {item_id: popularity_count} - popularity of each item</span></span><br><span class="line"><span class="string">            user_groups: {user_id: group} - user demographic groups</span></span><br><span class="line"><span class="string">            item_groups: {item_id: group} - item category groups</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.recommendations = recommendations</span><br><span class="line">        self.item_popularity = item_popularity</span><br><span class="line">        self.user_groups = user_groups <span class="keyword">or</span> {}</span><br><span class="line">        self.item_groups = item_groups <span class="keyword">or</span> {}</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">popularity_bias</span>(<span class="params">self, top_k: <span class="built_in">int</span> = <span class="number">10</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Measure popularity bias: how much recommendations favor popular items.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Popularity bias score (higher = more biased toward popular items)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        all_items = <span class="built_in">set</span>(self.item_popularity.keys())</span><br><span class="line">        recommended_items = <span class="built_in">set</span>()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> user_recs <span class="keyword">in</span> self.recommendations.values():</span><br><span class="line">            recommended_items.update(user_recs[:top_k])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Average popularity of recommended vs. all items</span></span><br><span class="line">        rec_popularity = np.mean([self.item_popularity.get(i, <span class="number">0</span>) </span><br><span class="line">                                  <span class="keyword">for</span> i <span class="keyword">in</span> recommended_items])</span><br><span class="line">        all_popularity = np.mean([self.item_popularity.get(i, <span class="number">0</span>) </span><br><span class="line">                                  <span class="keyword">for</span> i <span class="keyword">in</span> all_items])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> rec_popularity / (all_popularity + <span class="number">1e-10</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">gini_coefficient</span>(<span class="params">self, top_k: <span class="built_in">int</span> = <span class="number">10</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Measure inequality in item exposure using Gini coefficient.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Gini coefficient (0 = perfect equality, 1 = maximum inequality)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        item_exposure = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> user_recs <span class="keyword">in</span> self.recommendations.values():</span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> user_recs[:top_k]:</span><br><span class="line">                item_exposure[item] += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        exposures = np.array(<span class="built_in">list</span>(item_exposure.values()))</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(exposures) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Sort exposures</span></span><br><span class="line">        exposures = np.sort(exposures)</span><br><span class="line">        n = <span class="built_in">len</span>(exposures)</span><br><span class="line">        cumsum = np.cumsum(exposures)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Gini coefficient formula</span></span><br><span class="line">        gini = (<span class="number">2</span> * np.<span class="built_in">sum</span>((np.arange(<span class="number">1</span>, n + <span class="number">1</span>)) * exposures)) / (n * np.<span class="built_in">sum</span>(exposures)) - (n + <span class="number">1</span>) / n</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> gini</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">demographic_parity</span>(<span class="params">self, top_k: <span class="built_in">int</span> = <span class="number">10</span></span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">float</span>]:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Measure demographic parity: equal recommendation quality across groups.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Dictionary mapping group to average recommendation count</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.user_groups:</span><br><span class="line">            <span class="keyword">return</span> {}</span><br><span class="line">        </span><br><span class="line">        group_recs = defaultdict(<span class="built_in">list</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> user_id, recs <span class="keyword">in</span> self.recommendations.items():</span><br><span class="line">            group = self.user_groups.get(user_id, <span class="string">"unknown"</span>)</span><br><span class="line">            group_recs[group].append(<span class="built_in">len</span>(recs[:top_k]))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> {group: np.mean(counts) </span><br><span class="line">                <span class="keyword">for</span> group, counts <span class="keyword">in</span> group_recs.items()}</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">item_coverage</span>(<span class="params">self, top_k: <span class="built_in">int</span> = <span class="number">10</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Measure catalog coverage: fraction of items that appear in recommendations.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Coverage ratio (0 to 1)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        all_items = <span class="built_in">set</span>(self.item_popularity.keys())</span><br><span class="line">        recommended_items = <span class="built_in">set</span>()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> user_recs <span class="keyword">in</span> self.recommendations.values():</span><br><span class="line">            recommended_items.update(user_recs[:top_k])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(recommended_items) / <span class="built_in">len</span>(all_items) <span class="keyword">if</span> all_items <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">diversity</span>(<span class="params">self, item_features: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="type">List</span>[<span class="built_in">float</span>]] = <span class="literal">None</span>, </span></span><br><span class="line"><span class="params">                  top_k: <span class="built_in">int</span> = <span class="number">10</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Measure recommendation diversity.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            item_features: {item_id: feature_vector} - item feature vectors</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Average pairwise distance between recommended items</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> item_features <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># Use simple category-based diversity</span></span><br><span class="line">            all_dists = []</span><br><span class="line">            <span class="keyword">for</span> user_recs <span class="keyword">in</span> self.recommendations.values():</span><br><span class="line">                recs = user_recs[:top_k]</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(recs) &lt; <span class="number">2</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment"># Count unique categories</span></span><br><span class="line">                categories = [self.item_groups.get(i, <span class="string">"unknown"</span>) </span><br><span class="line">                             <span class="keyword">for</span> i <span class="keyword">in</span> recs]</span><br><span class="line">                unique_ratio = <span class="built_in">len</span>(<span class="built_in">set</span>(categories)) / <span class="built_in">len</span>(categories)</span><br><span class="line">                all_dists.append(unique_ratio)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">return</span> np.mean(all_dists) <span class="keyword">if</span> all_dists <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Feature-based diversity</span></span><br><span class="line">        all_dists = []</span><br><span class="line">        <span class="keyword">for</span> user_recs <span class="keyword">in</span> self.recommendations.values():</span><br><span class="line">            recs = user_recs[:top_k]</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(recs) &lt; <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line">            features = [item_features.get(i) <span class="keyword">for</span> i <span class="keyword">in</span> recs </span><br><span class="line">                      <span class="keyword">if</span> i <span class="keyword">in</span> item_features]</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(features) &lt; <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Compute pairwise distances</span></span><br><span class="line">            features = np.array(features)</span><br><span class="line">            distances = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(features)):</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(features)):</span><br><span class="line">                    dist = np.linalg.norm(features[i] - features[j])</span><br><span class="line">                    distances.append(dist)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> distances:</span><br><span class="line">                all_dists.append(np.mean(distances))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> np.mean(all_dists) <span class="keyword">if</span> all_dists <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">comprehensive_report</span>(<span class="params">self, top_k: <span class="built_in">int</span> = <span class="number">10</span></span>) -&gt; <span class="type">Dict</span>:</span><br><span class="line">        <span class="string">"""Generate comprehensive bias report"""</span></span><br><span class="line">        <span class="keyword">return</span> {</span><br><span class="line">            <span class="string">"popularity_bias"</span>: self.popularity_bias(top_k),</span><br><span class="line">            <span class="string">"gini_coefficient"</span>: self.gini_coefficient(top_k),</span><br><span class="line">            <span class="string">"demographic_parity"</span>: self.demographic_parity(top_k),</span><br><span class="line">            <span class="string">"item_coverage"</span>: self.item_coverage(top_k),</span><br><span class="line">            <span class="string">"diversity"</span>: self.diversity(top_k=top_k)</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Example usage</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># Sample data</span></span><br><span class="line">    recommendations = {</span><br><span class="line">        <span class="number">1</span>: [<span class="number">101</span>, <span class="number">102</span>, <span class="number">103</span>, <span class="number">104</span>, <span class="number">105</span>],</span><br><span class="line">        <span class="number">2</span>: [<span class="number">101</span>, <span class="number">106</span>, <span class="number">107</span>, <span class="number">108</span>, <span class="number">109</span>],</span><br><span class="line">        <span class="number">3</span>: [<span class="number">102</span>, <span class="number">103</span>, <span class="number">110</span>, <span class="number">111</span>, <span class="number">112</span>]</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    item_popularity = {</span><br><span class="line">        <span class="number">101</span>: <span class="number">1000</span>, <span class="number">102</span>: <span class="number">800</span>, <span class="number">103</span>: <span class="number">600</span>, <span class="number">104</span>: <span class="number">400</span>, <span class="number">105</span>: <span class="number">200</span>,</span><br><span class="line">        <span class="number">106</span>: <span class="number">150</span>, <span class="number">107</span>: <span class="number">100</span>, <span class="number">108</span>: <span class="number">50</span>, <span class="number">109</span>: <span class="number">30</span>, <span class="number">110</span>: <span class="number">20</span>, <span class="number">111</span>: <span class="number">10</span>, <span class="number">112</span>: <span class="number">5</span></span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    user_groups = {<span class="number">1</span>: <span class="string">"group_A"</span>, <span class="number">2</span>: <span class="string">"group_A"</span>, <span class="number">3</span>: <span class="string">"group_B"</span>}</span><br><span class="line">    item_groups = {i: <span class="string">f"category_<span class="subst">{i % <span class="number">3</span>}</span>"</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">101</span>, <span class="number">113</span>)}</span><br><span class="line">    </span><br><span class="line">    metrics = BiasMetrics(recommendations, item_popularity, </span><br><span class="line">                         user_groups, item_groups)</span><br><span class="line">    report = metrics.comprehensive_report()</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"Bias Report:"</span>)</span><br><span class="line">    <span class="keyword">for</span> metric, value <span class="keyword">in</span> report.items():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"<span class="subst">{metric}</span>: <span class="subst">{value}</span>"</span>)</span><br></pre></td></tr></table></figure>
<h2 id="causal-inference-foundations">Causal Inference Foundations</h2>
<h3 id="why-causal-inference-matters">Why Causal Inference Matters</h3>
<p>Traditional recommendation systems learn correlations: "users who
watched X also watched Y." But correlations don't imply causation.
Causal inference helps us understand: - <strong>Why</strong>
recommendations work (causal mechanisms) - <strong>What would
happen</strong> if we changed the recommendation strategy
(counterfactuals) - <strong>Whether</strong> recommendations cause user
satisfaction or just correlate with it</p>
<h3 id="basic-causal-concepts">Basic Causal Concepts</h3>
<p><strong>Potential Outcomes Framework</strong></p>
<p>For a user <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.294ex" height="1.025ex" role="img" focusable="false" viewbox="0 -442 572 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g></g></g></svg></mjx-container></span> and item <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.781ex" height="1.52ex" role="img" focusable="false" viewbox="0 -661 345 672"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g></g></g></svg></mjx-container></span>, we define: - <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="5.861ex" height="2.262ex" role="img" focusable="false" viewbox="0 -750 2590.4 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"/></g><g data-mml-node="TeXAtom" transform="translate(614,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(572,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g></g></g><g data-mml-node="mo" transform="translate(1312.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mn" transform="translate(1701.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g><g data-mml-node="mo" transform="translate(2201.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g></g></g></svg></mjx-container></span>: outcome if item <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.781ex" height="1.52ex" role="img" focusable="false" viewbox="0 -661 345 672"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g></g></g></svg></mjx-container></span> is recommended (treatment = 1) - <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="5.861ex" height="2.262ex" role="img" focusable="false" viewbox="0 -750 2590.4 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"/></g><g data-mml-node="TeXAtom" transform="translate(614,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(572,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g></g></g><g data-mml-node="mo" transform="translate(1312.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mn" transform="translate(1701.4,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"/></g><g data-mml-node="mo" transform="translate(2201.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g></g></g></svg></mjx-container></span>: outcome if item <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.781ex" height="1.52ex" role="img" focusable="false" viewbox="0 -661 345 672"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g></g></g></svg></mjx-container></span> is not recommended (treatment = 0)</p>
<p>The <strong>Individual Treatment Effect (ITE)</strong> is: <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="23.15ex" height="2.262ex" role="img" focusable="false" viewbox="0 -750 10232.3 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mtext"><path data-c="49" d="M328 0Q307 3 180 3T32 0H21V46H43Q92 46 106 49T126 60Q128 63 128 342Q128 620 126 623Q122 628 118 630T96 635T43 637H21V683H32Q53 680 180 680T328 683H339V637H317Q268 637 254 634T234 623Q232 620 232 342Q232 63 234 60Q238 55 242 53T264 48T317 46H339V0H328Z"/><path data-c="54" d="M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z" transform="translate(361,0)"/><path data-c="45" d="M128 619Q121 626 117 628T101 631T58 634H25V680H597V676Q599 670 611 560T625 444V440H585V444Q584 447 582 465Q578 500 570 526T553 571T528 601T498 619T457 629T411 633T353 634Q266 634 251 633T233 622Q233 622 233 621Q232 619 232 497V376H286Q359 378 377 385Q413 401 416 469Q416 471 416 473V493H456V213H416V233Q415 268 408 288T383 317T349 328T297 330Q290 330 286 330H232V196V114Q232 57 237 52Q243 47 289 47H340H391Q428 47 452 50T505 62T552 92T584 146Q594 172 599 200T607 247T612 270V273H652V270Q651 267 632 137T610 3V0H25V46H58Q100 47 109 49T128 61V619Z" transform="translate(1083,0)"/></g><g data-mml-node="TeXAtom" transform="translate(1797,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(572,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g></g></g><g data-mml-node="mo" transform="translate(2773.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="msub" transform="translate(3829,0)"><g data-mml-node="mi"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"/></g><g data-mml-node="TeXAtom" transform="translate(614,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(572,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g></g></g><g data-mml-node="mo" transform="translate(5141.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mn" transform="translate(5530.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g><g data-mml-node="mo" transform="translate(6030.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g><g data-mml-node="mo" transform="translate(6641.6,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"/></g><g data-mml-node="msub" transform="translate(7641.8,0)"><g data-mml-node="mi"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"/></g><g data-mml-node="TeXAtom" transform="translate(614,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(572,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g></g></g><g data-mml-node="mo" transform="translate(8954.3,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mn" transform="translate(9343.3,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"/></g><g data-mml-node="mo" transform="translate(9843.3,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g></g></g></svg></mjx-container></span></p>
<p>Since we can only observe one outcome, we estimate the
<strong>Average Treatment Effect (ATE)</strong>: <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="25.142ex" height="2.262ex" role="img" focusable="false" viewbox="0 -750 11112.8 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="41" d="M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z"/><path data-c="54" d="M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z" transform="translate(750,0)"/><path data-c="45" d="M128 619Q121 626 117 628T101 631T58 634H25V680H597V676Q599 670 611 560T625 444V440H585V444Q584 447 582 465Q578 500 570 526T553 571T528 601T498 619T457 629T411 633T353 634Q266 634 251 633T233 622Q233 622 233 621Q232 619 232 497V376H286Q359 378 377 385Q413 401 416 469Q416 471 416 473V493H456V213H416V233Q415 268 408 288T383 317T349 328T297 330Q290 330 286 330H232V196V114Q232 57 237 52Q243 47 289 47H340H391Q428 47 452 50T505 62T552 92T584 146Q594 172 599 200T607 247T612 270V273H652V270Q651 267 632 137T610 3V0H25V46H58Q100 47 109 49T128 61V619Z" transform="translate(1472,0)"/></g><g data-mml-node="mo" transform="translate(2430.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(3486.6,0)"><g data-mml-node="mi"><path data-c="1D53C" d="M12 666Q12 675 24 683H582Q590 680 593 672V588Q593 514 591 502T575 490Q567 490 563 495T555 517Q552 556 517 590Q486 623 445 634T340 648H282Q266 636 264 620T260 492V370H277Q329 375 358 391T404 439Q420 480 420 506Q420 529 436 529Q445 529 451 521Q455 517 455 361Q455 333 455 298T456 253Q456 217 453 207T437 197Q420 196 420 217Q420 240 406 270Q377 328 284 335H260V201Q261 174 261 134Q262 73 264 61T278 38Q281 36 282 35H331Q400 35 449 50Q571 93 602 179Q605 203 622 203Q629 203 634 197T640 183Q638 181 624 95T604 3L600 -1H24Q12 5 12 16Q12 35 51 35Q92 38 97 52Q102 60 102 341T97 632Q91 645 51 648Q12 648 12 666ZM137 341Q137 131 136 89T130 37Q129 36 129 35H235Q233 41 231 48L226 61V623L231 635L235 648H129Q132 641 133 638T135 603T137 517T137 341ZM557 603V648H504Q504 646 515 639Q527 634 542 619L557 603ZM420 317V397L406 383Q394 370 380 363L366 355Q373 350 382 346Q400 333 409 328L420 317ZM582 61L586 88Q585 88 582 83Q557 61 526 46L511 37L542 35H577Q577 36 578 39T580 49T582 61Z"/></g></g><g data-mml-node="mo" transform="translate(4153.6,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"/></g><g data-mml-node="msub" transform="translate(4431.6,0)"><g data-mml-node="mi"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"/></g><g data-mml-node="TeXAtom" transform="translate(614,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(572,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g></g></g><g data-mml-node="mo" transform="translate(5744,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mn" transform="translate(6133,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g><g data-mml-node="mo" transform="translate(6633,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g><g data-mml-node="mo" transform="translate(7244.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"/></g><g data-mml-node="msub" transform="translate(8244.4,0)"><g data-mml-node="mi"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"/></g><g data-mml-node="TeXAtom" transform="translate(614,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(572,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g></g></g><g data-mml-node="mo" transform="translate(9556.8,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mn" transform="translate(9945.8,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"/></g><g data-mml-node="mo" transform="translate(10445.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g><g data-mml-node="mo" transform="translate(10834.8,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"/></g></g></g></svg></mjx-container></span></p>
<p><strong>Confounding Variables</strong></p>
<p>Confounders are variables that affect both treatment (recommendation)
and outcome (user satisfaction). For example: - User preference affects
both what gets recommended and satisfaction - Item popularity affects
both recommendation probability and user interaction</p>
<p><strong>Causal Graph</strong></p>
<p>A causal graph represents relationships between variables:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">User Preference â†’ Recommendation â†’ User Satisfaction</span><br><span class="line">       â†“                              â†‘</span><br><span class="line">    Item Quality â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span><br></pre></td></tr></table></figure>
<h3 id="causal-inference-methods">Causal Inference Methods</h3>
<p><strong>1. Randomized Controlled Trials (RCT)</strong></p>
<p>The gold standard: randomly assign recommendations and measure
outcomes.</p>
<p><strong>Code Purpose:</strong> This code implements a Randomized
Controlled Trial (RCT) framework for recommendation systems, which is
the gold standard for causal inference. RCTs randomly assign
recommendations to users, eliminating selection bias and providing
unbiased estimates of recommendation effects.</p>
<p><strong>Overall Approach:</strong> 1. <strong>Random Treatment
Assignment</strong>: Randomly assign recommendations with a specified
probability 2. <strong>Outcome Recording</strong>: Track user outcomes
(ratings, clicks) for both treated and control groups 3. <strong>ATE
Estimation</strong>: Calculate Average Treatment Effect by comparing
treated and control group outcomes 4. <strong>ITE
Approximation</strong>: Estimate Individual Treatment Effect using
matching methods (simplified implementation)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Tuple</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RCTRecommender</span>:</span><br><span class="line">    <span class="string">"""Randomized Controlled Trial for recommendation"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, items: <span class="type">List</span>[<span class="built_in">int</span>], treatment_prob: <span class="built_in">float</span> = <span class="number">0.5</span></span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            items: List of item IDs</span></span><br><span class="line"><span class="string">            treatment_prob: Probability of recommending each item</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.items = items</span><br><span class="line">        self.treatment_prob = treatment_prob</span><br><span class="line">        self.treatment_assignment = {}</span><br><span class="line">        self.outcomes = {}</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">assign_treatment</span>(<span class="params">self, user_id: <span class="built_in">int</span>, item_id: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Randomly assign treatment (recommendation).</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            True if item is recommended, False otherwise</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        np.random.seed(<span class="built_in">hash</span>((user_id, item_id)) % <span class="number">2</span>**<span class="number">32</span>)</span><br><span class="line">        assigned = np.random.random() &lt; self.treatment_prob</span><br><span class="line">        </span><br><span class="line">        self.treatment_assignment[(user_id, item_id)] = assigned</span><br><span class="line">        <span class="keyword">return</span> assigned</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">record_outcome</span>(<span class="params">self, user_id: <span class="built_in">int</span>, item_id: <span class="built_in">int</span>, outcome: <span class="built_in">float</span></span>):</span><br><span class="line">        <span class="string">"""Record user outcome (e.g., rating, click)"""</span></span><br><span class="line">        self.outcomes[(user_id, item_id)] = outcome</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">estimate_ate</span>(<span class="params">self</span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Estimate Average Treatment Effect.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            ATE estimate</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        treatment_outcomes = []</span><br><span class="line">        control_outcomes = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (user_id, item_id), outcome <span class="keyword">in</span> self.outcomes.items():</span><br><span class="line">            <span class="keyword">if</span> self.treatment_assignment.get((user_id, item_id), <span class="literal">False</span>):</span><br><span class="line">                treatment_outcomes.append(outcome)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                control_outcomes.append(outcome)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> treatment_outcomes <span class="keyword">or</span> <span class="keyword">not</span> control_outcomes:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line">        </span><br><span class="line">        ate = np.mean(treatment_outcomes) - np.mean(control_outcomes)</span><br><span class="line">        <span class="keyword">return</span> ate</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">estimate_ite</span>(<span class="params">self, user_id: <span class="built_in">int</span>, item_id: <span class="built_in">int</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Estimate Individual Treatment Effect using matching.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Note: True ITE is unobservable, this is an approximation.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># Find similar users who didn't receive treatment</span></span><br><span class="line">        <span class="comment"># This is simplified - real implementation would use matching</span></span><br><span class="line">        treatment_outcome = self.outcomes.get((user_id, item_id), <span class="literal">None</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> treatment_outcome <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Estimate control outcome from similar users</span></span><br><span class="line">        <span class="comment"># (simplified - would use propensity score matching in practice)</span></span><br><span class="line">        control_outcomes = [</span><br><span class="line">            outcome <span class="keyword">for</span> (uid, iid), outcome <span class="keyword">in</span> self.outcomes.items()</span><br><span class="line">            <span class="keyword">if</span> uid != user_id <span class="keyword">and</span> iid == item_id</span><br><span class="line">            <span class="keyword">and</span> <span class="keyword">not</span> self.treatment_assignment.get((uid, iid), <span class="literal">False</span>)</span><br><span class="line">        ]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> control_outcomes:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line">        </span><br><span class="line">        control_outcome = np.mean(control_outcomes)</span><br><span class="line">        <span class="keyword">return</span> treatment_outcome - control_outcome</span><br></pre></td></tr></table></figure>
<p><strong>2. Propensity Score Matching</strong></p>
<p>Match treated and control units with similar propensity scores
(probability of treatment).</p>
<p><strong>Code Purpose:</strong> This code implements Propensity Score
Matching (PSM), a causal inference method that matches treated and
control units with similar propensity scores (probability of receiving
treatment). This helps eliminate confounding bias when random assignment
is not possible.</p>
<p><strong>Overall Approach:</strong> 1. <strong>Propensity Score
Estimation</strong>: Use logistic regression to estimate the probability
of treatment given covariates 2. <strong>Matching</strong>: Match each
treated unit with the nearest control unit based on propensity scores 3.
<strong>ATE Estimation</strong>: Calculate Average Treatment Effect
using matched pairs, reducing bias from confounding variables</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> NearestNeighbors</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PropensityScoreMatching</span>:</span><br><span class="line">    <span class="string">"""Propensity score matching for causal inference"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.propensity_model = LogisticRegression()</span><br><span class="line">        self.nn_model = NearestNeighbors(n_neighbors=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit_propensity_model</span>(<span class="params">self, X: np.ndarray, treatment: np.ndarray</span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Fit propensity score model.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            X: User/item features</span></span><br><span class="line"><span class="string">            treatment: Binary treatment indicator</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.propensity_model.fit(X, treatment)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute_propensity_scores</span>(<span class="params">self, X: np.ndarray</span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">"""Compute propensity scores"""</span></span><br><span class="line">        <span class="keyword">return</span> self.propensity_model.predict_proba(X)[:, <span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">match</span>(<span class="params">self, X_treated: np.ndarray, X_control: np.ndarray,</span></span><br><span class="line"><span class="params">              propensity_treated: np.ndarray, </span></span><br><span class="line"><span class="params">              propensity_control: np.ndarray</span>) -&gt; <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]]:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Match treated and control units.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            List of (treated_idx, control_idx) pairs</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># Build nearest neighbor index on control units</span></span><br><span class="line">        self.nn_model.fit(propensity_control.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        matches = []</span><br><span class="line">        <span class="keyword">for</span> i, ps <span class="keyword">in</span> <span class="built_in">enumerate</span>(propensity_treated):</span><br><span class="line">            <span class="comment"># Find nearest control unit</span></span><br><span class="line">            distances, indices = self.nn_model.kneighbors(</span><br><span class="line">                ps.reshape(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">            )</span><br><span class="line">            matches.append((i, indices[<span class="number">0</span>][<span class="number">0</span>]))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> matches</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">estimate_ate</span>(<span class="params">self, X_treated: np.ndarray, X_control: np.ndarray,</span></span><br><span class="line"><span class="params">                     y_treated: np.ndarray, y_control: np.ndarray</span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">"""Estimate ATE using propensity score matching"""</span></span><br><span class="line">        <span class="comment"># Compute propensity scores</span></span><br><span class="line">        ps_treated = self.compute_propensity_scores(X_treated)</span><br><span class="line">        ps_control = self.compute_propensity_scores(X_control)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Match</span></span><br><span class="line">        matches = self.<span class="keyword">match</span>(X_treated, X_control, ps_treated, ps_control)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute matched outcomes</span></span><br><span class="line">        matched_diffs = []</span><br><span class="line">        <span class="keyword">for</span> treated_idx, control_idx <span class="keyword">in</span> matches:</span><br><span class="line">            diff = y_treated[treated_idx] - y_control[control_idx]</span><br><span class="line">            matched_diffs.append(diff)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> np.mean(matched_diffs)</span><br></pre></td></tr></table></figure>
<p><strong>3. Instrumental Variables</strong></p>
<p>Use variables that affect treatment but not outcome directly.</p>
<p><strong>Code Purpose:</strong> This code implements Instrumental
Variable (IV) estimation using Two-Stage Least Squares (2SLS). IV
methods are used when treatment assignment is not random and there are
unobserved confounders. An instrumental variable affects treatment but
not outcome directly, allowing us to identify causal effects.</p>
<p><strong>Overall Approach:</strong> 1. <strong>First Stage</strong>:
Predict treatment from instrumental variables and confounders 2.
<strong>Second Stage</strong>: Predict outcome from predicted treatment
and confounders 3. <strong>ATE Estimation</strong>: Extract the
treatment coefficient from the second stage model as the causal effect
estimate</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">InstrumentalVariableEstimator</span>:</span><br><span class="line">    <span class="string">"""Instrumental variable estimation for causal inference"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.first_stage_model = <span class="literal">None</span></span><br><span class="line">        self.second_stage_model = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, Z: np.ndarray, X: np.ndarray, treatment: np.ndarray,</span></span><br><span class="line"><span class="params">            outcome: np.ndarray</span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Two-stage least squares (2SLS).</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            Z: Instrumental variables</span></span><br><span class="line"><span class="string">            X: Confounders</span></span><br><span class="line"><span class="string">            treatment: Treatment variable</span></span><br><span class="line"><span class="string">            outcome: Outcome variable</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># First stage: predict treatment from instruments</span></span><br><span class="line">        self.first_stage_model = LinearRegression()</span><br><span class="line">        ZX = np.hstack([Z, X])</span><br><span class="line">        self.first_stage_model.fit(ZX, treatment)</span><br><span class="line">        treatment_pred = self.first_stage_model.predict(ZX)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Second stage: predict outcome from predicted treatment</span></span><br><span class="line">        self.second_stage_model = LinearRegression()</span><br><span class="line">        treatment_X = np.hstack([treatment_pred.reshape(-<span class="number">1</span>, <span class="number">1</span>), X])</span><br><span class="line">        self.second_stage_model.fit(treatment_X, outcome)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">estimate_ate</span>(<span class="params">self</span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">"""Estimate ATE from second stage model"""</span></span><br><span class="line">        <span class="comment"># Coefficient on treatment variable</span></span><br><span class="line">        <span class="keyword">return</span> self.second_stage_model.coef_[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<h2 id="counterfactual-reasoning">Counterfactual Reasoning</h2>
<h3 id="what-are-counterfactuals">What Are Counterfactuals?</h3>
<p>Counterfactuals answer "what if" questions: "What would have happened
if we recommended a different item?" This is crucial for: -
<strong>Fairness</strong>: Ensuring recommendations would be similar for
similar users regardless of protected attributes -
<strong>Explainability</strong>: Understanding why recommendations were
made - <strong>Debiasing</strong>: Identifying and correcting unfair
patterns</p>
<h3 id="counterfactual-fairness">Counterfactual Fairness</h3>
<p>A recommendation system is counterfactually fair if, for any user,
changing their protected attributes (e.g., gender, race) while keeping
other attributes constant would not change the recommendations.</p>
<p>Formally, for protected attribute <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.697ex" height="1.62ex" role="img" focusable="false" viewbox="0 -716 750 716"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"/></g></g></g></svg></mjx-container></span> and recommendation function <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="1.244ex" height="2.059ex" role="img" focusable="false" viewbox="0 -705 550 910"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"/></g></g></g></svg></mjx-container></span>: <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="70.709ex" height="2.396ex" role="img" focusable="false" viewbox="0 -809 31253.6 1059"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"/></g><g data-mml-node="mo" transform="translate(751,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mi" transform="translate(1140,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"/></g><g data-mml-node="mo" transform="translate(1690,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mi" transform="translate(2079,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"/></g><g data-mml-node="mo" transform="translate(2931,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"/></g><g data-mml-node="mi" transform="translate(3375.7,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"/></g><g data-mml-node="mo" transform="translate(4403.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="mi" transform="translate(5459.2,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"/></g><g data-mml-node="mo" transform="translate(5988.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g><g data-mml-node="mo" transform="translate(6655,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="mi" transform="translate(7710.8,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mo" transform="translate(8200.8,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"/></g><g data-mml-node="mi" transform="translate(8478.8,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"/></g><g data-mml-node="mo" transform="translate(9608.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="mi" transform="translate(10664.3,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mo" transform="translate(11236.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"/></g><g data-mml-node="mi" transform="translate(11681,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"/></g><g data-mml-node="mo" transform="translate(12708.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="mi" transform="translate(13764.6,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"/></g><g data-mml-node="mo" transform="translate(14293.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g><g data-mml-node="mo" transform="translate(14960.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="mi" transform="translate(16016.1,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"/></g><g data-mml-node="mo" transform="translate(16767.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mi" transform="translate(17156.1,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"/></g><g data-mml-node="mo" transform="translate(17706.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mi" transform="translate(18095.1,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"/></g><g data-mml-node="mo" transform="translate(18947.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"/></g><g data-mml-node="mi" transform="translate(19391.8,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"/></g><g data-mml-node="mo" transform="translate(20419.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="msup" transform="translate(21475.3,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"/></g><g data-mml-node="mo" transform="translate(562,413) scale(0.707)"><path data-c="2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"/></g></g><g data-mml-node="mo" transform="translate(22281.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g><g data-mml-node="mo" transform="translate(22948.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="mi" transform="translate(24004.3,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mo" transform="translate(24494.3,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"/></g><g data-mml-node="mi" transform="translate(24772.3,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"/></g><g data-mml-node="mo" transform="translate(25902.1,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="mi" transform="translate(26957.9,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mo" transform="translate(27529.9,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"/></g><g data-mml-node="mi" transform="translate(27974.6,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"/></g><g data-mml-node="mo" transform="translate(29002.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="msup" transform="translate(30058.1,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"/></g><g data-mml-node="mo" transform="translate(562,413) scale(0.707)"><path data-c="2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"/></g></g><g data-mml-node="mo" transform="translate(30864.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g></g></g></svg></mjx-container></span></p>
<p>for all <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="4.027ex" height="2.156ex" role="img" focusable="false" viewbox="0 -759 1780.1 953"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"/></g><g data-mml-node="mo" transform="translate(529,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"/></g><g data-mml-node="msup" transform="translate(973.7,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"/></g><g data-mml-node="mo" transform="translate(562,363) scale(0.707)"><path data-c="2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"/></g></g></g></g></svg></mjx-container></span> and <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="3.409ex" height="1.464ex" role="img" focusable="false" viewbox="0 -442 1506.7 647"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mo" transform="translate(572,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"/></g><g data-mml-node="mi" transform="translate(1016.7,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g></g></g></svg></mjx-container></span>.</p>
<h3 id="implementing-counterfactual-reasoning">Implementing
Counterfactual Reasoning</h3>
<p><strong>Code Purpose:</strong> This code implements a counterfactual
reasoning framework for fair recommendation. It enables answering "what
if" questions: what would happen if we changed a user's protected
attributes (e.g., gender, race) while keeping other attributes constant?
This is crucial for ensuring counterfactual fairness.</p>
<p><strong>Overall Approach:</strong> 1. <strong>Embedding-Based
Model</strong>: Use user and item embeddings to predict recommendation
scores 2. <strong>Protected Attribute Handling</strong>: Allow
specification of protected attributes for users 3.
<strong>Counterfactual Generation</strong>: Generate counterfactual
recommendations by changing protected attributes 4. <strong>Fairness
Evaluation</strong>: Compare factual and counterfactual recommendations
to assess fairness</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Dict</span>, <span class="type">List</span>, <span class="type">Tuple</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CounterfactualRecommender</span>:</span><br><span class="line">    <span class="string">"""Counterfactual reasoning for fair recommendation"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_users: <span class="built_in">int</span>, num_items: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                 embedding_dim: <span class="built_in">int</span> = <span class="number">64</span></span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            num_users: Number of users</span></span><br><span class="line"><span class="string">            num_items: Number of items</span></span><br><span class="line"><span class="string">            embedding_dim: Embedding dimension</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.user_embedding = nn.Embedding(num_users, embedding_dim)</span><br><span class="line">        self.item_embedding = nn.Embedding(num_items, embedding_dim)</span><br><span class="line">        self.predictor = nn.Sequential(</span><br><span class="line">            nn.Linear(embedding_dim * <span class="number">2</span>, <span class="number">128</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">128</span>, <span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.protected_attributes = {}  <span class="comment"># {user_id: protected_attr}</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set_protected_attributes</span>(<span class="params">self, protected_attrs: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]</span>):</span><br><span class="line">        <span class="string">"""Set protected attributes for users"""</span></span><br><span class="line">        self.protected_attributes = protected_attrs</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, user_ids: torch.Tensor, item_ids: torch.Tensor,</span></span><br><span class="line"><span class="params">                counterfactual_attrs: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">int</span>] = <span class="literal">None</span></span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Forward pass with optional counterfactual attributes.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_ids: User IDs</span></span><br><span class="line"><span class="string">            item_ids: Item IDs</span></span><br><span class="line"><span class="string">            counterfactual_attrs: Counterfactual protected attributes</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Prediction scores</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        user_emb = self.user_embedding(user_ids)</span><br><span class="line">        item_emb = self.item_embedding(item_ids)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Apply counterfactual transformation if specified</span></span><br><span class="line">        <span class="keyword">if</span> counterfactual_attrs:</span><br><span class="line">            user_emb = self._apply_counterfactual(user_emb, user_ids, </span><br><span class="line">                                                  counterfactual_attrs)</span><br><span class="line">        </span><br><span class="line">        combined = torch.cat([user_emb, item_emb], dim=<span class="number">1</span>)</span><br><span class="line">        scores = self.predictor(combined)</span><br><span class="line">        <span class="keyword">return</span> scores</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_apply_counterfactual</span>(<span class="params">self, user_emb: torch.Tensor,</span></span><br><span class="line"><span class="params">                              user_ids: torch.Tensor,</span></span><br><span class="line"><span class="params">                              counterfactual_attrs: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Apply counterfactual transformation to embeddings.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        This is a simplified version - real implementation would</span></span><br><span class="line"><span class="string">        use more sophisticated methods like adversarial training.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># In practice, this would involve:</span></span><br><span class="line">        <span class="comment"># 1. Learning attribute-specific transformations</span></span><br><span class="line">        <span class="comment"># 2. Removing attribute information from embeddings</span></span><br><span class="line">        <span class="comment"># 3. Adding counterfactual attribute information</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Simplified: just return original embeddings</span></span><br><span class="line">        <span class="comment"># Real implementation would modify embeddings based on attributes</span></span><br><span class="line">        <span class="keyword">return</span> user_emb</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">counterfactual_fairness_loss</span>(<span class="params">self, user_ids: torch.Tensor,</span></span><br><span class="line"><span class="params">                                     item_ids: torch.Tensor,</span></span><br><span class="line"><span class="params">                                     scores: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Compute counterfactual fairness loss.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Ensures that changing protected attributes doesn't change predictions.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># Get protected attributes</span></span><br><span class="line">        protected_attrs = torch.tensor([</span><br><span class="line">            self.protected_attributes.get(uid.item(), <span class="number">0</span>) </span><br><span class="line">            <span class="keyword">for</span> uid <span class="keyword">in</span> user_ids</span><br><span class="line">        ])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Generate counterfactual attributes (flip binary attributes)</span></span><br><span class="line">        counterfactual_attrs = {</span><br><span class="line">            uid.item(): <span class="number">1</span> - self.protected_attributes.get(uid.item(), <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">for</span> uid <span class="keyword">in</span> user_ids</span><br><span class="line">        }</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Get counterfactual predictions</span></span><br><span class="line">        counterfactual_scores = self.forward(user_ids, item_ids, </span><br><span class="line">                                              counterfactual_attrs)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Fairness loss: minimize difference between factual and counterfactual</span></span><br><span class="line">        fairness_loss = nn.MSELoss()(scores, counterfactual_scores)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> fairness_loss</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">recommend</span>(<span class="params">self, user_id: <span class="built_in">int</span>, top_k: <span class="built_in">int</span> = <span class="number">10</span>,</span></span><br><span class="line"><span class="params">                 use_counterfactual: <span class="built_in">bool</span> = <span class="literal">False</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Generate recommendations for a user.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_id: User ID</span></span><br><span class="line"><span class="string">            top_k: Number of recommendations</span></span><br><span class="line"><span class="string">            use_counterfactual: Whether to use counterfactual reasoning</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.<span class="built_in">eval</span>()</span><br><span class="line">        </span><br><span class="line">        user_tensor = torch.tensor([user_id])</span><br><span class="line">        all_items = torch.arange(self.item_embedding.num_embeddings)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Expand user tensor to match items</span></span><br><span class="line">        user_ids_expanded = user_tensor.repeat(<span class="built_in">len</span>(all_items))</span><br><span class="line">        </span><br><span class="line">        counterfactual_attrs = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> use_counterfactual:</span><br><span class="line">            <span class="comment"># Use counterfactual attributes</span></span><br><span class="line">            original_attr = self.protected_attributes.get(user_id, <span class="number">0</span>)</span><br><span class="line">            counterfactual_attrs = {user_id: <span class="number">1</span> - original_attr}</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            scores = self.forward(user_ids_expanded, all_items, </span><br><span class="line">                                 counterfactual_attrs)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Get top-k items</span></span><br><span class="line">        top_scores, top_indices = torch.topk(scores.squeeze(), top_k)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> top_indices.tolist()</span><br></pre></td></tr></table></figure>
<h2 id="cfairer-counterfactual-fairness-in-recommendation">CFairER:
Counterfactual Fairness in Recommendation</h2>
<p>CFairER (Counterfactual Fairness in Recommendation) is a framework
that ensures recommendations are counterfactually fair by learning
representations that are invariant to protected attributes.</p>
<h3 id="cfairer-architecture">CFairER Architecture</h3>
<p>CFairER consists of: 1. <strong>Encoder</strong>: Maps users and
items to embeddings 2. <strong>Predictor</strong>: Predicts ratings from
embeddings 3. <strong>Adversarial Discriminator</strong>: Tries to
predict protected attributes from embeddings 4. <strong>Fairness
Regularizer</strong>: Ensures embeddings don't encode protected
information</p>
<h3 id="implementation">Implementation</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CFairER</span>(nn.Module):</span><br><span class="line">    <span class="string">"""CFairER: Counterfactual Fairness in Recommendation"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_users: <span class="built_in">int</span>, num_items: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 embedding_dim: <span class="built_in">int</span> = <span class="number">64</span>, hidden_dim: <span class="built_in">int</span> = <span class="number">128</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Encoders</span></span><br><span class="line">        self.user_encoder = nn.Embedding(num_users, embedding_dim)</span><br><span class="line">        self.item_encoder = nn.Embedding(num_items, embedding_dim)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Predictor</span></span><br><span class="line">        self.predictor = nn.Sequential(</span><br><span class="line">            nn.Linear(embedding_dim * <span class="number">2</span>, hidden_dim),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(hidden_dim, hidden_dim // <span class="number">2</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(hidden_dim // <span class="number">2</span>, <span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Adversarial discriminator (tries to predict protected attributes)</span></span><br><span class="line">        self.discriminator = nn.Sequential(</span><br><span class="line">            nn.Linear(embedding_dim, hidden_dim),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(hidden_dim, hidden_dim // <span class="number">2</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(hidden_dim // <span class="number">2</span>, <span class="number">1</span>),  <span class="comment"># Binary protected attribute</span></span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, user_ids: torch.Tensor, item_ids: torch.Tensor</span>):</span><br><span class="line">        <span class="string">"""Forward pass"""</span></span><br><span class="line">        user_emb = self.user_encoder(user_ids)</span><br><span class="line">        item_emb = self.item_encoder(item_ids)</span><br><span class="line">        </span><br><span class="line">        combined = torch.cat([user_emb, item_emb], dim=<span class="number">1</span>)</span><br><span class="line">        prediction = self.predictor(combined)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> prediction, user_emb</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict_protected_attribute</span>(<span class="params">self, user_emb: torch.Tensor</span>):</span><br><span class="line">        <span class="string">"""Predict protected attribute from user embedding"""</span></span><br><span class="line">        <span class="keyword">return</span> self.discriminator(user_emb)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute_fairness_loss</span>(<span class="params">self, user_emb: torch.Tensor,</span></span><br><span class="line"><span class="params">                            protected_attrs: torch.Tensor,</span></span><br><span class="line"><span class="params">                            lambda_fair: <span class="built_in">float</span> = <span class="number">1.0</span></span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Compute fairness loss using adversarial training.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        The discriminator tries to predict protected attributes,</span></span><br><span class="line"><span class="string">        but we want embeddings to be invariant to protected attributes.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># Discriminator prediction</span></span><br><span class="line">        pred_attrs = self.predict_protected_attribute(user_emb)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Adversarial loss: maximize discriminator error</span></span><br><span class="line">        <span class="comment"># (i.e., minimize ability to predict protected attributes)</span></span><br><span class="line">        fairness_loss = nn.BCELoss()(pred_attrs, </span><br><span class="line">                                     torch.ones_like(pred_attrs) * <span class="number">0.5</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> lambda_fair * fairness_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_cfairer</span>(<span class="params">model: CFairER, train_loader, protected_attrs: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">                 num_epochs: <span class="built_in">int</span> = <span class="number">10</span>, lambda_fair: <span class="built_in">float</span> = <span class="number">1.0</span>,</span></span><br><span class="line"><span class="params">                 lambda_pred: <span class="built_in">float</span> = <span class="number">1.0</span></span>):</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Train CFairER model.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        model: CFairER model</span></span><br><span class="line"><span class="string">        train_loader: DataLoader for training data</span></span><br><span class="line"><span class="string">        protected_attrs: Dictionary mapping user_id to protected attribute</span></span><br><span class="line"><span class="string">        num_epochs: Number of training epochs</span></span><br><span class="line"><span class="string">        lambda_fair: Weight for fairness loss</span></span><br><span class="line"><span class="string">        lambda_pred: Weight for prediction loss</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line">    prediction_criterion = nn.MSELoss()</span><br><span class="line">    discriminator_criterion = nn.BCELoss()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Separate optimizer for discriminator (adversarial training)</span></span><br><span class="line">    discriminator_params = <span class="built_in">list</span>(model.discriminator.parameters())</span><br><span class="line">    discriminator_optimizer = torch.optim.Adam(discriminator_params, lr=<span class="number">0.001</span>)</span><br><span class="line">    </span><br><span class="line">    model.train()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        total_loss = <span class="number">0.0</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> train_loader:</span><br><span class="line">            user_ids = batch[<span class="string">'user_id'</span>]</span><br><span class="line">            item_ids = batch[<span class="string">'item_id'</span>]</span><br><span class="line">            ratings = batch[<span class="string">'rating'</span>]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Get protected attributes for batch</span></span><br><span class="line">            protected_batch = torch.tensor([</span><br><span class="line">                protected_attrs.get(uid.item(), <span class="number">0</span>) </span><br><span class="line">                <span class="keyword">for</span> uid <span class="keyword">in</span> user_ids</span><br><span class="line">            ], dtype=torch.float32)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Forward pass</span></span><br><span class="line">            predictions, user_emb = model(user_ids, item_ids)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Prediction loss</span></span><br><span class="line">            pred_loss = prediction_criterion(predictions.squeeze(), ratings)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Fairness loss (adversarial)</span></span><br><span class="line">            fairness_loss = model.compute_fairness_loss(</span><br><span class="line">                user_emb, protected_batch, lambda_fair</span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Discriminator loss (train discriminator to predict attributes)</span></span><br><span class="line">            pred_attrs = model.predict_protected_attribute(user_emb.detach())</span><br><span class="line">            discriminator_loss = discriminator_criterion(</span><br><span class="line">                pred_attrs.squeeze(), protected_batch</span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Update discriminator</span></span><br><span class="line">            discriminator_optimizer.zero_grad()</span><br><span class="line">            discriminator_loss.backward()</span><br><span class="line">            discriminator_optimizer.step()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Update main model (minimize prediction loss, maximize discriminator error)</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            total_loss_batch = lambda_pred * pred_loss - lambda_fair * fairness_loss</span><br><span class="line">            total_loss_batch.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            </span><br><span class="line">            total_loss += total_loss_batch.item()</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"Epoch <span class="subst">{epoch+<span class="number">1</span>}</span>/<span class="subst">{num_epochs}</span>, Loss: <span class="subst">{total_loss/<span class="built_in">len</span>(train_loader):<span class="number">.4</span>f}</span>"</span>)</span><br></pre></td></tr></table></figure>
<h2 id="debiasing-methods">Debiasing Methods</h2>
<h3 id="pre-processing-methods">Pre-Processing Methods</h3>
<p>Pre-processing methods modify training data before model
training.</p>
<p><strong>1. Rebalancing</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DataRebalancer</span>:</span><br><span class="line">    <span class="string">"""Rebalance training data to reduce bias"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, min_interactions_per_item: <span class="built_in">int</span> = <span class="number">10</span>,</span></span><br><span class="line"><span class="params">                 max_interactions_per_item: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">        self.min_interactions = min_interactions_per_item</span><br><span class="line">        self.max_interactions = max_interactions_per_item</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">rebalance</span>(<span class="params">self, interactions: pd.DataFrame,</span></span><br><span class="line"><span class="params">                  user_col: <span class="built_in">str</span> = <span class="string">'user_id'</span>,</span></span><br><span class="line"><span class="params">                  item_col: <span class="built_in">str</span> = <span class="string">'item_id'</span></span>) -&gt; pd.DataFrame:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Rebalance interactions to reduce popularity bias.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            interactions: DataFrame with user-item interactions</span></span><br><span class="line"><span class="string">            user_col: Column name for user ID</span></span><br><span class="line"><span class="string">            item_col: Column name for item ID</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Rebalanced DataFrame</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># Count interactions per item</span></span><br><span class="line">        item_counts = interactions[item_col].value_counts()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Identify items to downsample (too popular)</span></span><br><span class="line">        popular_items = item_counts[</span><br><span class="line">            item_counts &gt; self.max_interactions</span><br><span class="line">        ].index</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Identify items to upsample (too unpopular)</span></span><br><span class="line">        unpopular_items = item_counts[</span><br><span class="line">            item_counts &lt; self.min_interactions</span><br><span class="line">        ].index</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Downsample popular items</span></span><br><span class="line">        rebalanced = []</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> interactions[item_col].unique():</span><br><span class="line">            item_interactions = interactions[interactions[item_col] == item]</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> item <span class="keyword">in</span> popular_items:</span><br><span class="line">                <span class="comment"># Randomly sample max_interactions</span></span><br><span class="line">                item_interactions = item_interactions.sample(</span><br><span class="line">                    n=<span class="built_in">min</span>(self.max_interactions, <span class="built_in">len</span>(item_interactions)),</span><br><span class="line">                    random_state=<span class="number">42</span></span><br><span class="line">                )</span><br><span class="line">            <span class="keyword">elif</span> item <span class="keyword">in</span> unpopular_items:</span><br><span class="line">                <span class="comment"># Oversample (with replacement)</span></span><br><span class="line">                n_samples = self.min_interactions</span><br><span class="line">                item_interactions = item_interactions.sample(</span><br><span class="line">                    n=n_samples,</span><br><span class="line">                    replace=<span class="literal">True</span>,</span><br><span class="line">                    random_state=<span class="number">42</span></span><br><span class="line">                )</span><br><span class="line">            </span><br><span class="line">            rebalanced.append(item_interactions)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> pd.concat(rebalanced, ignore_index=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p><strong>2. Fair Sampling</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FairSampler</span>:</span><br><span class="line">    <span class="string">"""Sample interactions fairly across user/item groups"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, user_groups: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">str</span>] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 item_groups: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">str</span>] = <span class="literal">None</span></span>):</span><br><span class="line">        self.user_groups = user_groups <span class="keyword">or</span> {}</span><br><span class="line">        self.item_groups = item_groups <span class="keyword">or</span> {}</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sample</span>(<span class="params">self, interactions: pd.DataFrame,</span></span><br><span class="line"><span class="params">              sample_size: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">              user_col: <span class="built_in">str</span> = <span class="string">'user_id'</span>,</span></span><br><span class="line"><span class="params">              item_col: <span class="built_in">str</span> = <span class="string">'item_id'</span></span>) -&gt; pd.DataFrame:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Sample interactions ensuring fair representation.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            interactions: Original interactions</span></span><br><span class="line"><span class="string">            sample_size: Target sample size</span></span><br><span class="line"><span class="string">            user_col: Column name for user ID</span></span><br><span class="line"><span class="string">            item_col: Column name for item ID</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Fairly sampled DataFrame</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.user_groups <span class="keyword">and</span> <span class="keyword">not</span> self.item_groups:</span><br><span class="line">            <span class="comment"># No groups specified, random sample</span></span><br><span class="line">            <span class="keyword">return</span> interactions.sample(n=<span class="built_in">min</span>(sample_size, <span class="built_in">len</span>(interactions)))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Sample proportionally from each group</span></span><br><span class="line">        sampled = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.user_groups:</span><br><span class="line">            <span class="comment"># Sample by user groups</span></span><br><span class="line">            <span class="keyword">for</span> group <span class="keyword">in</span> <span class="built_in">set</span>(self.user_groups.values()):</span><br><span class="line">                group_users = [</span><br><span class="line">                    uid <span class="keyword">for</span> uid, g <span class="keyword">in</span> self.user_groups.items() </span><br><span class="line">                    <span class="keyword">if</span> g == group</span><br><span class="line">                ]</span><br><span class="line">                group_interactions = interactions[</span><br><span class="line">                    interactions[user_col].isin(group_users)</span><br><span class="line">                ]</span><br><span class="line">                </span><br><span class="line">                group_size = <span class="built_in">int</span>(sample_size * <span class="built_in">len</span>(group_interactions) / <span class="built_in">len</span>(interactions))</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(group_interactions) &gt; <span class="number">0</span>:</span><br><span class="line">                    sampled.append(</span><br><span class="line">                        group_interactions.sample(</span><br><span class="line">                            n=<span class="built_in">min</span>(group_size, <span class="built_in">len</span>(group_interactions))</span><br><span class="line">                        )</span><br><span class="line">                    )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># Sample by item groups</span></span><br><span class="line">            <span class="keyword">for</span> group <span class="keyword">in</span> <span class="built_in">set</span>(self.item_groups.values()):</span><br><span class="line">                group_items = [</span><br><span class="line">                    iid <span class="keyword">for</span> iid, g <span class="keyword">in</span> self.item_groups.items() </span><br><span class="line">                    <span class="keyword">if</span> g == group</span><br><span class="line">                ]</span><br><span class="line">                group_interactions = interactions[</span><br><span class="line">                    interactions[item_col].isin(group_items)</span><br><span class="line">                ]</span><br><span class="line">                </span><br><span class="line">                group_size = <span class="built_in">int</span>(sample_size * <span class="built_in">len</span>(group_interactions) / <span class="built_in">len</span>(interactions))</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(group_interactions) &gt; <span class="number">0</span>:</span><br><span class="line">                    sampled.append(</span><br><span class="line">                        group_interactions.sample(</span><br><span class="line">                            n=<span class="built_in">min</span>(group_size, <span class="built_in">len</span>(group_interactions))</span><br><span class="line">                        )</span><br><span class="line">                    )</span><br><span class="line">        </span><br><span class="line">        result = pd.concat(sampled, ignore_index=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># If we have fewer samples than requested, add random samples</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(result) &lt; sample_size:</span><br><span class="line">            remaining = interactions[~interactions.index.isin(result.index)]</span><br><span class="line">            additional = remaining.sample(</span><br><span class="line">                n=<span class="built_in">min</span>(sample_size - <span class="built_in">len</span>(result), <span class="built_in">len</span>(remaining))</span><br><span class="line">            )</span><br><span class="line">            result = pd.concat([result, additional], ignore_index=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<h3 id="in-processing-methods">In-Processing Methods</h3>
<p>In-processing methods modify the training objective or model
architecture.</p>
<p><strong>1. Fairness-Aware Loss Functions</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FairnessAwareLoss</span>(nn.Module):</span><br><span class="line">    <span class="string">"""Loss function that incorporates fairness constraints"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, base_loss: nn.Module, lambda_fair: <span class="built_in">float</span> = <span class="number">1.0</span></span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            base_loss: Base prediction loss (e.g., MSE, BCE)</span></span><br><span class="line"><span class="string">            lambda_fair: Weight for fairness term</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.base_loss = base_loss</span><br><span class="line">        self.lambda_fair = lambda_fair</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, predictions: torch.Tensor, targets: torch.Tensor,</span></span><br><span class="line"><span class="params">               user_groups: torch.Tensor = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">               item_groups: torch.Tensor = <span class="literal">None</span></span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Compute fairness-aware loss.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            predictions: Model predictions</span></span><br><span class="line"><span class="string">            targets: True labels</span></span><br><span class="line"><span class="string">            user_groups: User group assignments</span></span><br><span class="line"><span class="string">            item_groups: Item group assignments</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># Base prediction loss</span></span><br><span class="line">        pred_loss = self.base_loss(predictions, targets)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Fairness loss</span></span><br><span class="line">        fairness_loss = <span class="number">0.0</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> user_groups <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># Demographic parity: equal average predictions across groups</span></span><br><span class="line">            fairness_loss += self._demographic_parity_loss(</span><br><span class="line">                predictions, user_groups</span><br><span class="line">            )</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> item_groups <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># Item fairness: equal exposure across item groups</span></span><br><span class="line">            fairness_loss += self._item_fairness_loss(</span><br><span class="line">                predictions, item_groups</span><br><span class="line">            )</span><br><span class="line">        </span><br><span class="line">        total_loss = pred_loss + self.lambda_fair * fairness_loss</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> total_loss</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_demographic_parity_loss</span>(<span class="params">self, predictions: torch.Tensor,</span></span><br><span class="line"><span class="params">                                 user_groups: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">"""Demographic parity loss"""</span></span><br><span class="line">        unique_groups = torch.unique(user_groups)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(unique_groups) &lt; <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> torch.tensor(<span class="number">0.0</span>)</span><br><span class="line">        </span><br><span class="line">        group_means = []</span><br><span class="line">        <span class="keyword">for</span> group <span class="keyword">in</span> unique_groups:</span><br><span class="line">            group_mask = (user_groups == group)</span><br><span class="line">            group_mean = predictions[group_mask].mean()</span><br><span class="line">            group_means.append(group_mean)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Variance of group means (want them to be equal)</span></span><br><span class="line">        group_means_tensor = torch.stack(group_means)</span><br><span class="line">        variance = torch.var(group_means_tensor)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> variance</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_item_fairness_loss</span>(<span class="params">self, predictions: torch.Tensor,</span></span><br><span class="line"><span class="params">                           item_groups: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">"""Item group fairness loss"""</span></span><br><span class="line">        unique_groups = torch.unique(item_groups)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(unique_groups) &lt; <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> torch.tensor(<span class="number">0.0</span>)</span><br><span class="line">        </span><br><span class="line">        group_means = []</span><br><span class="line">        <span class="keyword">for</span> group <span class="keyword">in</span> unique_groups:</span><br><span class="line">            group_mask = (item_groups == group)</span><br><span class="line">            group_mean = predictions[group_mask].mean()</span><br><span class="line">            group_means.append(group_mean)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Variance of group means</span></span><br><span class="line">        group_means_tensor = torch.stack(group_means)</span><br><span class="line">        variance = torch.var(group_means_tensor)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> variance</span><br></pre></td></tr></table></figure>
<p><strong>2. Adversarial Debiasing</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AdversarialDebiasing</span>(nn.Module):</span><br><span class="line">    <span class="string">"""Adversarial training to remove bias"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, base_model: nn.Module, num_groups: <span class="built_in">int</span> = <span class="number">2</span></span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            base_model: Base recommendation model</span></span><br><span class="line"><span class="string">            num_groups: Number of protected attribute groups</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.base_model = base_model</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Adversarial discriminator</span></span><br><span class="line">        <span class="comment"># Input: model's hidden representation</span></span><br><span class="line">        <span class="comment"># Output: protected attribute prediction</span></span><br><span class="line">        self.discriminator = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">64</span>, <span class="number">32</span>),  <span class="comment"># Assume 64-dim hidden representation</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">32</span>, num_groups),</span><br><span class="line">            nn.Softmax(dim=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, user_ids: torch.Tensor, item_ids: torch.Tensor</span>):</span><br><span class="line">        <span class="string">"""Forward pass"""</span></span><br><span class="line">        <span class="keyword">return</span> self.base_model(user_ids, item_ids)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_hidden_representation</span>(<span class="params">self, user_ids: torch.Tensor,</span></span><br><span class="line"><span class="params">                                  item_ids: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">"""Extract hidden representation from base model"""</span></span><br><span class="line">        <span class="comment"># This depends on base_model architecture</span></span><br><span class="line">        <span class="comment"># Simplified: assume base_model returns (prediction, hidden)</span></span><br><span class="line">        prediction, hidden = self.base_model(user_ids, item_ids)</span><br><span class="line">        <span class="keyword">return</span> hidden</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict_protected_attribute</span>(<span class="params">self, user_ids: torch.Tensor,</span></span><br><span class="line"><span class="params">                                   item_ids: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">"""Predict protected attribute from hidden representation"""</span></span><br><span class="line">        hidden = self.get_hidden_representation(user_ids, item_ids)</span><br><span class="line">        <span class="keyword">return</span> self.discriminator(hidden)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_adversarial_debiasing</span>(<span class="params">model: AdversarialDebiasing,</span></span><br><span class="line"><span class="params">                                train_loader,</span></span><br><span class="line"><span class="params">                                protected_attrs: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">                                num_epochs: <span class="built_in">int</span> = <span class="number">10</span>,</span></span><br><span class="line"><span class="params">                                lambda_adv: <span class="built_in">float</span> = <span class="number">1.0</span></span>):</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Train model with adversarial debiasing.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        model: AdversarialDebiasing model</span></span><br><span class="line"><span class="string">        train_loader: Training data loader</span></span><br><span class="line"><span class="string">        protected_attrs: User protected attributes</span></span><br><span class="line"><span class="string">        num_epochs: Number of epochs</span></span><br><span class="line"><span class="string">        lambda_adv: Adversarial loss weight</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    optimizer = torch.optim.Adam(model.base_model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line">    discriminator_optimizer = torch.optim.Adam(</span><br><span class="line">        model.discriminator.parameters(), lr=<span class="number">0.001</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    criterion = nn.MSELoss()</span><br><span class="line">    discriminator_criterion = nn.CrossEntropyLoss()</span><br><span class="line">    </span><br><span class="line">    model.train()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> train_loader:</span><br><span class="line">            user_ids = batch[<span class="string">'user_id'</span>]</span><br><span class="line">            item_ids = batch[<span class="string">'item_id'</span>]</span><br><span class="line">            ratings = batch[<span class="string">'rating'</span>]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Get protected attributes</span></span><br><span class="line">            protected_batch = torch.tensor([</span><br><span class="line">                protected_attrs.get(uid.item(), <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">for</span> uid <span class="keyword">in</span> user_ids</span><br><span class="line">            ], dtype=torch.long)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Base model prediction</span></span><br><span class="line">            predictions = model(user_ids, item_ids)</span><br><span class="line">            pred_loss = criterion(predictions.squeeze(), ratings)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Train discriminator</span></span><br><span class="line">            discriminator_optimizer.zero_grad()</span><br><span class="line">            pred_attrs = model.predict_protected_attribute(user_ids, item_ids)</span><br><span class="line">            discriminator_loss = discriminator_criterion(</span><br><span class="line">                pred_attrs, protected_batch</span><br><span class="line">            )</span><br><span class="line">            discriminator_loss.backward()</span><br><span class="line">            discriminator_optimizer.step()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Train base model (minimize prediction loss, maximize discriminator error)</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            pred_attrs_detached = model.predict_protected_attribute(</span><br><span class="line">                user_ids, item_ids</span><br><span class="line">            )</span><br><span class="line">            adversarial_loss = -discriminator_criterion(</span><br><span class="line">                pred_attrs_detached, protected_batch</span><br><span class="line">            )  <span class="comment"># Negative: maximize discriminator error</span></span><br><span class="line">            </span><br><span class="line">            total_loss = pred_loss + lambda_adv * adversarial_loss</span><br><span class="line">            total_loss.backward()</span><br><span class="line">            optimizer.step()</span><br></pre></td></tr></table></figure>
<h3 id="post-processing-methods">Post-Processing Methods</h3>
<p>Post-processing methods adjust recommendations after they're
generated.</p>
<p><strong>1. Re-ranking for Fairness</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FairReranker</span>:</span><br><span class="line">    <span class="string">"""Rerank recommendations to ensure fairness"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, fairness_metric: <span class="built_in">str</span> = <span class="string">'demographic_parity'</span>,</span></span><br><span class="line"><span class="params">                 lambda_fair: <span class="built_in">float</span> = <span class="number">0.5</span></span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            fairness_metric: Type of fairness ('demographic_parity', 'equalized_odds')</span></span><br><span class="line"><span class="string">            lambda_fair: Trade-off between relevance and fairness</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.fairness_metric = fairness_metric</span><br><span class="line">        self.lambda_fair = lambda_fair</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">rerank</span>(<span class="params">self, recommendations: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">float</span>]]],</span></span><br><span class="line"><span class="params">              user_groups: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">str</span>] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">              item_groups: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">str</span>] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">              top_k: <span class="built_in">int</span> = <span class="number">10</span></span>) -&gt; <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Rerank recommendations for fairness.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            recommendations: {user_id: [(item_id, score), ...]}</span></span><br><span class="line"><span class="string">            user_groups: User group assignments</span></span><br><span class="line"><span class="string">            item_groups: Item group assignments</span></span><br><span class="line"><span class="string">            top_k: Number of recommendations per user</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Reranked recommendations</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        reranked = {}</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> user_id, recs <span class="keyword">in</span> recommendations.items():</span><br><span class="line">            <span class="keyword">if</span> self.fairness_metric == <span class="string">'demographic_parity'</span>:</span><br><span class="line">                reranked[user_id] = self._demographic_parity_rerank(</span><br><span class="line">                    recs, user_groups, item_groups, top_k</span><br><span class="line">                )</span><br><span class="line">            <span class="keyword">elif</span> self.fairness_metric == <span class="string">'equalized_odds'</span>:</span><br><span class="line">                reranked[user_id] = self._equalized_odds_rerank(</span><br><span class="line">                    recs, user_groups, item_groups, top_k</span><br><span class="line">                )</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># Default: diversity-based reranking</span></span><br><span class="line">                reranked[user_id] = self._diversity_rerank(</span><br><span class="line">                    recs, item_groups, top_k</span><br><span class="line">                )</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> reranked</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_demographic_parity_rerank</span>(<span class="params">self, recs: <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">float</span>]],</span></span><br><span class="line"><span class="params">                                   user_groups: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">str</span>],</span></span><br><span class="line"><span class="params">                                   item_groups: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">str</span>],</span></span><br><span class="line"><span class="params">                                   top_k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="string">"""Rerank for demographic parity"""</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> item_groups:</span><br><span class="line">            <span class="comment"># No groups, return top-k by score</span></span><br><span class="line">            <span class="keyword">return</span> [item_id <span class="keyword">for</span> item_id, score <span class="keyword">in</span> <span class="built_in">sorted</span>(recs, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:top_k]]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Count current group distribution</span></span><br><span class="line">        group_counts = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">        selected = []</span><br><span class="line">        remaining = recs.copy()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Target: equal representation across groups</span></span><br><span class="line">        target_per_group = top_k // <span class="built_in">len</span>(<span class="built_in">set</span>(item_groups.values()))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> <span class="built_in">len</span>(selected) &lt; top_k <span class="keyword">and</span> remaining:</span><br><span class="line">            <span class="comment"># Score each remaining item</span></span><br><span class="line">            scores = []</span><br><span class="line">            <span class="keyword">for</span> item_id, score <span class="keyword">in</span> remaining:</span><br><span class="line">                item_group = item_groups.get(item_id, <span class="string">'unknown'</span>)</span><br><span class="line">                current_count = group_counts[item_group]</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># Fairness score: boost items from underrepresented groups</span></span><br><span class="line">                fairness_boost = <span class="built_in">max</span>(<span class="number">0</span>, target_per_group - current_count)</span><br><span class="line">                fairness_score = score + self.lambda_fair * fairness_boost</span><br><span class="line">                </span><br><span class="line">                scores.append((item_id, fairness_score, score))</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Select item with highest fairness-adjusted score</span></span><br><span class="line">            scores.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">            best_item_id, _, original_score = scores[<span class="number">0</span>]</span><br><span class="line">            </span><br><span class="line">            selected.append(best_item_id)</span><br><span class="line">            remaining = [(iid, s) <span class="keyword">for</span> iid, s, _ <span class="keyword">in</span> scores[<span class="number">1</span>:]]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Update group counts</span></span><br><span class="line">            item_group = item_groups.get(best_item_id, <span class="string">'unknown'</span>)</span><br><span class="line">            group_counts[item_group] += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> selected</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_diversity_rerank</span>(<span class="params">self, recs: <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">float</span>]],</span></span><br><span class="line"><span class="params">                         item_groups: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">str</span>],</span></span><br><span class="line"><span class="params">                         top_k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="string">"""Rerank for diversity"""</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> item_groups:</span><br><span class="line">            <span class="keyword">return</span> [item_id <span class="keyword">for</span> item_id, score <span class="keyword">in</span> <span class="built_in">sorted</span>(recs, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:top_k]]</span><br><span class="line">        </span><br><span class="line">        selected = []</span><br><span class="line">        remaining = recs.copy()</span><br><span class="line">        selected_groups = <span class="built_in">set</span>()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> <span class="built_in">len</span>(selected) &lt; top_k <span class="keyword">and</span> remaining:</span><br><span class="line">            <span class="comment"># Prioritize items from unseen groups</span></span><br><span class="line">            scores = []</span><br><span class="line">            <span class="keyword">for</span> item_id, score <span class="keyword">in</span> remaining:</span><br><span class="line">                item_group = item_groups.get(item_id, <span class="string">'unknown'</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># Diversity boost: prefer items from new groups</span></span><br><span class="line">                diversity_boost = <span class="number">1.0</span> <span class="keyword">if</span> item_group <span class="keyword">not</span> <span class="keyword">in</span> selected_groups <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">                diversity_score = score + self.lambda_fair * diversity_boost * score</span><br><span class="line">                </span><br><span class="line">                scores.append((item_id, diversity_score, score))</span><br><span class="line">            </span><br><span class="line">            scores.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">            best_item_id, _, _ = scores[<span class="number">0</span>]</span><br><span class="line">            </span><br><span class="line">            selected.append(best_item_id)</span><br><span class="line">            remaining = [(iid, s) <span class="keyword">for</span> iid, s, _ <span class="keyword">in</span> scores[<span class="number">1</span>:]]</span><br><span class="line">            </span><br><span class="line">            item_group = item_groups.get(best_item_id, <span class="string">'unknown'</span>)</span><br><span class="line">            selected_groups.add(item_group)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> selected</span><br></pre></td></tr></table></figure>
<p><strong>2. Calibration</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CalibratedRecommender</span>:</span><br><span class="line">    <span class="string">"""Calibrate recommendations to match user preferences"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">calibrate</span>(<span class="params">self, recommendations: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">float</span>]]],</span></span><br><span class="line"><span class="params">                 user_preferences: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">float</span>]],</span></span><br><span class="line"><span class="params">                 top_k: <span class="built_in">int</span> = <span class="number">10</span></span>) -&gt; <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Calibrate recommendations to match user preference distribution.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            recommendations: {user_id: [(item_id, score), ...]}</span></span><br><span class="line"><span class="string">            user_preferences: {user_id: {category: proportion}}</span></span><br><span class="line"><span class="string">            top_k: Number of recommendations</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Calibrated recommendations</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        calibrated = {}</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> user_id, recs <span class="keyword">in</span> recommendations.items():</span><br><span class="line">            <span class="keyword">if</span> user_id <span class="keyword">not</span> <span class="keyword">in</span> user_preferences:</span><br><span class="line">                <span class="comment"># No preferences, return original</span></span><br><span class="line">                calibrated[user_id] = [item_id <span class="keyword">for</span> item_id, _ <span class="keyword">in</span> recs[:top_k]]</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line">            target_dist = user_preferences[user_id]</span><br><span class="line">            calibrated[user_id] = self._calibrate_user(</span><br><span class="line">                recs, target_dist, top_k</span><br><span class="line">            )</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> calibrated</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_calibrate_user</span>(<span class="params">self, recs: <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">float</span>]],</span></span><br><span class="line"><span class="params">                       target_dist: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">float</span>],</span></span><br><span class="line"><span class="params">                       top_k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="string">"""Calibrate recommendations for a single user"""</span></span><br><span class="line">        <span class="comment"># This is simplified - real implementation would:</span></span><br><span class="line">        <span class="comment"># 1. Map items to categories</span></span><br><span class="line">        <span class="comment"># 2. Track current distribution</span></span><br><span class="line">        <span class="comment"># 3. Select items to match target distribution</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Simplified: diversity-based selection</span></span><br><span class="line">        selected = []</span><br><span class="line">        category_counts = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">        </span><br><span class="line">        target_total = <span class="built_in">sum</span>(target_dist.values())</span><br><span class="line">        target_counts = {</span><br><span class="line">            cat: <span class="built_in">int</span>(prop * top_k / target_total)</span><br><span class="line">            <span class="keyword">for</span> cat, prop <span class="keyword">in</span> target_dist.items()</span><br><span class="line">        }</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> item_id, score <span class="keyword">in</span> <span class="built_in">sorted</span>(recs, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(selected) &gt;= top_k:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Simplified: assume we can map items to categories</span></span><br><span class="line">            <span class="comment"># In practice, this would use item metadata</span></span><br><span class="line">            item_category = self._get_item_category(item_id)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> category_counts[item_category] &lt; target_counts.get(item_category, top_k):</span><br><span class="line">                selected.append(item_id)</span><br><span class="line">                category_counts[item_category] += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> selected</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_item_category</span>(<span class="params">self, item_id: <span class="built_in">int</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""Get item category (simplified)"""</span></span><br><span class="line">        <span class="comment"># In practice, this would query item metadata</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">f"category_<span class="subst">{item_id % <span class="number">3</span>}</span>"</span></span><br></pre></td></tr></table></figure>
<h2 id="explainable-recommendation">Explainable Recommendation</h2>
<h3 id="why-explainability-matters">Why Explainability Matters</h3>
<p>Explainability in recommendation systems serves multiple purposes: -
<strong>Trust</strong>: Users trust recommendations more when they
understand the reasoning - <strong>Transparency</strong>: Stakeholders
can audit recommendation decisions - <strong>Debugging</strong>:
Engineers can identify and fix issues - <strong>User Control</strong>:
Users can provide feedback and adjust preferences</p>
<h3 id="types-of-explanations">Types of Explanations</h3>
<p><strong>1. Feature-Based Explanations</strong></p>
<p>Explain recommendations using item features (e.g., "Recommended
because you like action movies").</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FeatureBasedExplainer</span>:</span><br><span class="line">    <span class="string">"""Generate feature-based explanations"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, item_features: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">float</span>]]</span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            item_features: {item_id: {feature: value}}</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.item_features = item_features</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">explain</span>(<span class="params">self, user_id: <span class="built_in">int</span>, item_id: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">               user_preferences: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">float</span>],</span></span><br><span class="line"><span class="params">               top_features: <span class="built_in">int</span> = <span class="number">3</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Generate explanation based on matching features.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_id: User ID</span></span><br><span class="line"><span class="string">            item_id: Recommended item ID</span></span><br><span class="line"><span class="string">            user_preferences: User's feature preferences</span></span><br><span class="line"><span class="string">            top_features: Number of features to mention</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Explanation string</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> item_id <span class="keyword">not</span> <span class="keyword">in</span> self.item_features:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"This item matches your preferences."</span></span><br><span class="line">        </span><br><span class="line">        item_feats = self.item_features[item_id]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Find matching features</span></span><br><span class="line">        matches = []</span><br><span class="line">        <span class="keyword">for</span> feature, user_pref <span class="keyword">in</span> user_preferences.items():</span><br><span class="line">            <span class="keyword">if</span> feature <span class="keyword">in</span> item_feats:</span><br><span class="line">                item_value = item_feats[feature]</span><br><span class="line">                match_score = <span class="built_in">min</span>(user_pref, item_value)</span><br><span class="line">                matches.append((feature, match_score))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Sort by match score</span></span><br><span class="line">        matches.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> matches:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"This item is recommended based on your preferences."</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Generate explanation</span></span><br><span class="line">        top_matches = matches[:top_features]</span><br><span class="line">        feature_names = [feat <span class="keyword">for</span> feat, _ <span class="keyword">in</span> top_matches]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(feature_names) == <span class="number">1</span>:</span><br><span class="line">            explanation = <span class="string">f"Recommended because you like <span class="subst">{feature_names[<span class="number">0</span>]}</span>."</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">len</span>(feature_names) == <span class="number">2</span>:</span><br><span class="line">            explanation = <span class="string">f"Recommended because you like <span class="subst">{feature_names[<span class="number">0</span>]}</span> and <span class="subst">{feature_names[<span class="number">1</span>]}</span>."</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            explanation = <span class="string">f"Recommended because you like <span class="subst">{<span class="string">', '</span>.join(feature_names[:-<span class="number">1</span>])}</span>, and <span class="subst">{feature_names[-<span class="number">1</span>]}</span>."</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> explanation</span><br></pre></td></tr></table></figure>
<p><strong>2. Neighbor-Based Explanations</strong></p>
<p>Explain using similar users or items (e.g., "Users like you also
liked this").</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NeighborBasedExplainer</span>:</span><br><span class="line">    <span class="string">"""Generate explanations based on similar users/items"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, user_similarities: np.ndarray = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 item_similarities: np.ndarray = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_similarities: User-user similarity matrix</span></span><br><span class="line"><span class="string">            item_similarities: Item-item similarity matrix</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.user_similarities = user_similarities</span><br><span class="line">        self.item_similarities = item_similarities</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">explain_user_based</span>(<span class="params">self, user_id: <span class="built_in">int</span>, item_id: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                          user_history: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="type">List</span>[<span class="built_in">int</span>]],</span></span><br><span class="line"><span class="params">                          top_neighbors: <span class="built_in">int</span> = <span class="number">3</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Generate user-based explanation.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_id: User ID</span></span><br><span class="line"><span class="string">            item_id: Recommended item ID</span></span><br><span class="line"><span class="string">            user_history: {user_id: [item_ids]} - user interaction history</span></span><br><span class="line"><span class="string">            top_neighbors: Number of neighbors to mention</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> self.user_similarities <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"Users similar to you also liked this item."</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Find similar users who interacted with this item</span></span><br><span class="line">        similar_users = []</span><br><span class="line">        <span class="keyword">for</span> other_user_id, items <span class="keyword">in</span> user_history.items():</span><br><span class="line">            <span class="keyword">if</span> other_user_id == user_id:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> item_id <span class="keyword">in</span> items:</span><br><span class="line">                similarity = self.user_similarities[user_id, other_user_id]</span><br><span class="line">                similar_users.append((other_user_id, similarity))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> similar_users:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"This item matches your preferences."</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Sort by similarity</span></span><br><span class="line">        similar_users.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        neighbor_count = <span class="built_in">len</span>(similar_users[:top_neighbors])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> neighbor_count == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"A user similar to you also liked this item."</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">f"<span class="subst">{neighbor_count}</span> users similar to you also liked this item."</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">explain_item_based</span>(<span class="params">self, user_id: <span class="built_in">int</span>, item_id: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                          user_history: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="type">List</span>[<span class="built_in">int</span>]],</span></span><br><span class="line"><span class="params">                          top_neighbors: <span class="built_in">int</span> = <span class="number">3</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Generate item-based explanation.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_id: User ID</span></span><br><span class="line"><span class="string">            item_id: Recommended item ID</span></span><br><span class="line"><span class="string">            user_history: User interaction history</span></span><br><span class="line"><span class="string">            top_neighbors: Number of similar items to mention</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> self.item_similarities <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"This item is similar to items you've liked."</span></span><br><span class="line">        </span><br><span class="line">        user_items = user_history.get(user_id, [])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> user_items:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"This item matches your preferences."</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Find items similar to recommended item that user has interacted with</span></span><br><span class="line">        similar_items = []</span><br><span class="line">        <span class="keyword">for</span> hist_item_id <span class="keyword">in</span> user_items:</span><br><span class="line">            <span class="keyword">if</span> hist_item_id == item_id:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            similarity = self.item_similarities[item_id, hist_item_id]</span><br><span class="line">            similar_items.append((hist_item_id, similarity))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> similar_items:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"This item matches your preferences."</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Sort by similarity</span></span><br><span class="line">        similar_items.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        neighbor_count = <span class="built_in">len</span>(similar_items[:top_neighbors])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> neighbor_count == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"This item is similar to an item you've liked."</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">f"This item is similar to <span class="subst">{neighbor_count}</span> items you've liked."</span></span><br></pre></td></tr></table></figure>
<p><strong>3. Attention-Based Explanations</strong></p>
<p>Use attention weights to identify important features or
interactions.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AttentionBasedExplainer</span>:</span><br><span class="line">    <span class="string">"""Generate explanations using attention weights"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model: nn.Module</span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            model: Model with attention mechanism</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.model = model</span><br><span class="line">        self.attention_weights = {}</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">extract_attention</span>(<span class="params">self, user_id: <span class="built_in">int</span>, item_id: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                         user_history: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">float</span>]:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Extract attention weights for explanation.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_id: User ID</span></span><br><span class="line"><span class="string">            item_id: Recommended item ID</span></span><br><span class="line"><span class="string">            user_history: User's historical items</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Dictionary mapping features/items to attention weights</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># This depends on model architecture</span></span><br><span class="line">        <span class="comment"># Simplified: assume model has attention mechanism</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Forward pass with attention</span></span><br><span class="line">        self.model.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="comment"># Get attention weights (implementation depends on model)</span></span><br><span class="line">            attention = self._get_attention_weights(user_id, item_id, user_history)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> attention</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_attention_weights</span>(<span class="params">self, user_id: <span class="built_in">int</span>, item_id: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                              user_history: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">float</span>]:</span><br><span class="line">        <span class="string">"""Extract attention weights from model"""</span></span><br><span class="line">        <span class="comment"># Simplified - real implementation would:</span></span><br><span class="line">        <span class="comment"># 1. Forward pass through model</span></span><br><span class="line">        <span class="comment"># 2. Extract attention weights from attention layers</span></span><br><span class="line">        <span class="comment"># 3. Map to interpretable features/items</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Placeholder</span></span><br><span class="line">        <span class="keyword">return</span> {<span class="string">"feature_1"</span>: <span class="number">0.4</span>, <span class="string">"feature_2"</span>: <span class="number">0.3</span>, <span class="string">"feature_3"</span>: <span class="number">0.3</span>}</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">explain</span>(<span class="params">self, user_id: <span class="built_in">int</span>, item_id: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">               user_history: <span class="type">List</span>[<span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">               top_k: <span class="built_in">int</span> = <span class="number">3</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Generate explanation from attention weights.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_id: User ID</span></span><br><span class="line"><span class="string">            item_id: Recommended item ID</span></span><br><span class="line"><span class="string">            user_history: User's historical items</span></span><br><span class="line"><span class="string">            top_k: Number of top features to mention</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Explanation string</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        attention = self.extract_attention(user_id, item_id, user_history)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Sort by attention weight</span></span><br><span class="line">        sorted_attention = <span class="built_in">sorted</span>(</span><br><span class="line">            attention.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        top_features = sorted_attention[:top_k]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> top_features:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"This item matches your preferences."</span></span><br><span class="line">        </span><br><span class="line">        feature_names = [feat <span class="keyword">for</span> feat, _ <span class="keyword">in</span> top_features]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(feature_names) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">f"Recommended primarily because of <span class="subst">{feature_names[<span class="number">0</span>]}</span>."</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">f"Recommended because of <span class="subst">{<span class="string">', '</span>.join(feature_names[:-<span class="number">1</span>])}</span>, and <span class="subst">{feature_names[-<span class="number">1</span>]}</span>."</span></span><br></pre></td></tr></table></figure>
<h2 id="attention-visualization">Attention Visualization</h2>
<p>Visualizing attention weights helps understand what the model focuses
on.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AttentionVisualizer</span>:</span><br><span class="line">    <span class="string">"""Visualize attention weights"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">plot_attention_heatmap</span>(<span class="params">self, attention_weights: np.ndarray,</span></span><br><span class="line"><span class="params">                              row_labels: <span class="type">List</span>[<span class="built_in">str</span>] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              col_labels: <span class="type">List</span>[<span class="built_in">str</span>] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              title: <span class="built_in">str</span> = <span class="string">"Attention Weights"</span></span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Plot attention weights as heatmap.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            attention_weights: 2D array of attention weights</span></span><br><span class="line"><span class="string">            row_labels: Labels for rows</span></span><br><span class="line"><span class="string">            col_labels: Labels for columns</span></span><br><span class="line"><span class="string">            title: Plot title</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">8</span>))</span><br><span class="line">        sns.heatmap(attention_weights, annot=<span class="literal">True</span>, fmt=<span class="string">'.2f'</span>,</span><br><span class="line">                   xticklabels=col_labels, yticklabels=row_labels,</span><br><span class="line">                   cmap=<span class="string">'YlOrRd'</span>)</span><br><span class="line">        plt.title(title)</span><br><span class="line">        plt.xlabel(<span class="string">'Items/Features'</span>)</span><br><span class="line">        plt.ylabel(<span class="string">'User History Items'</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.show()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">plot_attention_bar</span>(<span class="params">self, attention_weights: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">float</span>],</span></span><br><span class="line"><span class="params">                          title: <span class="built_in">str</span> = <span class="string">"Attention Weights"</span></span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Plot attention weights as bar chart.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            attention_weights: Dictionary mapping features to weights</span></span><br><span class="line"><span class="string">            title: Plot title</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        features = <span class="built_in">list</span>(attention_weights.keys())</span><br><span class="line">        weights = <span class="built_in">list</span>(attention_weights.values())</span><br><span class="line">        </span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">        plt.barh(features, weights)</span><br><span class="line">        plt.xlabel(<span class="string">'Attention Weight'</span>)</span><br><span class="line">        plt.title(title)</span><br><span class="line">        plt.gca().invert_yaxis()</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.show()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">plot_attention_sequence</span>(<span class="params">self, attention_weights: <span class="type">List</span>[<span class="built_in">float</span>],</span></span><br><span class="line"><span class="params">                               item_labels: <span class="type">List</span>[<span class="built_in">str</span>] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                               title: <span class="built_in">str</span> = <span class="string">"Attention Over Sequence"</span></span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Plot attention weights over a sequence.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            attention_weights: List of attention weights</span></span><br><span class="line"><span class="string">            item_labels: Labels for items in sequence</span></span><br><span class="line"><span class="string">            title: Plot title</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">12</span>, <span class="number">4</span>))</span><br><span class="line">        x = <span class="built_in">range</span>(<span class="built_in">len</span>(attention_weights))</span><br><span class="line">        plt.plot(x, attention_weights, marker=<span class="string">'o'</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> item_labels:</span><br><span class="line">            plt.xticks(x, item_labels, rotation=<span class="number">45</span>, ha=<span class="string">'right'</span>)</span><br><span class="line">        </span><br><span class="line">        plt.xlabel(<span class="string">'Position in Sequence'</span>)</span><br><span class="line">        plt.ylabel(<span class="string">'Attention Weight'</span>)</span><br><span class="line">        plt.title(title)</span><br><span class="line">        plt.grid(<span class="literal">True</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="lime-and-shap-for-model-interpretation">LIME and SHAP for Model
Interpretation</h2>
<h3 id="lime-local-interpretable-model-agnostic-explanations">LIME
(Local Interpretable Model-agnostic Explanations)</h3>
<p>LIME explains individual predictions by learning an interpretable
model locally around the prediction.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LIMEExplainer</span>:</span><br><span class="line">    <span class="string">"""LIME explainer for recommendation systems"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model, feature_names: <span class="type">List</span>[<span class="built_in">str</span>] = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            model: Black-box recommendation model</span></span><br><span class="line"><span class="string">            feature_names: Names of input features</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.model = model</span><br><span class="line">        self.feature_names = feature_names <span class="keyword">or</span> [<span class="string">f"feature_<span class="subst">{i}</span>"</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>)]</span><br><span class="line">        self.scaler = StandardScaler()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">explain</span>(<span class="params">self, user_features: np.ndarray, item_features: np.ndarray,</span></span><br><span class="line"><span class="params">               num_samples: <span class="built_in">int</span> = <span class="number">1000</span>, num_features: <span class="built_in">int</span> = <span class="number">10</span></span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">float</span>]:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Explain prediction for a user-item pair.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_features: User feature vector</span></span><br><span class="line"><span class="string">            item_features: Item feature vector</span></span><br><span class="line"><span class="string">            num_samples: Number of samples for LIME</span></span><br><span class="line"><span class="string">            num_features: Number of top features to return</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Dictionary mapping feature names to importance scores</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># Combine user and item features</span></span><br><span class="line">        combined_features = np.concatenate([user_features, item_features])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Get original prediction</span></span><br><span class="line">        original_pred = self._predict(user_features, item_features)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Generate perturbed samples</span></span><br><span class="line">        samples = self._generate_samples(combined_features, num_samples)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Get predictions for samples</span></span><br><span class="line">        predictions = []</span><br><span class="line">        <span class="keyword">for</span> sample <span class="keyword">in</span> samples:</span><br><span class="line">            <span class="comment"># Split back to user and item features</span></span><br><span class="line">            user_feat = sample[:<span class="built_in">len</span>(user_features)]</span><br><span class="line">            item_feat = sample[<span class="built_in">len</span>(user_features):]</span><br><span class="line">            pred = self._predict(user_feat, item_feat)</span><br><span class="line">            predictions.append(pred)</span><br><span class="line">        </span><br><span class="line">        predictions = np.array(predictions)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute distances (weights)</span></span><br><span class="line">        distances = self._compute_distances(combined_features, samples)</span><br><span class="line">        weights = np.exp(-distances ** <span class="number">2</span> / <span class="number">0.25</span>)  <span class="comment"># Kernel width</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Fit interpretable model (linear)</span></span><br><span class="line">        interpretable_model = Ridge(alpha=<span class="number">1.0</span>)</span><br><span class="line">        interpretable_model.fit(samples, predictions, sample_weight=weights)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Get feature importances</span></span><br><span class="line">        importances = np.<span class="built_in">abs</span>(interpretable_model.coef_)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Map to feature names</span></span><br><span class="line">        feature_importance = {</span><br><span class="line">            self.feature_names[i]: importances[i]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.feature_names))</span><br><span class="line">        }</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Sort and return top features</span></span><br><span class="line">        sorted_features = <span class="built_in">sorted</span>(</span><br><span class="line">            feature_importance.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">dict</span>(sorted_features[:num_features])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_predict</span>(<span class="params">self, user_features: np.ndarray, item_features: np.ndarray</span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">"""Get prediction from model"""</span></span><br><span class="line">        <span class="comment"># This depends on model interface</span></span><br><span class="line">        <span class="comment"># Simplified: assume model takes concatenated features</span></span><br><span class="line">        combined = np.concatenate([user_features, item_features])</span><br><span class="line">        <span class="keyword">return</span> self.model.predict(combined.reshape(<span class="number">1</span>, -<span class="number">1</span>))[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_generate_samples</span>(<span class="params">self, original: np.ndarray, num_samples: <span class="built_in">int</span></span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">"""Generate perturbed samples around original"""</span></span><br><span class="line">        samples = []</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_samples):</span><br><span class="line">            <span class="comment"># Add Gaussian noise</span></span><br><span class="line">            noise = np.random.normal(<span class="number">0</span>, <span class="number">0.1</span>, size=original.shape)</span><br><span class="line">            sample = original + noise</span><br><span class="line">            samples.append(sample)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> np.array(samples)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_compute_distances</span>(<span class="params">self, original: np.ndarray, samples: np.ndarray</span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">"""Compute distances between original and samples"""</span></span><br><span class="line">        distances = np.linalg.norm(samples - original, axis=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> distances</span><br></pre></td></tr></table></figure>
<h3 id="shap-shapley-additive-explanations">SHAP (SHapley Additive
exPlanations)</h3>
<p>SHAP uses game theory to assign feature importance values.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> combinations</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SHAPExplainer</span>:</span><br><span class="line">    <span class="string">"""SHAP explainer for recommendation systems"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model, feature_names: <span class="type">List</span>[<span class="built_in">str</span>] = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            model: Black-box recommendation model</span></span><br><span class="line"><span class="string">            feature_names: Names of input features</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.model = model</span><br><span class="line">        self.feature_names = feature_names <span class="keyword">or</span> [<span class="string">f"feature_<span class="subst">{i}</span>"</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>)]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">explain</span>(<span class="params">self, user_features: np.ndarray, item_features: np.ndarray,</span></span><br><span class="line"><span class="params">               baseline: np.ndarray = <span class="literal">None</span></span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">float</span>]:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Compute SHAP values for a prediction.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_features: User feature vector</span></span><br><span class="line"><span class="string">            item_features: Item feature vector</span></span><br><span class="line"><span class="string">            baseline: Baseline feature vector (e.g., mean features)</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Dictionary mapping feature names to SHAP values</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># Combine features</span></span><br><span class="line">        combined_features = np.concatenate([user_features, item_features])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> baseline <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            baseline = np.zeros_like(combined_features)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute SHAP values</span></span><br><span class="line">        shap_values = self._compute_shap_values(combined_features, baseline)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Map to feature names</span></span><br><span class="line">        feature_shap = {</span><br><span class="line">            self.feature_names[i]: shap_values[i]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.feature_names))</span><br><span class="line">        }</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> feature_shap</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_compute_shap_values</span>(<span class="params">self, features: np.ndarray,</span></span><br><span class="line"><span class="params">                            baseline: np.ndarray</span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Compute SHAP values using Shapley value formula.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Note: Exact computation is exponential. This is a simplified version.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        n_features = <span class="built_in">len</span>(features)</span><br><span class="line">        shap_values = np.zeros(n_features)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># For each feature</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_features):</span><br><span class="line">            shap_value = <span class="number">0.0</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Sum over all subsets S not containing i</span></span><br><span class="line">            <span class="keyword">for</span> subset_size <span class="keyword">in</span> <span class="built_in">range</span>(n_features):</span><br><span class="line">                <span class="comment"># Generate all subsets of size subset_size</span></span><br><span class="line">                other_features = [j <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n_features) <span class="keyword">if</span> j != i]</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">for</span> subset <span class="keyword">in</span> combinations(other_features, subset_size):</span><br><span class="line">                    subset = <span class="built_in">set</span>(subset)</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># f(S) - prediction with features in S set to baseline</span></span><br><span class="line">                    features_S = baseline.copy()</span><br><span class="line">                    <span class="keyword">for</span> j <span class="keyword">in</span> subset:</span><br><span class="line">                        features_S[j] = features[j]</span><br><span class="line">                    pred_S = self._predict_from_features(features_S)</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># f(S âˆª {i}) - prediction with feature i added</span></span><br><span class="line">                    features_S_i = features_S.copy()</span><br><span class="line">                    features_S_i[i] = features[i]</span><br><span class="line">                    pred_S_i = self._predict_from_features(features_S_i)</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># Shapley value contribution</span></span><br><span class="line">                    weight = <span class="number">1.0</span> / (n_features * </span><br><span class="line">                                   <span class="built_in">len</span>(<span class="built_in">list</span>(combinations(other_features, subset_size))))</span><br><span class="line">                    shap_value += weight * (pred_S_i - pred_S)</span><br><span class="line">            </span><br><span class="line">            shap_values[i] = shap_value</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> shap_values</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_predict_from_features</span>(<span class="params">self, features: np.ndarray</span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">"""Get prediction from feature vector"""</span></span><br><span class="line">        <span class="keyword">return</span> self.model.predict(features.reshape(<span class="number">1</span>, -<span class="number">1</span>))[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">explain_approximate</span>(<span class="params">self, user_features: np.ndarray,</span></span><br><span class="line"><span class="params">                           item_features: np.ndarray,</span></span><br><span class="line"><span class="params">                           num_samples: <span class="built_in">int</span> = <span class="number">100</span></span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">float</span>]:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Approximate SHAP values using sampling (faster for large feature sets).</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_features: User feature vector</span></span><br><span class="line"><span class="string">            item_features: Item feature vector</span></span><br><span class="line"><span class="string">            num_samples: Number of samples for approximation</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Dictionary mapping feature names to approximate SHAP values</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        combined_features = np.concatenate([user_features, item_features])</span><br><span class="line">        baseline = np.zeros_like(combined_features)</span><br><span class="line">        </span><br><span class="line">        n_features = <span class="built_in">len</span>(combined_features)</span><br><span class="line">        shap_values = np.zeros(n_features)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Sample-based approximation</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_samples):</span><br><span class="line">            <span class="comment"># Random subset of features</span></span><br><span class="line">            subset = np.random.choice(n_features, </span><br><span class="line">                                     size=np.random.randint(<span class="number">0</span>, n_features),</span><br><span class="line">                                     replace=<span class="literal">False</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_features):</span><br><span class="line">                <span class="comment"># With feature i</span></span><br><span class="line">                features_with_i = baseline.copy()</span><br><span class="line">                features_with_i[subset] = combined_features[subset]</span><br><span class="line">                features_with_i[i] = combined_features[i]</span><br><span class="line">                pred_with_i = self._predict_from_features(features_with_i)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># Without feature i</span></span><br><span class="line">                features_without_i = baseline.copy()</span><br><span class="line">                features_without_i[subset] = combined_features[subset]</span><br><span class="line">                pred_without_i = self._predict_from_features(features_without_i)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># Contribution</span></span><br><span class="line">                contribution = (pred_with_i - pred_without_i) / num_samples</span><br><span class="line">                shap_values[i] += contribution</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Map to feature names</span></span><br><span class="line">        feature_shap = {</span><br><span class="line">            self.feature_names[i]: shap_values[i]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.feature_names))</span><br><span class="line">        }</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> feature_shap</span><br></pre></td></tr></table></figure>
<h2 id="trust-building-strategies">Trust Building Strategies</h2>
<h3 id="transparency">Transparency</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TransparentRecommender</span>:</span><br><span class="line">    <span class="string">"""Recommender that provides transparency"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">recommend_with_explanation</span>(<span class="params">self, user_id: <span class="built_in">int</span>, top_k: <span class="built_in">int</span> = <span class="number">10</span></span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Provide recommendations with full transparency.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            List of (item_id, score, explanation, confidence) tuples</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        recommendations = self._generate_recommendations(user_id, top_k)</span><br><span class="line">        </span><br><span class="line">        transparent_recs = []</span><br><span class="line">        <span class="keyword">for</span> item_id, score <span class="keyword">in</span> recommendations:</span><br><span class="line">            explanation = self._generate_explanation(user_id, item_id)</span><br><span class="line">            confidence = self._compute_confidence(user_id, item_id)</span><br><span class="line">            </span><br><span class="line">            transparent_recs.append({</span><br><span class="line">                <span class="string">'item_id'</span>: item_id,</span><br><span class="line">                <span class="string">'score'</span>: score,</span><br><span class="line">                <span class="string">'explanation'</span>: explanation,</span><br><span class="line">                <span class="string">'confidence'</span>: confidence,</span><br><span class="line">                <span class="string">'factors'</span>: self._get_contributing_factors(user_id, item_id)</span><br><span class="line">            })</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> transparent_recs</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_generate_recommendations</span>(<span class="params">self, user_id: <span class="built_in">int</span>, top_k: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="string">"""Generate recommendations (placeholder)"""</span></span><br><span class="line">        <span class="comment"># Implementation depends on model</span></span><br><span class="line">        <span class="keyword">return</span> [(i, <span class="number">0.9</span> - i * <span class="number">0.1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(top_k)]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_generate_explanation</span>(<span class="params">self, user_id: <span class="built_in">int</span>, item_id: <span class="built_in">int</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""Generate explanation (placeholder)"""</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">f"Recommended because it matches your preferences."</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_compute_confidence</span>(<span class="params">self, user_id: <span class="built_in">int</span>, item_id: <span class="built_in">int</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">"""Compute confidence score (placeholder)"""</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.85</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_contributing_factors</span>(<span class="params">self, user_id: <span class="built_in">int</span>, item_id: <span class="built_in">int</span></span>) -&gt; <span class="type">Dict</span>:</span><br><span class="line">        <span class="string">"""Get contributing factors (placeholder)"""</span></span><br><span class="line">        <span class="keyword">return</span> {</span><br><span class="line">            <span class="string">'user_history'</span>: <span class="number">0.4</span>,</span><br><span class="line">            <span class="string">'item_features'</span>: <span class="number">0.3</span>,</span><br><span class="line">            <span class="string">'similar_users'</span>: <span class="number">0.3</span></span><br><span class="line">        }</span><br></pre></td></tr></table></figure>
<h3 id="user-control">User Control</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UserControlledRecommender</span>:</span><br><span class="line">    <span class="string">"""Recommender that allows user control"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.user_preferences = {}</span><br><span class="line">        self.user_filters = {}</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set_preference</span>(<span class="params">self, user_id: <span class="built_in">int</span>, preference_type: <span class="built_in">str</span>, value: <span class="built_in">float</span></span>):</span><br><span class="line">        <span class="string">"""Allow users to set preferences"""</span></span><br><span class="line">        <span class="keyword">if</span> user_id <span class="keyword">not</span> <span class="keyword">in</span> self.user_preferences:</span><br><span class="line">            self.user_preferences[user_id] = {}</span><br><span class="line">        </span><br><span class="line">        self.user_preferences[user_id][preference_type] = value</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set_filter</span>(<span class="params">self, user_id: <span class="built_in">int</span>, filter_type: <span class="built_in">str</span>, filter_value</span>):</span><br><span class="line">        <span class="string">"""Allow users to set filters"""</span></span><br><span class="line">        <span class="keyword">if</span> user_id <span class="keyword">not</span> <span class="keyword">in</span> self.user_filters:</span><br><span class="line">            self.user_filters[user_id] = {}</span><br><span class="line">        </span><br><span class="line">        self.user_filters[user_id][filter_type] = filter_value</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">recommend</span>(<span class="params">self, user_id: <span class="built_in">int</span>, top_k: <span class="built_in">int</span> = <span class="number">10</span></span>):</span><br><span class="line">        <span class="string">"""Generate recommendations respecting user preferences and filters"""</span></span><br><span class="line">        <span class="comment"># Get base recommendations</span></span><br><span class="line">        base_recs = self._generate_base_recommendations(user_id)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Apply user preferences</span></span><br><span class="line">        adjusted_recs = self._apply_preferences(user_id, base_recs)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Apply filters</span></span><br><span class="line">        filtered_recs = self._apply_filters(user_id, adjusted_recs)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> filtered_recs[:top_k]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_generate_base_recommendations</span>(<span class="params">self, user_id: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="string">"""Generate base recommendations"""</span></span><br><span class="line">        <span class="keyword">return</span> [(i, <span class="number">0.9</span> - i * <span class="number">0.1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>)]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_apply_preferences</span>(<span class="params">self, user_id: <span class="built_in">int</span>, recs: <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">float</span>]]</span>):</span><br><span class="line">        <span class="string">"""Apply user preferences to adjust scores"""</span></span><br><span class="line">        <span class="keyword">if</span> user_id <span class="keyword">not</span> <span class="keyword">in</span> self.user_preferences:</span><br><span class="line">            <span class="keyword">return</span> recs</span><br><span class="line">        </span><br><span class="line">        preferences = self.user_preferences[user_id]</span><br><span class="line">        adjusted = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> item_id, score <span class="keyword">in</span> recs:</span><br><span class="line">            <span class="comment"># Adjust score based on preferences</span></span><br><span class="line">            <span class="comment"># Simplified: assume preferences affect score multiplicatively</span></span><br><span class="line">            adjustment = <span class="number">1.0</span></span><br><span class="line">            <span class="keyword">for</span> pref_type, pref_value <span class="keyword">in</span> preferences.items():</span><br><span class="line">                <span class="comment"># This would use item features in practice</span></span><br><span class="line">                adjustment *= (<span class="number">1.0</span> + pref_value * <span class="number">0.1</span>)</span><br><span class="line">            </span><br><span class="line">            adjusted.append((item_id, score * adjustment))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Re-sort</span></span><br><span class="line">        adjusted.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> adjusted</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_apply_filters</span>(<span class="params">self, user_id: <span class="built_in">int</span>, recs: <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">float</span>]]</span>):</span><br><span class="line">        <span class="string">"""Apply user filters"""</span></span><br><span class="line">        <span class="keyword">if</span> user_id <span class="keyword">not</span> <span class="keyword">in</span> self.user_filters:</span><br><span class="line">            <span class="keyword">return</span> recs</span><br><span class="line">        </span><br><span class="line">        filters = self.user_filters[user_id]</span><br><span class="line">        filtered = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> item_id, score <span class="keyword">in</span> recs:</span><br><span class="line">            <span class="comment"># Check if item passes filters</span></span><br><span class="line">            <span class="comment"># Simplified: assume filters are exclusion lists</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">'exclude_categories'</span> <span class="keyword">in</span> filters:</span><br><span class="line">                <span class="comment"># Would check item category in practice</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line">            filtered.append((item_id, score))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> filtered</span><br></pre></td></tr></table></figure>
<h2 id="complete-example-fair-and-explainable-recommender">Complete
Example: Fair and Explainable Recommender</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FairExplainableRecommender</span>:</span><br><span class="line">    <span class="string">"""Complete fair and explainable recommendation system"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_users: <span class="built_in">int</span>, num_items: <span class="built_in">int</span></span>):</span><br><span class="line">        self.num_users = num_users</span><br><span class="line">        self.num_items = num_items</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Components</span></span><br><span class="line">        self.model = <span class="literal">None</span>  <span class="comment"># Base recommendation model</span></span><br><span class="line">        self.fairness_module = <span class="literal">None</span>  <span class="comment"># Fairness module</span></span><br><span class="line">        self.explainer = <span class="literal">None</span>  <span class="comment"># Explanation module</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Metrics</span></span><br><span class="line">        self.bias_metrics = <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, train_data, protected_attrs: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">             lambda_fair: <span class="built_in">float</span> = <span class="number">1.0</span></span>):</span><br><span class="line">        <span class="string">"""Train fair recommendation model"""</span></span><br><span class="line">        <span class="comment"># Initialize model</span></span><br><span class="line">        self.model = CFairER(self.num_users, self.num_items)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Train with fairness constraints</span></span><br><span class="line">        train_cfairer(self.model, train_data, protected_attrs,</span><br><span class="line">                     lambda_fair=lambda_fair)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Initialize explainer</span></span><br><span class="line">        self.explainer = FeatureBasedExplainer({})</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Initialize bias metrics</span></span><br><span class="line">        self.bias_metrics = BiasMetrics({}, {})</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">recommend</span>(<span class="params">self, user_id: <span class="built_in">int</span>, top_k: <span class="built_in">int</span> = <span class="number">10</span>,</span></span><br><span class="line"><span class="params">                 explain: <span class="built_in">bool</span> = <span class="literal">True</span></span>) -&gt; <span class="type">List</span>[<span class="type">Dict</span>]:</span><br><span class="line">        <span class="string">"""Generate fair and explainable recommendations"""</span></span><br><span class="line">        <span class="comment"># Generate base recommendations</span></span><br><span class="line">        recommendations = self.model.recommend(user_id, top_k)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Apply fairness post-processing if needed</span></span><br><span class="line">        fair_recommendations = self._apply_fairness_postprocessing(</span><br><span class="line">            user_id, recommendations</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Generate explanations</span></span><br><span class="line">        results = []</span><br><span class="line">        <span class="keyword">for</span> item_id <span class="keyword">in</span> fair_recommendations:</span><br><span class="line">            result = {</span><br><span class="line">                <span class="string">'item_id'</span>: item_id,</span><br><span class="line">                <span class="string">'score'</span>: self._get_score(user_id, item_id)</span><br><span class="line">            }</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> explain:</span><br><span class="line">                result[<span class="string">'explanation'</span>] = self.explainer.explain(</span><br><span class="line">                    user_id, item_id, {}</span><br><span class="line">                )</span><br><span class="line">                result[<span class="string">'factors'</span>] = self._get_contributing_factors(</span><br><span class="line">                    user_id, item_id</span><br><span class="line">                )</span><br><span class="line">            </span><br><span class="line">            results.append(result)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> results</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_apply_fairness_postprocessing</span>(<span class="params">self, user_id: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                                      recommendations: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="string">"""Apply fairness post-processing"""</span></span><br><span class="line">        <span class="comment"># Could use FairReranker here</span></span><br><span class="line">        <span class="keyword">return</span> recommendations</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_score</span>(<span class="params">self, user_id: <span class="built_in">int</span>, item_id: <span class="built_in">int</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">"""Get recommendation score"""</span></span><br><span class="line">        <span class="comment"># Implementation depends on model</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.85</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_contributing_factors</span>(<span class="params">self, user_id: <span class="built_in">int</span>, item_id: <span class="built_in">int</span></span>) -&gt; <span class="type">Dict</span>:</span><br><span class="line">        <span class="string">"""Get contributing factors for explanation"""</span></span><br><span class="line">        <span class="keyword">return</span> {</span><br><span class="line">            <span class="string">'user_history'</span>: <span class="number">0.4</span>,</span><br><span class="line">            <span class="string">'item_features'</span>: <span class="number">0.3</span>,</span><br><span class="line">            <span class="string">'similar_users'</span>: <span class="number">0.3</span></span><br><span class="line">        }</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">evaluate_fairness</span>(<span class="params">self, recommendations: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="type">List</span>[<span class="built_in">int</span>]],</span></span><br><span class="line"><span class="params">                         protected_attrs: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]</span>) -&gt; <span class="type">Dict</span>:</span><br><span class="line">        <span class="string">"""Evaluate fairness of recommendations"""</span></span><br><span class="line">        self.bias_metrics = BiasMetrics(</span><br><span class="line">            recommendations, {}, </span><br><span class="line">            user_groups=protected_attrs</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> self.bias_metrics.comprehensive_report()</span><br></pre></td></tr></table></figure>
<h2 id="qa-section">Q&amp;A Section</h2>
<h3 id="q1-what-is-the-difference-between-fairness-and-explainability">Q1:
What is the difference between fairness and explainability?</h3>
<p><strong>A:</strong> Fairness ensures that recommendations treat all
users and items equitably, without systematic bias toward certain
groups. Explainability ensures that users and stakeholders can
understand why recommendations are made. While related (explainability
can help identify unfair patterns), they address different concerns: -
<strong>Fairness</strong>: "Are recommendations fair?" (normative
question) - <strong>Explainability</strong>: "Why was this recommended?"
(descriptive question)</p>
<p>A system can be explainable but unfair (e.g., clearly explaining
biased recommendations), or fair but unexplainable (e.g., fair
recommendations from a black-box model).</p>
<h3 id="q2-how-do-i-choose-between-pre-processing-in-processing-and-post-processing-debiasing-methods">Q2:
How do I choose between pre-processing, in-processing, and
post-processing debiasing methods?</h3>
<p><strong>A:</strong> The choice depends on your constraints:</p>
<p><strong>Pre-processing</strong> (modify data): - âœ… Pros:
Model-agnostic, easy to implement - âŒ Cons: May lose information,
doesn't address algorithmic bias - <strong>Use when</strong>: You have
control over data collection, want model-agnostic solution</p>
<p><strong>In-processing</strong> (modify training): - âœ… Pros:
Addresses root cause, can optimize fairness-accuracy trade-off - âŒ
Cons: Requires model modification, more complex - <strong>Use
when</strong>: You can modify model architecture, want optimal
trade-offs</p>
<p><strong>Post-processing</strong> (modify outputs): - âœ… Pros: No
model changes needed, fast to deploy - âŒ Cons: May reduce accuracy,
doesn't fix underlying bias - <strong>Use when</strong>: Model is
already trained, need quick solution</p>
<p><strong>Best practice</strong>: Combine methods (e.g., pre-processing
+ in-processing).</p>
<h3 id="q3-how-do-i-measure-fairness-in-recommendation-systems">Q3: How
do I measure fairness in recommendation systems?</h3>
<p><strong>A:</strong> Fairness can be measured at multiple levels:</p>
<p><strong>User-level fairness</strong>: - Demographic parity: Equal
recommendation quality across user groups - Equalized odds: Equal
true/false positive rates across groups</p>
<p><strong>Item-level fairness</strong>: - Exposure fairness: Equal
exposure across item groups - Quality fairness: High-quality items get
fair exposure</p>
<p><strong>Metrics</strong>: - Gini coefficient (inequality) -
Demographic parity gap - Item coverage - Diversity metrics</p>
<p>Use multiple metrics to get a comprehensive view.</p>
<h3 id="q4-what-is-counterfactual-fairness-and-why-is-it-important">Q4:
What is counterfactual fairness and why is it important?</h3>
<p><strong>A:</strong> Counterfactual fairness ensures that changing a
user's protected attributes (e.g., gender, race) while keeping other
attributes constant would not change recommendations. This is important
because:</p>
<ol type="1">
<li><strong>Causal understanding</strong>: It addresses "what if"
questions about fairness</li>
<li><strong>Legal compliance</strong>: Aligns with anti-discrimination
laws</li>
<li><strong>User trust</strong>: Users trust systems that treat similar
users similarly</li>
</ol>
<p><strong>Example</strong>: Two users with identical preferences except
gender should receive similar recommendations.</p>
<h3 id="q5-how-do-lime-and-shap-differ">Q5: How do LIME and SHAP
differ?</h3>
<p><strong>A:</strong></p>
<p><strong>LIME</strong>: - Local explanations (explains individual
predictions) - Uses linear models locally - Faster, easier to implement
- May be inconsistent across similar inputs</p>
<p><strong>SHAP</strong>: - Based on Shapley values (game theory) -
Theoretically grounded (additivity, efficiency) - More consistent -
Computationally expensive (exact) or approximate</p>
<p><strong>Choose LIME</strong> for: Quick explanations, large feature
sets, when consistency isn't critical.</p>
<p><strong>Choose SHAP</strong> for: Theoretically sound explanations,
when consistency matters, smaller feature sets.</p>
<h3 id="q6-how-can-i-balance-fairness-and-accuracy">Q6: How can I
balance fairness and accuracy?</h3>
<p><strong>A:</strong> This is a fundamental trade-off. Strategies:</p>
<ol type="1">
<li><p><strong>Multi-objective optimization</strong>: Optimize both
fairness and accuracy <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.666ex;" xmlns="http://www.w3.org/2000/svg" width="23.474ex" height="2.261ex" role="img" focusable="false" viewbox="0 -705 10375.7 999.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="4C" d="M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z"/></g></g><g data-mml-node="mo" transform="translate(967.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="msub" transform="translate(2023.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="4C" d="M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z"/></g></g><g data-mml-node="TeXAtom" transform="translate(723,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"/><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(500,0)"/><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(944,0)"/><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z" transform="translate(1388,0)"/><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(1944,0)"/><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2336,0)"/><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(2836,0)"/><path data-c="79" d="M69 -66Q91 -66 104 -80T118 -116Q118 -134 109 -145T91 -160Q84 -163 97 -166Q104 -168 111 -168Q131 -168 148 -159T175 -138T197 -106T213 -75T225 -43L242 0L170 183Q150 233 125 297Q101 358 96 368T80 381Q79 382 78 382Q66 385 34 385H19V431H26L46 430Q65 430 88 429T122 428Q129 428 142 428T171 429T200 430T224 430L233 431H241V385H232Q183 385 185 366L286 112Q286 113 332 227L376 341V350Q376 365 366 373T348 383T334 385H331V431H337H344Q351 431 361 431T382 430T405 429T422 429Q477 429 503 431H508V385H497Q441 380 422 345Q420 343 378 235T289 9T227 -131Q180 -204 113 -204Q69 -204 44 -177T19 -116Q19 -89 35 -78T69 -66Z" transform="translate(3280,0)"/></g></g></g><g data-mml-node="mo" transform="translate(5711.4,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"/></g><g data-mml-node="mi" transform="translate(6711.7,0)"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="msub" transform="translate(7294.7,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="4C" d="M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z"/></g></g><g data-mml-node="TeXAtom" transform="translate(723,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z"/><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(306,0)"/><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(806,0)"/><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(1084,0)"/><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1476,0)"/><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(2032,0)"/><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(2476,0)"/><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(2870,0)"/></g></g></g></g></g></svg></mjx-container></span></p></li>
<li><p><strong>Pareto frontier</strong>: Explore trade-offs, let
stakeholders choose</p></li>
<li><p><strong>Fairness constraints</strong>: Set fairness thresholds,
optimize accuracy subject to constraints</p></li>
<li><p><strong>Group-specific models</strong>: Different models for
different groups (if legally allowed)</p></li>
<li><p><strong>Calibration</strong>: Ensure predictions are
well-calibrated across groups</p></li>
</ol>
<p><strong>Best practice</strong>: Start with small <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.027ex;" xmlns="http://www.w3.org/2000/svg" width="1.319ex" height="1.597ex" role="img" focusable="false" viewbox="0 -694 583 706"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g></g></g></svg></mjx-container></span>, gradually increase while
monitoring both metrics.</p>
<h3 id="q7-how-do-i-explain-recommendations-to-non-technical-users">Q7:
How do I explain recommendations to non-technical users?</h3>
<p><strong>A:</strong> Use simple, intuitive explanations:</p>
<ol type="1">
<li><strong>Feature-based</strong>: "Because you like action
movies"</li>
<li><strong>Neighbor-based</strong>: "Users like you also liked
this"</li>
<li><strong>Temporal</strong>: "Because you watched X recently"</li>
<li><strong>Visual</strong>: Use charts, heatmaps for attention</li>
</ol>
<p><strong>Guidelines</strong>: - Avoid technical jargon - Focus on
user-relevant factors - Be concise (1-2 sentences) - Provide actionable
information</p>
<h3 id="q8-what-are-common-pitfalls-in-fairness-evaluation">Q8: What are
common pitfalls in fairness evaluation?</h3>
<p><strong>A:</strong> Common pitfalls:</p>
<ol type="1">
<li><strong>Single metric</strong>: Using only one fairness metric (use
multiple)</li>
<li><strong>Ignoring intersectionality</strong>: Not considering
multiple protected attributes together</li>
<li><strong>Offline-only evaluation</strong>: Not testing in real-world
conditions</li>
<li><strong>Ignoring feedback loops</strong>: Not accounting for how
recommendations affect future data</li>
<li><strong>Static evaluation</strong>: Not monitoring fairness over
time</li>
<li><strong>Group size</strong>: Not accounting for small group sizes
(statistical significance)</li>
</ol>
<p><strong>Best practice</strong>: Comprehensive evaluation with
multiple metrics, online testing, continuous monitoring.</p>
<h3 id="q9-how-do-i-handle-fairness-in-sequential-recommendation">Q9:
How do I handle fairness in sequential recommendation?</h3>
<p><strong>A:</strong> Sequential recommendation adds temporal
challenges:</p>
<ol type="1">
<li><strong>Temporal bias</strong>: Recent items may be
over-represented</li>
<li><strong>Feedback loops</strong>: Recommendations affect future
sequences</li>
<li><strong>Fairness over time</strong>: Ensure fairness across time
periods</li>
</ol>
<p><strong>Solutions</strong>: - Fairness-aware sequence modeling -
Temporal diversity constraints - Long-term fairness objectives -
Counterfactual evaluation over sequences</p>
<h3 id="q10-what-are-the-legal-and-ethical-considerations">Q10: What are
the legal and ethical considerations?</h3>
<p><strong>A:</strong> Key considerations:</p>
<p><strong>Legal</strong>: - Anti-discrimination laws (e.g., Title VII
in US, GDPR in EU) - Protected attributes (gender, race, age, etc.) -
Disparate impact vs. disparate treatment</p>
<p><strong>Ethical</strong>: - Transparency: Users should know how
recommendations work - User autonomy: Users should control their
recommendations - Beneficence: Recommendations should benefit users -
Non-maleficence: Avoid harm (e.g., filter bubbles, addiction)</p>
<p><strong>Best practices</strong>: - Document fairness decisions -
Regular audits - User consent for data use - Explainability for users -
Compliance with regulations</p>
<h2 id="summary">Summary</h2>
<p>Fairness and explainability are critical for building trustworthy
recommendation systems. This article covered:</p>
<p><strong>Key Concepts</strong>: - Types of bias (popularity,
demographic, confirmation, etc.) - Causal inference foundations
(potential outcomes, confounders) - Counterfactual reasoning and CFairER
- Debiasing methods (pre-, in-, post-processing) - Explainability
techniques (feature-based, neighbor-based, attention) - Interpretation
tools (LIME, SHAP) - Trust-building strategies</p>
<p><strong>Practical Takeaways</strong>: 1. Measure bias comprehensively
before addressing it 2. Use multiple debiasing methods in combination 3.
Provide explanations that users can understand 4. Balance fairness and
accuracy carefully 5. Monitor fairness continuously in production 6.
Consider legal and ethical implications</p>
<p><strong>Future Directions</strong>: - Long-term fairness (fairness
over time) - Multi-stakeholder fairness (users, items, platforms) -
Causal explainability (why vs. how) - Federated fairness (distributed
systems) - Human-in-the-loop fairness (incorporating human feedback)</p>
<p>Building fair and explainable recommendation systems is an ongoing
process that requires continuous monitoring, evaluation, and
improvement. By understanding the foundations and implementing the
techniques covered in this article, you can build recommendation systems
that users trust and that treat all stakeholders equitably.</p>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    
    
    
    
    
    
    <ul>
        <li>Post titleï¼šRecommendation Systems (13): Fairness, Debiasing, and Explainability</li>
        <li>Post authorï¼šChen Kai</li>
        <li>Create timeï¼š2025-11-16 00:00:00</li>
        <li>
            Post linkï¼šhttps://www.chenk.top/en/recommendation-systems-13-fairness-explainability/
        </li>
        <li>
            Copyright Noticeï¼šAll articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en">BY-NC-SA</a> unless stating additionally.
        </li>
    </ul>
</div>

            </div>
        

        
            <ul class="post-tags-box">
                
                    <li class="tag-item">
                        <a href="/en/tags/Recommendation-Systems/">#Recommendation Systems</a>&nbsp;
                    </li>
                
                    <li class="tag-item">
                        <a href="/en/tags/Fairness/">#Fairness</a>&nbsp;
                    </li>
                
                    <li class="tag-item">
                        <a href="/en/tags/Explainability/">#Explainability</a>&nbsp;
                    </li>
                
            </ul>
        

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/en/recommendation-systems-14-cross-domain-cold-start/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Recommendation Systems (14): Cross-Domain Recommendation and Cold-Start Solutions</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/en/recommendation-systems-12-llm-recommendation/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Recommendation Systems (12): Large Language Models and Recommendation</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
            <div class="comment-container">
                <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fas fa-comments">&nbsp;Comments</i>
    </div>
    

        
            
    <div class="valine-container">
        <script data-pjax
                src="//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script>
        <div id="vcomments"></div>
        <script data-pjax>
            function loadValine() {
                new Valine({
                    el: '#vcomments',
                    appId: 'p2Cu9MgjoKzo3VmulhNLIusH-gzGzoHsz',
                    appKey: 'QThQHg3c8sVwGpzg9lu8zEG3',
                    meta: ['nick', 'mail', 'link'],
                    avatar: 'wavatar',
                    enableQQ: true,
                    placeholder: 'ðŸ˜œ å°½æƒ…èµžç¾Žå¸…æ°”ä¼Ÿå¤§çš„ckå§~',
                    lang: 'en'.toLowerCase()
                });

                function getAuthor(language) {
                    switch (language) {
                        case 'en':
                            return 'Author';
                        case 'zh-CN':
                            return 'åšä¸»';
                        default:
                            return 'Master';
                    }
                }

                // Add "Author" identify
                const getValineDomTimer = setInterval(() => {
                    const vcards = document.querySelectorAll('#vcomments .vcards .vcard');
                    if (vcards.length > 0) {
                        let author = 'Chen Kai';

                        if (author) {
                            for (let vcard of vcards) {
                                const vnick_dom = vcard.querySelector('.vhead .vnick');
                                const vnick = vnick_dom.innerHTML;
                                if (vnick === author) {
                                    vnick_dom.innerHTML = `${vnick} <span class="author">${getAuthor(KEEP.hexo_config.language)}</span>`
                                }
                            }
                        }
                        clearInterval(getValineDomTimer);
                    } else {
                        clearInterval(getValineDomTimer);
                    }
                }, 2000);
            }

            if ('true') {
                const loadValineTimeout = setTimeout(() => {
                    loadValine();
                    clearTimeout(loadValineTimeout);
                }, 1000);
            } else {
                window.addEventListener('DOMContentLoaded', loadValine);
            }
        </script>
    </div>



        
    
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2020</span>
              -
            
            2026&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Chen Kai</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
            </div>
        
        <div class="theme-info info-item">
            <!-- Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.5</a> -->
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fas fa-comment"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        
            <li class="tools-item rss flex-center">
                <a class="flex-center"
                   href="/atom.xml"
                   target="_blank"
                >
                    <i class="fas fa-rss"></i>
                </a>
            </li>
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#understanding-bias-in-recommendation-systems"><span class="nav-number">1.</span> <span class="nav-text">Understanding Bias
in Recommendation Systems</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#types-of-bias-in-recommendation-systems"><span class="nav-number">1.1.</span> <span class="nav-text">Types of Bias in
Recommendation Systems</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sources-of-bias"><span class="nav-number">1.2.</span> <span class="nav-text">Sources of Bias</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#measuring-bias"><span class="nav-number">1.3.</span> <span class="nav-text">Measuring Bias</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#causal-inference-foundations"><span class="nav-number">2.</span> <span class="nav-text">Causal Inference Foundations</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#why-causal-inference-matters"><span class="nav-number">2.1.</span> <span class="nav-text">Why Causal Inference Matters</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#basic-causal-concepts"><span class="nav-number">2.2.</span> <span class="nav-text">Basic Causal Concepts</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#causal-inference-methods"><span class="nav-number">2.3.</span> <span class="nav-text">Causal Inference Methods</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#counterfactual-reasoning"><span class="nav-number">3.</span> <span class="nav-text">Counterfactual Reasoning</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#what-are-counterfactuals"><span class="nav-number">3.1.</span> <span class="nav-text">What Are Counterfactuals?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#counterfactual-fairness"><span class="nav-number">3.2.</span> <span class="nav-text">Counterfactual Fairness</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#implementing-counterfactual-reasoning"><span class="nav-number">3.3.</span> <span class="nav-text">Implementing
Counterfactual Reasoning</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cfairer-counterfactual-fairness-in-recommendation"><span class="nav-number">4.</span> <span class="nav-text">CFairER:
Counterfactual Fairness in Recommendation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#cfairer-architecture"><span class="nav-number">4.1.</span> <span class="nav-text">CFairER Architecture</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#implementation"><span class="nav-number">4.2.</span> <span class="nav-text">Implementation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#debiasing-methods"><span class="nav-number">5.</span> <span class="nav-text">Debiasing Methods</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#pre-processing-methods"><span class="nav-number">5.1.</span> <span class="nav-text">Pre-Processing Methods</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#in-processing-methods"><span class="nav-number">5.2.</span> <span class="nav-text">In-Processing Methods</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#post-processing-methods"><span class="nav-number">5.3.</span> <span class="nav-text">Post-Processing Methods</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#explainable-recommendation"><span class="nav-number">6.</span> <span class="nav-text">Explainable Recommendation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#why-explainability-matters"><span class="nav-number">6.1.</span> <span class="nav-text">Why Explainability Matters</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#types-of-explanations"><span class="nav-number">6.2.</span> <span class="nav-text">Types of Explanations</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#attention-visualization"><span class="nav-number">7.</span> <span class="nav-text">Attention Visualization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#lime-and-shap-for-model-interpretation"><span class="nav-number">8.</span> <span class="nav-text">LIME and SHAP for Model
Interpretation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#lime-local-interpretable-model-agnostic-explanations"><span class="nav-number">8.1.</span> <span class="nav-text">LIME
(Local Interpretable Model-agnostic Explanations)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#shap-shapley-additive-explanations"><span class="nav-number">8.2.</span> <span class="nav-text">SHAP (SHapley Additive
exPlanations)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#trust-building-strategies"><span class="nav-number">9.</span> <span class="nav-text">Trust Building Strategies</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#transparency"><span class="nav-number">9.1.</span> <span class="nav-text">Transparency</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#user-control"><span class="nav-number">9.2.</span> <span class="nav-text">User Control</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#complete-example-fair-and-explainable-recommender"><span class="nav-number">10.</span> <span class="nav-text">Complete
Example: Fair and Explainable Recommender</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#qa-section"><span class="nav-number">11.</span> <span class="nav-text">Q&amp;A Section</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#q1-what-is-the-difference-between-fairness-and-explainability"><span class="nav-number">11.1.</span> <span class="nav-text">Q1:
What is the difference between fairness and explainability?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q2-how-do-i-choose-between-pre-processing-in-processing-and-post-processing-debiasing-methods"><span class="nav-number">11.2.</span> <span class="nav-text">Q2:
How do I choose between pre-processing, in-processing, and
post-processing debiasing methods?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q3-how-do-i-measure-fairness-in-recommendation-systems"><span class="nav-number">11.3.</span> <span class="nav-text">Q3: How
do I measure fairness in recommendation systems?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q4-what-is-counterfactual-fairness-and-why-is-it-important"><span class="nav-number">11.4.</span> <span class="nav-text">Q4:
What is counterfactual fairness and why is it important?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q5-how-do-lime-and-shap-differ"><span class="nav-number">11.5.</span> <span class="nav-text">Q5: How do LIME and SHAP
differ?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q6-how-can-i-balance-fairness-and-accuracy"><span class="nav-number">11.6.</span> <span class="nav-text">Q6: How can I
balance fairness and accuracy?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q7-how-do-i-explain-recommendations-to-non-technical-users"><span class="nav-number">11.7.</span> <span class="nav-text">Q7:
How do I explain recommendations to non-technical users?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q8-what-are-common-pitfalls-in-fairness-evaluation"><span class="nav-number">11.8.</span> <span class="nav-text">Q8: What are
common pitfalls in fairness evaluation?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q9-how-do-i-handle-fairness-in-sequential-recommendation"><span class="nav-number">11.9.</span> <span class="nav-text">Q9:
How do I handle fairness in sequential recommendation?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q10-what-are-the-legal-and-ethical-considerations"><span class="nav-number">11.10.</span> <span class="nav-text">Q10: What are
the legal and ethical considerations?</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#summary"><span class="nav-number">12.</span> <span class="nav-text">Summary</span></a></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>

<script src="/js/lang-switch.js"></script>



    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-copy.js"></script>





<div class="post-scripts pjax">
    
        
<script src="/js/left-side-toggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/toc.js"></script>

    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
