<!DOCTYPE html>



<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Chen Kai">
    
    <title>
        
            推荐系统（十二）—— 大语言模型与推荐系统 |
        
        Chen Kai Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/logo.svg">
    
<link rel="stylesheet" href="/css/font-awesome.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"chenk.top","root":"/","language":"zh-CN","default_language":"zh-CN","languages":["zh-CN","en"],"path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":true},"style":{"primary_color":"#0066CC","avatar":"/images/avatar.svg","favicon":"/images/logo.svg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":false,"scale":false},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"Keep writing and Keep loving."},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":true,"style":"default"},"pjax":{"enable":true},"lazyload":{"enable":false},"version":"3.4.5"};
    KEEP.language_ago = {"second":"%s 秒前","minute":"%s 分钟前","hour":"%s 小时前","day":"%s 天前","week":"%s 周前","month":"%s 个月前","year":"%s 年前"};
  </script>
<meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="Chen Kai Blog" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    
    
    
    
    

    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                Chen Kai Blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/"
                            >
                                首页
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/archives"
                            >
                                归档
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/categories"
                            >
                                分类
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/tags"
                            >
                                标签
                            </a>
                        </li>
                    
                    <li class="menu-item lang-switch lang-switch-trigger" title="Language">
                        <i class="fas fa-globe"></i>
                    </li>
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item lang-switch-trigger"><i class="fas fa-globe"></i></div>
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/">首页</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/archives">归档</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/categories">分类</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/tags">标签</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    
    
    
    

    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">推荐系统（十二）—— 大语言模型与推荐系统</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/avatar.svg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Chen Kai</span>
                        
                            <span class="author-label">BOSS</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    
    
    
    
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;
        <span class="pc">2025-10-31 00:00:00</span>
        <span class="mobile">2025-10-31 00:00</span>
    </span>
    
        <span class="article-categories article-meta-item">
            <i class="fas fa-folder"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/categories/Recommendation-Systems/">Recommendation Systems</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/LLM/">LLM</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/Recommendation-Systems/">Recommendation Systems</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/Large-Language-Models/">Large Language Models</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fas fa-file-word"></i>&nbsp;<span>16.9k 字</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fas fa-clock"></i>&nbsp;<span>73 分钟</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <p>当 ChatGPT
横空出世，大语言模型（LLM）的能力震惊了世界。从文本生成到代码编写，从问答对话到知识推理，LLM
展现出了前所未有的通用智能。那么，这样一个强大的工具能否应用到推荐系统中？答案是肯定的，而且正在发生。</p>
<p>传统的推荐系统依赖协同过滤、矩阵分解、深度学习等方法，它们擅长从用户行为数据中挖掘模式，但往往缺乏对物品语义的深度理解，也难以处理冷启动、可解释性等挑战。LLM
的出现为推荐系统带来了新的可能性：它能够理解物品的文本描述、用户的历史偏好、甚至生成自然语言的推荐理由。</p>
<p>这篇文章将深入探讨 LLM 在推荐系统中的各种应用方式：从简单的
Prompt-based
推荐，到复杂的端到端架构；从特征增强到重排序，从对话式推荐到可解释推荐。我们会看到
A-LLMRec、XRec、ChatREC、RA-Rec、ChatCRS
等前沿架构，理解它们的设计思路，并通过完整的代码实现来掌握这些技术。</p>
<span id="more"></span>
<h2 id="llm-在推荐系统中的角色定位">LLM 在推荐系统中的角色定位</h2>
<p>在深入具体架构之前，我们需要先理解 LLM
在推荐系统中可以扮演哪些角色。这决定了我们如何设计系统架构，以及如何平衡效果和效率。</p>
<h3 id="传统推荐系统的局限">传统推荐系统的局限</h3>
<p>传统的推荐系统（协同过滤、矩阵分解、深度神经网络）主要依赖用户行为数据（点击、购买、评分等）来学习用户偏好和物品特征。这种方法虽然有效，但存在几个根本性局限：</p>
<p><strong>语义理解不足</strong>：传统方法难以理解物品的文本描述、用户评论等语义信息。例如，一个电影推荐系统可能知道用户喜欢"动作片"，但无法理解"充满悬疑的动作片"和"轻松幽默的动作片"之间的区别。</p>
<p><strong>冷启动问题</strong>：新用户或新物品缺乏历史行为数据，传统方法难以做出准确推荐。虽然可以用内容特征缓解，但特征工程往往需要大量人工工作。</p>
<p><strong>可解释性差</strong>：深度学习模型是黑盒，难以解释为什么推荐某个物品。用户看到推荐结果时，往往不知道原因，降低了信任度。</p>
<p><strong>跨域迁移困难</strong>：在一个领域训练的模型很难迁移到另一个领域，因为不同领域的特征空间差异很大。</p>
<h3 id="llm-带来的新能力">LLM 带来的新能力</h3>
<p>LLM
通过预训练获得了丰富的世界知识和语言理解能力，为推荐系统带来了新的可能性：</p>
<p><strong>深度语义理解</strong>：LLM
能够理解物品的文本描述、用户评论、甚至隐含的语义信息。它可以将"悬疑动作片"和"轻松动作片"区分开来。</p>
<p><strong>零样本推理</strong>：LLM
可以在没有训练数据的情况下进行推理。对于新物品，只需要提供文本描述，LLM
就能理解其特性并做出推荐。</p>
<p><strong>自然语言生成</strong>：LLM
可以生成推荐理由，用自然语言解释为什么推荐某个物品，大大提升了可解释性。</p>
<p><strong>知识迁移</strong>：LLM
的预训练知识可以迁移到不同领域，减少了对领域特定数据的需求。</p>
<h3 id="llm-在推荐系统中的角色">LLM 在推荐系统中的角色</h3>
<p>根据 LLM 在推荐流程中的位置和作用，我们可以将其分为以下几种角色：</p>
<p><strong>1. 特征增强器（Feature Enhancer）</strong></p>
<p>LLM 用于提取或增强物品和用户的特征表示。例如： -
将物品的文本描述编码为向量 - 从用户评论中提取偏好特征 -
生成物品的语义标签</p>
<p><strong>2. 候选生成器（Candidate Generator）</strong></p>
<p>LLM 直接用于生成推荐候选。例如： - 基于用户历史，用 LLM
生成候选物品列表 - 通过对话理解用户需求，生成推荐</p>
<p><strong>3. 重排序器（Reranker）</strong></p>
<p>LLM 用于对候选物品进行精细排序。例如： -
对粗排后的候选进行语义理解和重排序 - 考虑用户意图和物品语义的匹配度</p>
<p><strong>4. 可解释性生成器（Explanation Generator）</strong></p>
<p>LLM 用于生成推荐理由。例如： - 解释为什么推荐某个物品 -
生成个性化的推荐说明</p>
<p><strong>5. 端到端推荐器（End-to-End Recommender）</strong></p>
<p>LLM 作为完整的推荐系统，从理解用户需求到生成推荐结果。</p>
<p>接下来，我们将深入探讨每种角色的具体实现方式。</p>
<h2 id="prompt-based-推荐最简单的-llm-应用">Prompt-based 推荐：最简单的
LLM 应用</h2>
<p>Prompt-based 推荐是最直观的 LLM
应用方式：将推荐任务转化为自然语言提示，让 LLM
直接生成推荐结果。虽然简单，但在某些场景下效果不错。</p>
<h3 id="基本思路">基本思路</h3>
<p>Prompt-based
推荐的核心思想是：将用户的历史行为和物品信息组织成自然语言提示，让 LLM
理解用户偏好并生成推荐。</p>
<p><strong>示例 Prompt</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">用户历史行为：</span><br><span class="line">- 看过《肖申克的救赎》（评分：5/5）</span><br><span class="line">- 看过《阿甘正传》（评分：5/5）</span><br><span class="line">- 看过《当幸福来敲门》（评分：4/5）</span><br><span class="line"></span><br><span class="line">候选电影：</span><br><span class="line">1. 《楚门的世界》- 剧情/科幻，1998年</span><br><span class="line">2. 《美丽人生》- 剧情/战争，1997年</span><br><span class="line">3. 《海上钢琴师》- 剧情/音乐，1998年</span><br><span class="line">4. 《教父》- 剧情/犯罪，1972年</span><br><span class="line">5. 《辛德勒的名单》- 剧情/历史，1993年</span><br><span class="line"></span><br><span class="line">请根据用户的历史偏好，推荐3部最可能喜欢的电影，并说明推荐理由。</span><br></pre></td></tr></table></figure>
<h3 id="实现代码">实现代码</h3>
<p>让我们实现一个完整的 Prompt-based
推荐系统。这个实现展示了如何将推荐任务转化为自然语言提示，让LLM理解用户偏好并生成推荐结果。</p>
<p><strong>Prompt-based推荐的核心设计</strong>： 1.
<strong>Prompt构建</strong>：将用户历史行为和候选物品组织成结构化的自然语言提示
2.
<strong>输出格式控制</strong>：通过明确的格式要求，确保LLM输出可解析的结构化结果
3.
<strong>错误处理</strong>：处理LLM输出可能的不一致性（如添加markdown标记）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Dict</span>, <span class="type">Tuple</span></span><br><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PromptBasedRecommender</span>:</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    基于Prompt的推荐系统</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Prompt-based推荐是最直观的LLM应用方式，核心思想是：</span></span><br><span class="line"><span class="string">    1. 将推荐任务转化为自然语言提示</span></span><br><span class="line"><span class="string">    2. 让LLM理解用户偏好并生成推荐结果</span></span><br><span class="line"><span class="string">    3. 解析LLM的输出得到结构化推荐</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    优势：</span></span><br><span class="line"><span class="string">    - 实现简单，无需训练模型</span></span><br><span class="line"><span class="string">    - 可解释性强，LLM会生成推荐理由</span></span><br><span class="line"><span class="string">    - 零样本能力，无需领域特定数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    局限：</span></span><br><span class="line"><span class="string">    - 依赖LLM的API，成本较高</span></span><br><span class="line"><span class="string">    - 延迟较大，不适合实时推荐</span></span><br><span class="line"><span class="string">    - 输出可能不稳定，需要robust的解析</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, api_key: <span class="built_in">str</span> = <span class="literal">None</span>, model: <span class="built_in">str</span> = <span class="string">"gpt-3.5-turbo"</span></span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        初始化推荐器</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            api_key: OpenAI API密钥</span></span><br><span class="line"><span class="string">                    - 如果为None，则从环境变量OPENAI_API_KEY读取</span></span><br><span class="line"><span class="string">                    - 实际应用中应该安全存储，不要硬编码</span></span><br><span class="line"><span class="string">            model: 使用的LLM模型名称</span></span><br><span class="line"><span class="string">                  - "gpt-3.5-turbo": 成本较低，速度较快</span></span><br><span class="line"><span class="string">                  - "gpt-4": 效果更好，但成本更高</span></span><br><span class="line"><span class="string">                  - 也可以使用其他LLM API（如Claude、文心一言等）</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.client = OpenAI(api_key=api_key <span class="keyword">or</span> os.getenv(<span class="string">"OPENAI_API_KEY"</span>))</span><br><span class="line">        self.model = model</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">format_user_history</span>(<span class="params">self, user_history: <span class="type">List</span>[<span class="type">Dict</span>]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        格式化用户历史行为</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        将用户的历史行为组织成易读的自然语言格式，帮助LLM理解用户偏好。</span></span><br><span class="line"><span class="string">        格式化的质量直接影响LLM对用户偏好的理解。</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_history: 用户历史行为列表</span></span><br><span class="line"><span class="string">                         - 每个元素是一个字典，包含：</span></span><br><span class="line"><span class="string">                           - item_name: 物品名称（必需）</span></span><br><span class="line"><span class="string">                           - rating: 评分（可选，如4/5）</span></span><br><span class="line"><span class="string">                           - category: 类别（可选，如"剧情/科幻"）</span></span><br><span class="line"><span class="string">                           - timestamp: 时间戳（可选）</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            格式化的历史行为字符串，例如：</span></span><br><span class="line"><span class="string">            "用户历史行为：</span></span><br><span class="line"><span class="string">             1. 《肖申克的救赎》 - 剧情（评分：5/5）</span></span><br><span class="line"><span class="string">             2. 《阿甘正传》 - 剧情（评分：5/5）</span></span><br><span class="line"><span class="string">             ..."</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        history_str = <span class="string">"用户历史行为：\n"</span></span><br><span class="line">        <span class="keyword">for</span> i, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(user_history, <span class="number">1</span>):</span><br><span class="line">            item_name = item.get(<span class="string">'item_name'</span>, <span class="string">'未知'</span>)</span><br><span class="line">            rating = item.get(<span class="string">'rating'</span>, <span class="string">'N/A'</span>)</span><br><span class="line">            category = item.get(<span class="string">'category'</span>, <span class="string">''</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 构建每个历史行为的描述</span></span><br><span class="line">            history_str += <span class="string">f"<span class="subst">{i}</span>. 《<span class="subst">{item_name}</span>》"</span></span><br><span class="line">            <span class="keyword">if</span> category:</span><br><span class="line">                history_str += <span class="string">f" - <span class="subst">{category}</span>"</span></span><br><span class="line">            <span class="keyword">if</span> rating != <span class="string">'N/A'</span>:</span><br><span class="line">                history_str += <span class="string">f"（评分：<span class="subst">{rating}</span>/5）"</span></span><br><span class="line">            history_str += <span class="string">"\n"</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> history_str</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">format_candidates</span>(<span class="params">self, candidates: <span class="type">List</span>[<span class="type">Dict</span>]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        格式化候选物品列表</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        将候选物品组织成结构化的格式，包含足够的信息让LLM做出判断。</span></span><br><span class="line"><span class="string">        信息越多，LLM的判断越准确，但也会增加token消耗。</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            candidates: 候选物品列表</span></span><br><span class="line"><span class="string">                        - 每个元素是一个字典，包含：</span></span><br><span class="line"><span class="string">                          - item_name: 物品名称（必需）</span></span><br><span class="line"><span class="string">                          - category: 类别（可选）</span></span><br><span class="line"><span class="string">                          - year: 年份（可选）</span></span><br><span class="line"><span class="string">                          - description: 描述（可选，但推荐包含）</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            格式化的候选物品字符串，例如：</span></span><br><span class="line"><span class="string">            "候选物品：</span></span><br><span class="line"><span class="string">             1. 《楚门的世界》 - 剧情/科幻，1998年</span></span><br><span class="line"><span class="string">                简介：一个关于真实与虚假的故事</span></span><br><span class="line"><span class="string">             ..."</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        candidates_str = <span class="string">"候选物品：\n"</span></span><br><span class="line">        <span class="keyword">for</span> i, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(candidates, <span class="number">1</span>):</span><br><span class="line">            item_name = item.get(<span class="string">'item_name'</span>, <span class="string">'未知'</span>)</span><br><span class="line">            category = item.get(<span class="string">'category'</span>, <span class="string">''</span>)</span><br><span class="line">            year = item.get(<span class="string">'year'</span>, <span class="string">''</span>)</span><br><span class="line">            description = item.get(<span class="string">'description'</span>, <span class="string">''</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 构建每个候选物品的描述</span></span><br><span class="line">            candidates_str += <span class="string">f"<span class="subst">{i}</span>. 《<span class="subst">{item_name}</span>》"</span></span><br><span class="line">            <span class="keyword">if</span> category:</span><br><span class="line">                candidates_str += <span class="string">f" - <span class="subst">{category}</span>"</span></span><br><span class="line">            <span class="keyword">if</span> year:</span><br><span class="line">                candidates_str += <span class="string">f"，<span class="subst">{year}</span>年"</span></span><br><span class="line">            <span class="keyword">if</span> description:</span><br><span class="line">                candidates_str += <span class="string">f"\n   简介：<span class="subst">{description}</span>"</span></span><br><span class="line">            candidates_str += <span class="string">"\n"</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> candidates_str</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">build_prompt</span>(<span class="params">self, user_history: <span class="type">List</span>[<span class="type">Dict</span>], </span></span><br><span class="line"><span class="params">                    candidates: <span class="type">List</span>[<span class="type">Dict</span>], </span></span><br><span class="line"><span class="params">                    top_k: <span class="built_in">int</span> = <span class="number">3</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        构建推荐Prompt</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Prompt的质量直接影响推荐效果。好的Prompt应该：</span></span><br><span class="line"><span class="string">        1. 清晰明确：告诉LLM要做什么</span></span><br><span class="line"><span class="string">        2. 结构完整：包含所有必要信息（用户历史、候选物品）</span></span><br><span class="line"><span class="string">        3. 格式规范：明确要求输出格式，便于解析</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_history: 用户历史行为列表</span></span><br><span class="line"><span class="string">            candidates: 候选物品列表</span></span><br><span class="line"><span class="string">            top_k: 推荐数量，通常设置为3-10</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            完整的Prompt字符串，包含：</span></span><br><span class="line"><span class="string">            - 任务描述：告诉LLM要做什么</span></span><br><span class="line"><span class="string">            - 用户历史：帮助LLM理解用户偏好</span></span><br><span class="line"><span class="string">            - 候选物品：LLM从中选择推荐</span></span><br><span class="line"><span class="string">            - 输出格式：确保LLM输出可解析的结构化结果</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 格式化用户历史和候选物品</span></span><br><span class="line">        history_str = self.format_user_history(user_history)</span><br><span class="line">        candidates_str = self.format_candidates(candidates)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 构建完整的Prompt</span></span><br><span class="line">        <span class="comment"># 关键设计点：</span></span><br><span class="line">        <span class="comment"># 1. 明确任务：告诉LLM要推荐top_k个物品</span></span><br><span class="line">        <span class="comment"># 2. 提供上下文：用户历史和候选物品</span></span><br><span class="line">        <span class="comment"># 3. 规范输出：要求JSON格式，便于解析</span></span><br><span class="line">        <span class="comment"># 4. 强调格式：只输出JSON，避免额外文本</span></span><br><span class="line">        prompt = <span class="string">f"""你是一个专业的电影推荐系统。请根据用户的历史观影偏好，从候选电影中推荐最合适的<span class="subst">{top_k}</span>部电影。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"><span class="subst">{history_str}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"><span class="subst">{candidates_str}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">请按照以下格式输出推荐结果（JSON格式）：</span></span><br><span class="line"><span class="string">{{</span></span><br><span class="line"><span class="string">    "recommendations": [</span></span><br><span class="line"><span class="string">        {{</span></span><br><span class="line"><span class="string">            "item_name": "电影名称",</span></span><br><span class="line"><span class="string">            "rank": 1,</span></span><br><span class="line"><span class="string">            "reason": "推荐理由"</span></span><br><span class="line"><span class="string">        }}</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">}}</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">只输出JSON，不要输出其他内容。"""</span></span><br><span class="line">        <span class="keyword">return</span> prompt</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">recommend</span>(<span class="params">self, user_history: <span class="type">List</span>[<span class="type">Dict</span>], </span></span><br><span class="line"><span class="params">                  candidates: <span class="type">List</span>[<span class="type">Dict</span>], </span></span><br><span class="line"><span class="params">                  top_k: <span class="built_in">int</span> = <span class="number">3</span></span>) -&gt; <span class="type">List</span>[<span class="type">Dict</span>]:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        生成推荐</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        这是Prompt-based推荐的核心方法，流程：</span></span><br><span class="line"><span class="string">        1. 构建Prompt：将用户历史和候选物品组织成Prompt</span></span><br><span class="line"><span class="string">        2. 调用LLM：发送Prompt到LLM API</span></span><br><span class="line"><span class="string">        3. 解析输出：将LLM的输出解析为结构化推荐结果</span></span><br><span class="line"><span class="string">        4. 错误处理：处理LLM输出可能的不一致性</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_history: 用户历史行为列表</span></span><br><span class="line"><span class="string">            candidates: 候选物品列表</span></span><br><span class="line"><span class="string">            top_k: 推荐数量</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            推荐结果列表，每个元素包含：</span></span><br><span class="line"><span class="string">            - item_name: 推荐的物品名称</span></span><br><span class="line"><span class="string">            - rank: 推荐排名（1表示最推荐）</span></span><br><span class="line"><span class="string">            - reason: 推荐理由（LLM生成的自然语言解释）</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 第一步：构建Prompt</span></span><br><span class="line">        prompt = self.build_prompt(user_history, candidates, top_k)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 第二步：调用LLM API</span></span><br><span class="line">            <span class="comment"># 关键参数：</span></span><br><span class="line">            <span class="comment"># - temperature: 控制输出的随机性</span></span><br><span class="line">            <span class="comment">#   * 0.3: 较低随机性，输出更一致（推荐用于推荐任务）</span></span><br><span class="line">            <span class="comment">#   * 0.7-1.0: 较高随机性，输出更多样（适合创意任务）</span></span><br><span class="line">            <span class="comment"># - max_tokens: 限制输出长度，控制成本</span></span><br><span class="line">            response = self.client.chat.completions.create(</span><br><span class="line">                model=self.model,</span><br><span class="line">                messages=[</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"system"</span>, <span class="string">"content"</span>: <span class="string">"你是一个专业的推荐系统助手。"</span>},</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: prompt}</span><br><span class="line">                ],</span><br><span class="line">                temperature=<span class="number">0.3</span>,  <span class="comment"># 降低随机性，提高一致性</span></span><br><span class="line">                max_tokens=<span class="number">1000</span>   <span class="comment"># 限制输出长度，控制API成本</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 第三步：提取LLM的输出</span></span><br><span class="line">            content = response.choices[<span class="number">0</span>].message.content.strip()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 第四步：解析JSON输出</span></span><br><span class="line">            <span class="comment"># LLM有时会在JSON前后添加markdown标记（如```json），需要清理</span></span><br><span class="line">            <span class="keyword">if</span> content.startswith(<span class="string">"```json"</span>):</span><br><span class="line">                content = content[<span class="number">7</span>:]  <span class="comment"># 移除```json标记</span></span><br><span class="line">            <span class="keyword">if</span> content.startswith(<span class="string">"```"</span>):</span><br><span class="line">                content = content[<span class="number">3</span>:]   <span class="comment"># 移除```标记</span></span><br><span class="line">            <span class="keyword">if</span> content.endswith(<span class="string">"```"</span>):</span><br><span class="line">                content = content[:-<span class="number">3</span>]   <span class="comment"># 移除结尾的```标记</span></span><br><span class="line">            content = content.strip()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 解析JSON</span></span><br><span class="line">            result = json.loads(content)</span><br><span class="line">            <span class="keyword">return</span> result.get(<span class="string">"recommendations"</span>, [])</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span> json.JSONDecodeError <span class="keyword">as</span> e:</span><br><span class="line">            <span class="comment"># JSON解析错误：LLM可能没有按照要求的格式输出</span></span><br><span class="line">            <span class="comment"># 实际应用中应该：</span></span><br><span class="line">            <span class="comment"># 1. 记录错误日志</span></span><br><span class="line">            <span class="comment"># 2. 尝试更robust的解析（如正则表达式）</span></span><br><span class="line">            <span class="comment"># 3. 返回默认推荐或重试</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"JSON 解析错误: <span class="subst">{e}</span>"</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"LLM 输出: <span class="subst">{content}</span>"</span>)</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="comment"># 其他错误：API调用失败、网络错误等</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"推荐生成错误: <span class="subst">{e}</span>"</span>)</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">recommend_with_explanation</span>(<span class="params">self, user_history: <span class="type">List</span>[<span class="type">Dict</span>], </span></span><br><span class="line"><span class="params">                                   candidates: <span class="type">List</span>[<span class="type">Dict</span>], </span></span><br><span class="line"><span class="params">                                   top_k: <span class="built_in">int</span> = <span class="number">3</span></span>) -&gt; <span class="type">Dict</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        生成带解释的推荐</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            包含推荐列表和整体解释的字典</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        prompt = self.build_prompt(user_history, candidates, top_k)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 添加生成整体解释的要求</span></span><br><span class="line">        prompt += <span class="string">"\n\n另外，请用一段话总结用户的观影偏好特点。"</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = self.client.chat.completions.create(</span><br><span class="line">                model=self.model,</span><br><span class="line">                messages=[</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"system"</span>, <span class="string">"content"</span>: <span class="string">"你是一个专业的推荐系统助手。"</span>},</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: prompt}</span><br><span class="line">                ],</span><br><span class="line">                temperature=<span class="number">0.3</span>,</span><br><span class="line">                max_tokens=<span class="number">1500</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            content = response.choices[<span class="number">0</span>].message.content.strip()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 解析结果</span></span><br><span class="line">            <span class="comment"># 这里简化处理，实际应用中需要更robust的解析</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">"{"</span> <span class="keyword">in</span> content <span class="keyword">and</span> <span class="string">"}"</span> <span class="keyword">in</span> content:</span><br><span class="line">                json_start = content.find(<span class="string">"{"</span>)</span><br><span class="line">                json_end = content.rfind(<span class="string">"}"</span>) + <span class="number">1</span></span><br><span class="line">                json_str = content[json_start:json_end]</span><br><span class="line">                </span><br><span class="line">                result = json.loads(json_str)</span><br><span class="line">                recommendations = result.get(<span class="string">"recommendations"</span>, [])</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 提取整体解释（JSON之后的内容）</span></span><br><span class="line">                explanation = content[json_end:].strip()</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> explanation:</span><br><span class="line">                    explanation = <span class="string">"基于您的观影历史，为您推荐了以上电影。"</span></span><br><span class="line">                </span><br><span class="line">                <span class="keyword">return</span> {</span><br><span class="line">                    <span class="string">"recommendations"</span>: recommendations,</span><br><span class="line">                    <span class="string">"user_preference_summary"</span>: explanation</span><br><span class="line">                }</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">return</span> {<span class="string">"recommendations"</span>: [], <span class="string">"user_preference_summary"</span>: <span class="string">""</span>}</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"推荐生成错误: <span class="subst">{e}</span>"</span>)</span><br><span class="line">            <span class="keyword">return</span> {<span class="string">"recommendations"</span>: [], <span class="string">"user_preference_summary"</span>: <span class="string">""</span>}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用示例</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># 初始化推荐器</span></span><br><span class="line">    recommender = PromptBasedRecommender()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 用户历史</span></span><br><span class="line">    user_history = [</span><br><span class="line">        {<span class="string">"item_name"</span>: <span class="string">"肖申克的救赎"</span>, <span class="string">"rating"</span>: <span class="number">5</span>, <span class="string">"category"</span>: <span class="string">"剧情/犯罪"</span>},</span><br><span class="line">        {<span class="string">"item_name"</span>: <span class="string">"阿甘正传"</span>, <span class="string">"rating"</span>: <span class="number">5</span>, <span class="string">"category"</span>: <span class="string">"剧情/爱情"</span>},</span><br><span class="line">        {<span class="string">"item_name"</span>: <span class="string">"当幸福来敲门"</span>, <span class="string">"rating"</span>: <span class="number">4</span>, <span class="string">"category"</span>: <span class="string">"剧情/传记"</span>}</span><br><span class="line">    ]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 候选电影</span></span><br><span class="line">    candidates = [</span><br><span class="line">        {</span><br><span class="line">            <span class="string">"item_name"</span>: <span class="string">"楚门的世界"</span>,</span><br><span class="line">            <span class="string">"category"</span>: <span class="string">"剧情/科幻"</span>,</span><br><span class="line">            <span class="string">"year"</span>: <span class="number">1998</span>,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"一个关于真实与虚假、自由与控制的深刻寓言"</span></span><br><span class="line">        },</span><br><span class="line">        {</span><br><span class="line">            <span class="string">"item_name"</span>: <span class="string">"美丽人生"</span>,</span><br><span class="line">            <span class="string">"category"</span>: <span class="string">"剧情/战争"</span>,</span><br><span class="line">            <span class="string">"year"</span>: <span class="number">1997</span>,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"在集中营中用父爱和幽默保护孩子的感人故事"</span></span><br><span class="line">        },</span><br><span class="line">        {</span><br><span class="line">            <span class="string">"item_name"</span>: <span class="string">"海上钢琴师"</span>,</span><br><span class="line">            <span class="string">"category"</span>: <span class="string">"剧情/音乐"</span>,</span><br><span class="line">            <span class="string">"year"</span>: <span class="number">1998</span>,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"一个天才钢琴师的一生，关于选择与坚持"</span></span><br><span class="line">        },</span><br><span class="line">        {</span><br><span class="line">            <span class="string">"item_name"</span>: <span class="string">"教父"</span>,</span><br><span class="line">            <span class="string">"category"</span>: <span class="string">"剧情/犯罪"</span>,</span><br><span class="line">            <span class="string">"year"</span>: <span class="number">1972</span>,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"黑帮家族的史诗，关于权力、家族和人性"</span></span><br><span class="line">        },</span><br><span class="line">        {</span><br><span class="line">            <span class="string">"item_name"</span>: <span class="string">"辛德勒的名单"</span>,</span><br><span class="line">            <span class="string">"category"</span>: <span class="string">"剧情/历史"</span>,</span><br><span class="line">            <span class="string">"year"</span>: <span class="number">1993</span>,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"二战期间拯救犹太人的真实故事"</span></span><br><span class="line">        }</span><br><span class="line">    ]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 生成推荐</span></span><br><span class="line">    recommendations = recommender.recommend(user_history, candidates, top_k=<span class="number">3</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"推荐结果："</span>)</span><br><span class="line">    <span class="keyword">for</span> rec <span class="keyword">in</span> recommendations:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"\n排名 <span class="subst">{rec[<span class="string">'rank'</span>]}</span>: 《<span class="subst">{rec[<span class="string">'item_name'</span>]}</span>》"</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"推荐理由：<span class="subst">{rec[<span class="string">'reason'</span>]}</span>"</span>)</span><br></pre></td></tr></table></figure>
<h3 id="prompt-工程技巧">Prompt 工程技巧</h3>
<p>要让 Prompt-based 推荐效果更好，需要注意以下几点：</p>
<p><strong>1. 结构化输入</strong></p>
<p>将用户历史和候选物品组织成清晰的结构，使用编号、分类等让 LLM
更容易理解。</p>
<p><strong>2. 明确输出格式</strong></p>
<p>指定 JSON 格式输出，便于后续解析。可以使用 few-shot examples 来引导
LLM 输出正确格式。</p>
<p><strong>3. 控制温度参数</strong></p>
<p>推荐任务需要一致性，应该使用较低的温度（0.1-0.3），而不是创意生成任务的高温度（0.7-1.0）。</p>
<p><strong>4. 添加约束条件</strong></p>
<p>在 Prompt
中明确约束，例如"不要推荐用户已经看过的电影"、"优先推荐评分高的电影"等。</p>
<p><strong>5. 处理长上下文</strong></p>
<p>如果用户历史很长，需要截断或摘要。可以使用 LLM
先对历史进行摘要，再用于推荐。</p>
<h3 id="优缺点分析">优缺点分析</h3>
<p><strong>优点</strong>： - 实现简单，无需训练模型 - 可解释性强，LLM
会生成推荐理由 - 零样本能力，对新领域也能工作 -
自然语言交互，用户体验好</p>
<p><strong>缺点</strong>： - 延迟高，每次推荐都需要调用 LLM API -
成本高，Token 消耗大 - 不稳定，可能生成格式错误的结果 -
难以处理大规模候选集</p>
<p>Prompt-based
推荐适合小规模、对延迟不敏感的场景，或者作为其他方法的补充。接下来，我们将看到更高效的架构设计。</p>
<h2 id="a-llmrec适配器增强的-llm-推荐架构">A-LLMRec：适配器增强的 LLM
推荐架构</h2>
<p>A-LLMRec（Adapter-enhanced LLM for Recommendation）是一种将 LLM
与传统推荐模型结合的架构。核心思想是：使用轻量级的适配器（Adapter）来微调
LLM，使其适应推荐任务，而不是直接使用预训练的 LLM。</p>
<h3 id="架构设计">架构设计</h3>
<p>A-LLMRec 的架构包含以下几个组件：</p>
<ol type="1">
<li><strong>LLM 编码器</strong>：使用预训练的 LLM（如
BERT、GPT）来编码物品文本和用户历史</li>
<li><strong>适配器层</strong>：在 LLM
的每一层插入轻量级的适配器，用于任务特定的微调</li>
<li><strong>推荐头</strong>：将 LLM 的输出映射到推荐分数</li>
</ol>
<h3 id="适配器机制">适配器机制</h3>
<p>适配器是一种参数高效的微调方法。在 Transformer
的每一层中，适配器插入在注意力层和前馈层之后：</p>
<p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.65ex;" xmlns="http://www.w3.org/2000/svg" width="39.929ex" height="2.347ex" role="img" focusable="false" viewbox="0 -750 17648.7 1037.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="41" d="M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z"/><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(750,0)"/><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1306,0)"/><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" transform="translate(1806,0)"/><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(2362,0)"/><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(2751,0)"/><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(3195,0)"/></g><g data-mml-node="mo" transform="translate(3587,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mi" transform="translate(3976,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mo" transform="translate(4548,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g><g data-mml-node="mo" transform="translate(5214.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="mi" transform="translate(6270.6,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mo" transform="translate(7064.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"/></g><g data-mml-node="mtext" transform="translate(8065,0)"><path data-c="44" d="M130 622Q123 629 119 631T103 634T60 637H27V683H228Q399 682 419 682T461 676Q504 667 546 641T626 573T685 470T708 336Q708 210 634 116T442 3Q429 1 228 0H27V46H60Q102 47 111 49T130 61V622ZM593 338Q593 439 571 501T493 602Q439 637 355 637H322H294Q238 637 234 628Q231 624 231 344Q231 62 232 59Q233 49 248 48T339 46H350Q456 46 515 95Q561 133 577 191T593 338Z"/><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(764,0)"/><path data-c="77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z" transform="translate(1264,0)"/><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1986,0)"/><path data-c="50" d="M130 622Q123 629 119 631T103 634T60 637H27V683H214Q237 683 276 683T331 684Q419 684 471 671T567 616Q624 563 624 489Q624 421 573 372T451 307Q429 302 328 301H234V181Q234 62 237 58Q245 47 304 46H337V0H326Q305 3 182 3Q47 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM507 488Q507 514 506 528T500 564T483 597T450 620T397 635Q385 637 307 637H286Q237 637 234 628Q231 624 231 483V342H302H339Q390 342 423 349T481 382Q507 411 507 488Z" transform="translate(2542,0)"/><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(3223,0)"/><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(3615,0)"/><path data-c="6A" d="M98 609Q98 637 116 653T160 669Q183 667 200 652T217 609Q217 579 200 564T158 549Q133 549 116 564T98 609ZM28 -163Q58 -168 64 -168Q124 -168 135 -77Q137 -65 137 141T136 353Q132 371 120 377T72 385H52V408Q52 431 54 431L58 432Q62 432 70 432T87 433T108 434T133 436Q151 437 171 438T202 441T214 442H218V184Q217 -36 217 -59T211 -98Q195 -145 153 -175T58 -205Q9 -205 -23 -179T-55 -117Q-55 -94 -40 -79T-2 -64T36 -79T52 -118Q52 -143 28 -163Z" transform="translate(4115,0)"/><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(4421,0)"/><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(4865,0)"/><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(5309,0)"/></g><g data-mml-node="mo" transform="translate(13763,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mi" transform="translate(14152,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mo" transform="translate(14724,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g><g data-mml-node="mo" transform="translate(15335.2,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"/></g><g data-mml-node="msub" transform="translate(15835.4,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"/></g><g data-mml-node="TeXAtom" transform="translate(977,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z"/><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" transform="translate(556,0)"/></g></g></g></g></g></svg></mjx-container></span></p>
<p>其中： - <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="35.49ex" height="2.262ex" role="img" focusable="false" viewbox="0 -750 15686.4 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="44" d="M130 622Q123 629 119 631T103 634T60 637H27V683H228Q399 682 419 682T461 676Q504 667 546 641T626 573T685 470T708 336Q708 210 634 116T442 3Q429 1 228 0H27V46H60Q102 47 111 49T130 61V622ZM593 338Q593 439 571 501T493 602Q439 637 355 637H322H294Q238 637 234 628Q231 624 231 344Q231 62 232 59Q233 49 248 48T339 46H350Q456 46 515 95Q561 133 577 191T593 338Z"/><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(764,0)"/><path data-c="77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z" transform="translate(1264,0)"/><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1986,0)"/><path data-c="50" d="M130 622Q123 629 119 631T103 634T60 637H27V683H214Q237 683 276 683T331 684Q419 684 471 671T567 616Q624 563 624 489Q624 421 573 372T451 307Q429 302 328 301H234V181Q234 62 237 58Q245 47 304 46H337V0H326Q305 3 182 3Q47 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM507 488Q507 514 506 528T500 564T483 597T450 620T397 635Q385 637 307 637H286Q237 637 234 628Q231 624 231 483V342H302H339Q390 342 423 349T481 382Q507 411 507 488Z" transform="translate(2542,0)"/><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(3223,0)"/><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(3615,0)"/><path data-c="6A" d="M98 609Q98 637 116 653T160 669Q183 667 200 652T217 609Q217 579 200 564T158 549Q133 549 116 564T98 609ZM28 -163Q58 -168 64 -168Q124 -168 135 -77Q137 -65 137 141T136 353Q132 371 120 377T72 385H52V408Q52 431 54 431L58 432Q62 432 70 432T87 433T108 434T133 436Q151 437 171 438T202 441T214 442H218V184Q217 -36 217 -59T211 -98Q195 -145 153 -175T58 -205Q9 -205 -23 -179T-55 -117Q-55 -94 -40 -79T-2 -64T36 -79T52 -118Q52 -143 28 -163Z" transform="translate(4115,0)"/><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(4421,0)"/><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(4865,0)"/><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(5309,0)"/></g><g data-mml-node="mo" transform="translate(5698,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mi" transform="translate(6087,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mo" transform="translate(6659,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g><g data-mml-node="mo" transform="translate(7325.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="mtext" transform="translate(8381.6,0)"><path data-c="52" d="M130 622Q123 629 119 631T103 634T60 637H27V683H202H236H300Q376 683 417 677T500 648Q595 600 609 517Q610 512 610 501Q610 468 594 439T556 392T511 361T472 343L456 338Q459 335 467 332Q497 316 516 298T545 254T559 211T568 155T578 94Q588 46 602 31T640 16H645Q660 16 674 32T692 87Q692 98 696 101T712 105T728 103T732 90Q732 59 716 27T672 -16Q656 -22 630 -22Q481 -16 458 90Q456 101 456 163T449 246Q430 304 373 320L363 322L297 323H231V192L232 61Q238 51 249 49T301 46H334V0H323Q302 3 181 3Q59 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM491 499V509Q491 527 490 539T481 570T462 601T424 623T362 636Q360 636 340 636T304 637H283Q238 637 234 628Q231 624 231 492V360H289Q390 360 434 378T489 456Q491 467 491 499Z"/><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(736,0)"/><path data-c="4C" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q48 680 182 680Q324 680 348 683H360V637H333Q273 637 258 635T233 622L232 342V129Q232 57 237 52Q243 47 313 47Q384 47 410 53Q470 70 498 110T536 221Q536 226 537 238T540 261T542 272T562 273H582V268Q580 265 568 137T554 5V0H25V46H58Q100 47 109 49T128 61V622Z" transform="translate(1180,0)"/><path data-c="55" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q57 680 180 680Q315 680 324 683H335V637H302Q262 636 251 634T233 622L232 418V291Q232 189 240 145T280 67Q325 24 389 24Q454 24 506 64T571 183Q575 206 575 410V598Q569 608 565 613T541 627T489 637H472V683H481Q496 680 598 680T715 683H724V637H707Q634 633 622 598L621 399Q620 194 617 180Q617 179 615 171Q595 83 531 31T389 -22Q304 -22 226 33T130 192Q129 201 128 412V622Z" transform="translate(1805,0)"/></g><g data-mml-node="mo" transform="translate(10936.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mi" transform="translate(11325.6,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mo" transform="translate(12119.8,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"/></g><g data-mml-node="msub" transform="translate(12620,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"/></g><g data-mml-node="TeXAtom" transform="translate(977,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z"/><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(556,0)"/><path data-c="77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z" transform="translate(1056,0)"/><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1778,0)"/></g></g></g><g data-mml-node="mo" transform="translate(15297.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g></g></g></svg></mjx-container></span> 是降维投影 - <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="13.443ex" height="2.288ex" role="img" focusable="false" viewbox="0 -853.7 5941.7 1011.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"/></g><g data-mml-node="TeXAtom" transform="translate(977,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z"/><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(556,0)"/><path data-c="77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z" transform="translate(1056,0)"/><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1778,0)"/></g></g></g><g data-mml-node="mo" transform="translate(2955.2,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"/></g><g data-mml-node="msup" transform="translate(3899.9,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="211D" d="M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z"/></g></g><g data-mml-node="TeXAtom" transform="translate(755,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></g><g data-mml-node="mo" transform="translate(520,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"/></g><g data-mml-node="mi" transform="translate(1298,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g></g></g></g></g></svg></mjx-container></span>，<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.65ex;" xmlns="http://www.w3.org/2000/svg" width="11.488ex" height="2.581ex" role="img" focusable="false" viewbox="0 -853.7 5077.6 1140.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"/></g><g data-mml-node="TeXAtom" transform="translate(977,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z"/><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" transform="translate(556,0)"/></g></g></g><g data-mml-node="mo" transform="translate(2091.1,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"/></g><g data-mml-node="msup" transform="translate(3035.9,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="211D" d="M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z"/></g></g><g data-mml-node="TeXAtom" transform="translate(755,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mo" transform="translate(451,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"/></g><g data-mml-node="mi" transform="translate(1229,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></g></g></g></g></g></svg></mjx-container></span>，<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.152ex;" xmlns="http://www.w3.org/2000/svg" width="5.716ex" height="1.722ex" role="img" focusable="false" viewbox="0 -694 2526.6 761"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mo" transform="translate(728.8,0)"><path data-c="226A" d="M639 -48Q639 -54 634 -60T619 -67H618Q612 -67 536 -26Q430 33 329 88Q61 235 59 239Q56 243 56 250T59 261Q62 266 336 415T615 567L619 568Q622 567 625 567Q639 562 639 548Q639 540 633 534Q632 532 374 391L117 250L374 109Q632 -32 633 -34Q639 -40 639 -48ZM944 -48Q944 -54 939 -60T924 -67H923Q917 -67 841 -26Q735 33 634 88Q366 235 364 239Q361 243 361 250T364 261Q367 266 641 415T920 567L924 568Q927 567 930 567Q944 562 944 548Q944 540 938 534Q937 532 679 391L422 250L679 109Q937 -32 938 -34Q944 -40 944 -48Z"/></g><g data-mml-node="mi" transform="translate(2006.6,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></g></g></g></svg></mjx-container></span>
是瓶颈维度</p>
<p>这样，只需要训练 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="8.859ex" height="1.595ex" role="img" focusable="false" viewbox="0 -694 3915.9 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"/></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"/></g><g data-mml-node="mi" transform="translate(1722.4,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/></g><g data-mml-node="mo" transform="translate(2464.7,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"/></g><g data-mml-node="mi" transform="translate(3464.9,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g></g></g></svg></mjx-container></span> 个参数（每个适配器），而不是整个 LLM 的参数。</p>
<h3 id="完整实现">完整实现</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModel, AutoTokenizer</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Dict</span>, <span class="type">Optional</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AdapterLayer</span>(nn.Module):</span><br><span class="line">    <span class="string">"""适配器层"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, hidden_size: <span class="built_in">int</span>, adapter_size: <span class="built_in">int</span> = <span class="number">64</span></span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            hidden_size: LLM 的隐藏层维度</span></span><br><span class="line"><span class="string">            adapter_size: 适配器的瓶颈维度</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.adapter_size = adapter_size</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 降维投影</span></span><br><span class="line">        self.down_proj = nn.Linear(hidden_size, adapter_size)</span><br><span class="line">        <span class="comment"># 上维投影</span></span><br><span class="line">        self.up_proj = nn.Linear(adapter_size, hidden_size)</span><br><span class="line">        <span class="comment"># 激活函数</span></span><br><span class="line">        self.activation = nn.ReLU()</span><br><span class="line">        <span class="comment"># Layer norm</span></span><br><span class="line">        self.layer_norm = nn.LayerNorm(hidden_size)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: 输入张量，形状为 (batch_size, seq_len, hidden_size)</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            适配器输出</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        residual = x</span><br><span class="line">        x = self.layer_norm(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 适配器前向传播</span></span><br><span class="line">        down = self.down_proj(x)</span><br><span class="line">        down = self.activation(down)</span><br><span class="line">        up = self.up_proj(down)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 残差连接</span></span><br><span class="line">        output = residual + up</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ALLMRec</span>(nn.Module):</span><br><span class="line">    <span class="string">"""A-LLMRec 模型"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        model_name: <span class="built_in">str</span> = <span class="string">"bert-base-chinese"</span>,</span></span><br><span class="line"><span class="params">        adapter_size: <span class="built_in">int</span> = <span class="number">64</span>,</span></span><br><span class="line"><span class="params">        num_items: <span class="built_in">int</span> = <span class="number">10000</span>,</span></span><br><span class="line"><span class="params">        embedding_dim: <span class="built_in">int</span> = <span class="number">128</span>,</span></span><br><span class="line"><span class="params">        max_history_length: <span class="built_in">int</span> = <span class="number">50</span></span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            model_name: 预训练 LLM 模型名称</span></span><br><span class="line"><span class="string">            adapter_size: 适配器瓶颈维度</span></span><br><span class="line"><span class="string">            num_items: 物品数量</span></span><br><span class="line"><span class="string">            embedding_dim: 物品嵌入维度</span></span><br><span class="line"><span class="string">            max_history_length: 最大历史长度</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># LLM 编码器</span></span><br><span class="line">        self.llm = AutoModel.from_pretrained(model_name)</span><br><span class="line">        self.tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br><span class="line">        self.hidden_size = self.llm.config.hidden_size</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 在每一层插入适配器</span></span><br><span class="line">        self.adapters = nn.ModuleList()</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.llm.config.num_hidden_layers):</span><br><span class="line">            self.adapters.append(AdapterLayer(self.hidden_size, adapter_size))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 物品嵌入层（用于物品 ID）</span></span><br><span class="line">        self.item_embedding = nn.Embedding(num_items, embedding_dim)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 历史编码器（将历史物品序列编码）</span></span><br><span class="line">        self.history_encoder = nn.LSTM(</span><br><span class="line">            embedding_dim, </span><br><span class="line">            self.hidden_size // <span class="number">2</span>, </span><br><span class="line">            batch_first=<span class="literal">True</span>,</span><br><span class="line">            bidirectional=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 推荐头</span></span><br><span class="line">        self.recommendation_head = nn.Sequential(</span><br><span class="line">            nn.Linear(self.hidden_size * <span class="number">2</span>, self.hidden_size),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.1</span>),</span><br><span class="line">            nn.Linear(self.hidden_size, <span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.max_history_length = max_history_length</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode_text</span>(<span class="params">self, texts: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        使用 LLM + 适配器编码文本</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            texts: 文本列表</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            文本表示，形状为 (batch_size, hidden_size)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># Tokenize</span></span><br><span class="line">        encoded = self.tokenizer(</span><br><span class="line">            texts,</span><br><span class="line">            padding=<span class="literal">True</span>,</span><br><span class="line">            truncation=<span class="literal">True</span>,</span><br><span class="line">            max_length=<span class="number">512</span>,</span><br><span class="line">            return_tensors=<span class="string">"pt"</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 移动到设备</span></span><br><span class="line">        device = <span class="built_in">next</span>(self.llm.parameters()).device</span><br><span class="line">        encoded = {k: v.to(device) <span class="keyword">for</span> k, v <span class="keyword">in</span> encoded.items()}</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># LLM 编码</span></span><br><span class="line">        outputs = self.llm(**encoded)</span><br><span class="line">        hidden_states = outputs.last_hidden_state  <span class="comment"># (batch_size, seq_len, hidden_size)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 通过适配器</span></span><br><span class="line">        <span class="keyword">for</span> adapter <span class="keyword">in</span> self.adapters:</span><br><span class="line">            hidden_states = adapter(hidden_states)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 取 [CLS] token 的表示</span></span><br><span class="line">        cls_representation = hidden_states[:, <span class="number">0</span>, :]  <span class="comment"># (batch_size, hidden_size)</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> cls_representation</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode_history</span>(<span class="params">self, item_ids: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        编码用户历史</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            item_ids: 物品 ID 序列，形状为 (batch_size, history_length)</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            历史表示，形状为 (batch_size, hidden_size)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 获取物品嵌入</span></span><br><span class="line">        item_embeds = self.item_embedding(item_ids)  <span class="comment"># (batch_size, seq_len, embedding_dim)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># LSTM 编码</span></span><br><span class="line">        lstm_out, (h_n, c_n) = self.history_encoder(item_embeds)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 使用最后时刻的隐藏状态</span></span><br><span class="line">        <span class="comment"># 双向 LSTM，拼接前向和后向的隐藏状态</span></span><br><span class="line">        history_repr = torch.cat([h_n[<span class="number">0</span>], h_n[<span class="number">1</span>]], dim=<span class="number">1</span>)  <span class="comment"># (batch_size, hidden_size)</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> history_repr</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        item_texts: <span class="type">List</span>[<span class="built_in">str</span>],</span></span><br><span class="line"><span class="params">        user_history_ids: torch.Tensor,</span></span><br><span class="line"><span class="params">        candidate_ids: <span class="type">Optional</span>[torch.Tensor] = <span class="literal">None</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        前向传播</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            item_texts: 候选物品的文本描述列表</span></span><br><span class="line"><span class="string">            user_history_ids: 用户历史物品 ID，形状为 (batch_size, history_length)</span></span><br><span class="line"><span class="string">            candidate_ids: 候选物品 ID（可选）</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            推荐分数，形状为 (batch_size, 1)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 编码物品文本</span></span><br><span class="line">        item_repr = self.encode_text(item_texts)  <span class="comment"># (batch_size, hidden_size)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 编码用户历史</span></span><br><span class="line">        history_repr = self.encode_history(user_history_ids)  <span class="comment"># (batch_size, hidden_size)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 拼接物品表示和历史表示</span></span><br><span class="line">        combined = torch.cat([item_repr, history_repr], dim=<span class="number">1</span>)  <span class="comment"># (batch_size, hidden_size * 2)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 推荐头</span></span><br><span class="line">        score = self.recommendation_head(combined)  <span class="comment"># (batch_size, 1)</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> score</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, item_text: <span class="built_in">str</span>, user_history_ids: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        预测用户对物品的评分</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            item_text: 物品文本描述</span></span><br><span class="line"><span class="string">            user_history_ids: 用户历史物品 ID 列表</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            预测分数</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.<span class="built_in">eval</span>()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 准备输入</span></span><br><span class="line">        item_texts = [item_text]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 填充历史</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(user_history_ids) &gt; self.max_history_length:</span><br><span class="line">            user_history_ids = user_history_ids[-self.max_history_length:]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            user_history_ids = user_history_ids + [<span class="number">0</span>] * (self.max_history_length - <span class="built_in">len</span>(user_history_ids))</span><br><span class="line">        </span><br><span class="line">        history_tensor = torch.tensor([user_history_ids], dtype=torch.long)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 移动到设备</span></span><br><span class="line">        device = <span class="built_in">next</span>(self.parameters()).device</span><br><span class="line">        history_tensor = history_tensor.to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            score = self.forward(item_texts, history_tensor)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> score.item()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练示例</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_allmrec</span>():</span><br><span class="line">    <span class="string">"""训练 A-LLMRec 模型"""</span></span><br><span class="line">    <span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">RecommendationDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data: <span class="type">List</span>[<span class="type">Dict</span>]</span>):</span><br><span class="line">            self.data = data</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">            <span class="keyword">return</span> self.data[idx]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 初始化模型</span></span><br><span class="line">    model = ALLMRec(</span><br><span class="line">        model_name=<span class="string">"bert-base-chinese"</span>,</span><br><span class="line">        adapter_size=<span class="number">64</span>,</span><br><span class="line">        num_items=<span class="number">10000</span>,</span><br><span class="line">        max_history_length=<span class="number">50</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 优化器（只优化适配器和推荐头的参数）</span></span><br><span class="line">    trainable_params = []</span><br><span class="line">    trainable_params.extend(model.adapters.parameters())</span><br><span class="line">    trainable_params.extend(model.item_embedding.parameters())</span><br><span class="line">    trainable_params.extend(model.history_encoder.parameters())</span><br><span class="line">    trainable_params.extend(model.recommendation_head.parameters())</span><br><span class="line">    </span><br><span class="line">    optimizer = torch.optim.Adam(trainable_params, lr=<span class="number">1e-4</span>)</span><br><span class="line">    criterion = nn.MSELoss()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 示例数据</span></span><br><span class="line">    train_data = [</span><br><span class="line">        {</span><br><span class="line">            <span class="string">"item_text"</span>: <span class="string">"一部充满悬疑的动作片"</span>,</span><br><span class="line">            <span class="string">"user_history"</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">            <span class="string">"rating"</span>: <span class="number">4.5</span></span><br><span class="line">        },</span><br><span class="line">        <span class="comment"># ... 更多数据</span></span><br><span class="line">    ]</span><br><span class="line">    </span><br><span class="line">    dataset = RecommendationDataset(train_data)</span><br><span class="line">    dataloader = DataLoader(dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 训练循环</span></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        total_loss = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> dataloader:</span><br><span class="line">            item_texts = batch[<span class="string">"item_text"</span>]</span><br><span class="line">            user_history = batch[<span class="string">"user_history"</span>]</span><br><span class="line">            ratings = batch[<span class="string">"rating"</span>]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 准备历史张量</span></span><br><span class="line">            max_len = <span class="built_in">max</span>(<span class="built_in">len</span>(h) <span class="keyword">for</span> h <span class="keyword">in</span> user_history)</span><br><span class="line">            history_tensor = torch.zeros(<span class="built_in">len</span>(user_history), max_len, dtype=torch.long)</span><br><span class="line">            <span class="keyword">for</span> i, h <span class="keyword">in</span> <span class="built_in">enumerate</span>(user_history):</span><br><span class="line">                history_tensor[i, :<span class="built_in">len</span>(h)] = torch.tensor(h)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 前向传播</span></span><br><span class="line">            scores = model(item_texts, history_tensor)</span><br><span class="line">            loss = criterion(scores.squeeze(), ratings.<span class="built_in">float</span>())</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 反向传播</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            </span><br><span class="line">            total_loss += loss.item()</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"Epoch <span class="subst">{epoch+<span class="number">1</span>}</span>, Loss: <span class="subst">{total_loss / <span class="built_in">len</span>(dataloader):<span class="number">.4</span>f}</span>"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># 使用示例</span></span><br><span class="line">    model = ALLMRec()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 预测</span></span><br><span class="line">    score = model.predict(</span><br><span class="line">        item_text=<span class="string">"一部感人的剧情片"</span>,</span><br><span class="line">        user_history_ids=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"预测分数: <span class="subst">{score:<span class="number">.2</span>f}</span>"</span>)</span><br></pre></td></tr></table></figure>
<h3 id="优势分析">优势分析</h3>
<p>A-LLMRec 的优势在于：</p>
<ol type="1">
<li><strong>参数高效</strong>：只需要训练适配器参数，而不是整个
LLM，大大降低了训练成本</li>
<li><strong>知识保留</strong>：LLM
的预训练知识得以保留，同时适应推荐任务</li>
<li><strong>可扩展性</strong>：可以轻松添加新的适配器来处理不同的推荐场景</li>
<li><strong>灵活性</strong>：可以针对不同层使用不同大小的适配器</li>
</ol>
<h2 id="xrec可解释的-llm-推荐系统">XRec：可解释的 LLM 推荐系统</h2>
<p>XRec（Explainable Recommendation）专注于使用 LLM
生成可解释的推荐理由。用户不仅看到推荐结果，还能理解为什么推荐这些物品。</p>
<h3 id="架构设计-1">架构设计</h3>
<p>XRec 包含两个主要组件：</p>
<ol type="1">
<li><strong>推荐模型</strong>：生成推荐分数（可以使用任何推荐模型）</li>
<li><strong>解释生成器</strong>：基于 LLM 生成推荐理由</li>
</ol>
<h3 id="实现代码-1">实现代码</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Dict</span>, <span class="type">Tuple</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">XRecExplainer</span>:</span><br><span class="line">    <span class="string">"""XRec 可解释推荐系统"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_name: <span class="built_in">str</span> = <span class="string">"gpt-3.5-turbo"</span></span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            model_name: 用于生成解释的 LLM 模型</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.model_name = model_name</span><br><span class="line">        <span class="comment"># 这里使用 OpenAI API，也可以使用本地模型</span></span><br><span class="line">        <span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line">        <span class="keyword">import</span> os</span><br><span class="line">        self.client = OpenAI(api_key=os.getenv(<span class="string">"OPENAI_API_KEY"</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generate_explanation</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        user_history: <span class="type">List</span>[<span class="type">Dict</span>],</span></span><br><span class="line"><span class="params">        recommended_item: <span class="type">Dict</span>,</span></span><br><span class="line"><span class="params">        recommendation_score: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">        explanation_type: <span class="built_in">str</span> = <span class="string">"detailed"</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        生成推荐解释</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_history: 用户历史行为</span></span><br><span class="line"><span class="string">            recommended_item: 推荐的物品信息</span></span><br><span class="line"><span class="string">            recommendation_score: 推荐分数</span></span><br><span class="line"><span class="string">            explanation_type: 解释类型（"brief", "detailed", "comparative"）</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            推荐解释文本</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 格式化用户历史</span></span><br><span class="line">        history_str = self._format_history(user_history)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 构建 Prompt</span></span><br><span class="line">        <span class="keyword">if</span> explanation_type == <span class="string">"brief"</span>:</span><br><span class="line">            prompt = self._build_brief_prompt(history_str, recommended_item, recommendation_score)</span><br><span class="line">        <span class="keyword">elif</span> explanation_type == <span class="string">"detailed"</span>:</span><br><span class="line">            prompt = self._build_detailed_prompt(history_str, recommended_item, recommendation_score)</span><br><span class="line">        <span class="keyword">elif</span> explanation_type == <span class="string">"comparative"</span>:</span><br><span class="line">            prompt = self._build_comparative_prompt(history_str, recommended_item, recommendation_score)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            prompt = self._build_detailed_prompt(history_str, recommended_item, recommendation_score)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 调用 LLM 生成解释</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = self.client.chat.completions.create(</span><br><span class="line">                model=self.model_name,</span><br><span class="line">                messages=[</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"system"</span>, <span class="string">"content"</span>: <span class="string">"你是一个专业的推荐系统解释生成器。你的任务是生成清晰、有说服力的推荐理由。"</span>},</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: prompt}</span><br><span class="line">                ],</span><br><span class="line">                temperature=<span class="number">0.7</span>,</span><br><span class="line">                max_tokens=<span class="number">500</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            explanation = response.choices[<span class="number">0</span>].message.content.strip()</span><br><span class="line">            <span class="keyword">return</span> explanation</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"解释生成错误: <span class="subst">{e}</span>"</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"基于您的历史偏好，我们为您推荐了此物品。"</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_format_history</span>(<span class="params">self, user_history: <span class="type">List</span>[<span class="type">Dict</span>]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""格式化用户历史"""</span></span><br><span class="line">        history_str = <span class="string">"用户历史行为：\n"</span></span><br><span class="line">        <span class="keyword">for</span> i, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(user_history[:<span class="number">10</span>], <span class="number">1</span>):  <span class="comment"># 只取最近10个</span></span><br><span class="line">            item_name = item.get(<span class="string">'item_name'</span>, <span class="string">'未知'</span>)</span><br><span class="line">            rating = item.get(<span class="string">'rating'</span>, <span class="string">'N/A'</span>)</span><br><span class="line">            category = item.get(<span class="string">'category'</span>, <span class="string">''</span>)</span><br><span class="line">            history_str += <span class="string">f"<span class="subst">{i}</span>. 《<span class="subst">{item_name}</span>》"</span></span><br><span class="line">            <span class="keyword">if</span> category:</span><br><span class="line">                history_str += <span class="string">f" (<span class="subst">{category}</span>)"</span></span><br><span class="line">            <span class="keyword">if</span> rating != <span class="string">'N/A'</span>:</span><br><span class="line">                history_str += <span class="string">f" - 评分: <span class="subst">{rating}</span>/5"</span></span><br><span class="line">            history_str += <span class="string">"\n"</span></span><br><span class="line">        <span class="keyword">return</span> history_str</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_brief_prompt</span>(<span class="params">self, history_str: <span class="built_in">str</span>, item: <span class="type">Dict</span>, score: <span class="built_in">float</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""构建简短解释的 Prompt"""</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">f"""用户历史：</span></span><br><span class="line"><span class="string"><span class="subst">{history_str}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">推荐物品：《<span class="subst">{item.get(<span class="string">'item_name'</span>, <span class="string">'未知'</span>)}</span>》</span></span><br><span class="line"><span class="string">推荐分数：<span class="subst">{score:<span class="number">.2</span>f}</span>/5.0</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">请用一句话解释为什么推荐这个物品。解释要简洁明了，不超过30字。"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_detailed_prompt</span>(<span class="params">self, history_str: <span class="built_in">str</span>, item: <span class="type">Dict</span>, score: <span class="built_in">float</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""构建详细解释的 Prompt"""</span></span><br><span class="line">        item_desc = item.get(<span class="string">'description'</span>, <span class="string">''</span>)</span><br><span class="line">        item_category = item.get(<span class="string">'category'</span>, <span class="string">''</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="string">f"""用户历史：</span></span><br><span class="line"><span class="string"><span class="subst">{history_str}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">推荐物品：</span></span><br><span class="line"><span class="string">- 名称：《<span class="subst">{item.get(<span class="string">'item_name'</span>, <span class="string">'未知'</span>)}</span>》</span></span><br><span class="line"><span class="string">- 类别：<span class="subst">{item_category}</span></span></span><br><span class="line"><span class="string">- 描述：<span class="subst">{item_desc}</span></span></span><br><span class="line"><span class="string">- 推荐分数：<span class="subst">{score:<span class="number">.2</span>f}</span>/5.0</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">请详细解释为什么推荐这个物品。解释应该：</span></span><br><span class="line"><span class="string">1. 说明与用户历史偏好的关联</span></span><br><span class="line"><span class="string">2. 突出物品的特点和优势</span></span><br><span class="line"><span class="string">3. 说明为什么用户可能会喜欢</span></span><br><span class="line"><span class="string">4. 语言自然流畅，有说服力</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">请生成一段100-200字的推荐解释。"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_comparative_prompt</span>(<span class="params">self, history_str: <span class="built_in">str</span>, item: <span class="type">Dict</span>, score: <span class="built_in">float</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""构建对比解释的 Prompt"""</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">f"""用户历史：</span></span><br><span class="line"><span class="string"><span class="subst">{history_str}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">推荐物品：《<span class="subst">{item.get(<span class="string">'item_name'</span>, <span class="string">'未知'</span>)}</span>》</span></span><br><span class="line"><span class="string">推荐分数：<span class="subst">{score:<span class="number">.2</span>f}</span>/5.0</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">请通过对比用户历史中的物品，解释为什么推荐这个新物品。说明：</span></span><br><span class="line"><span class="string">1. 与历史物品的相似之处</span></span><br><span class="line"><span class="string">2. 与历史物品的不同之处</span></span><br><span class="line"><span class="string">3. 为什么这些特点会让用户感兴趣</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">请生成一段150-250字的对比解释。"""</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">XRecRecommender</span>:</span><br><span class="line">    <span class="string">"""完整的 XRec 推荐系统"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, recommendation_model, explainer: XRecExplainer</span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            recommendation_model: 推荐模型（可以是任何推荐模型）</span></span><br><span class="line"><span class="string">            explainer: 解释生成器</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.recommendation_model = recommendation_model</span><br><span class="line">        self.explainer = explainer</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">recommend_with_explanation</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        user_id: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        candidates: <span class="type">List</span>[<span class="type">Dict</span>],</span></span><br><span class="line"><span class="params">        user_history: <span class="type">List</span>[<span class="type">Dict</span>],</span></span><br><span class="line"><span class="params">        top_k: <span class="built_in">int</span> = <span class="number">5</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="type">List</span>[<span class="type">Dict</span>]:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        生成带解释的推荐</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_id: 用户 ID</span></span><br><span class="line"><span class="string">            candidates: 候选物品列表</span></span><br><span class="line"><span class="string">            user_history: 用户历史行为</span></span><br><span class="line"><span class="string">            top_k: 推荐数量</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            推荐结果列表，每个包含物品信息和解释</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 使用推荐模型生成分数</span></span><br><span class="line">        scores = []</span><br><span class="line">        <span class="keyword">for</span> candidate <span class="keyword">in</span> candidates:</span><br><span class="line">            <span class="comment"># 这里简化处理，实际应该调用推荐模型</span></span><br><span class="line">            score = self.recommendation_model.predict(user_id, candidate[<span class="string">'item_id'</span>])</span><br><span class="line">            scores.append((candidate, score))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 排序</span></span><br><span class="line">        scores.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 生成解释</span></span><br><span class="line">        recommendations = []</span><br><span class="line">        <span class="keyword">for</span> candidate, score <span class="keyword">in</span> scores[:top_k]:</span><br><span class="line">            explanation = self.explainer.generate_explanation(</span><br><span class="line">                user_history=user_history,</span><br><span class="line">                recommended_item=candidate,</span><br><span class="line">                recommendation_score=score,</span><br><span class="line">                explanation_type=<span class="string">"detailed"</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            recommendations.append({</span><br><span class="line">                <span class="string">"item"</span>: candidate,</span><br><span class="line">                <span class="string">"score"</span>: score,</span><br><span class="line">                <span class="string">"explanation"</span>: explanation</span><br><span class="line">            })</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> recommendations</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用示例</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># 初始化解释器</span></span><br><span class="line">    explainer = XRecExplainer()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 用户历史</span></span><br><span class="line">    user_history = [</span><br><span class="line">        {<span class="string">"item_name"</span>: <span class="string">"肖申克的救赎"</span>, <span class="string">"rating"</span>: <span class="number">5</span>, <span class="string">"category"</span>: <span class="string">"剧情"</span>},</span><br><span class="line">        {<span class="string">"item_name"</span>: <span class="string">"阿甘正传"</span>, <span class="string">"rating"</span>: <span class="number">5</span>, <span class="string">"category"</span>: <span class="string">"剧情"</span>},</span><br><span class="line">        {<span class="string">"item_name"</span>: <span class="string">"当幸福来敲门"</span>, <span class="string">"rating"</span>: <span class="number">4</span>, <span class="string">"category"</span>: <span class="string">"剧情"</span>}</span><br><span class="line">    ]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 推荐物品</span></span><br><span class="line">    recommended_item = {</span><br><span class="line">        <span class="string">"item_name"</span>: <span class="string">"美丽人生"</span>,</span><br><span class="line">        <span class="string">"category"</span>: <span class="string">"剧情/战争"</span>,</span><br><span class="line">        <span class="string">"description"</span>: <span class="string">"在集中营中用父爱和幽默保护孩子的感人故事"</span></span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 生成解释</span></span><br><span class="line">    explanation = explainer.generate_explanation(</span><br><span class="line">        user_history=user_history,</span><br><span class="line">        recommended_item=recommended_item,</span><br><span class="line">        recommendation_score=<span class="number">4.8</span>,</span><br><span class="line">        explanation_type=<span class="string">"detailed"</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"推荐解释："</span>)</span><br><span class="line">    <span class="built_in">print</span>(explanation)</span><br></pre></td></tr></table></figure>
<p>XRec
的核心价值在于提升推荐系统的可解释性，让用户理解推荐的原因，从而增加信任度和满意度。</p>
<h2 id="llm-作为特征增强器">LLM 作为特征增强器</h2>
<p>LLM
可以作为特征增强器，将物品的文本信息（描述、评论、标签等）编码为高质量的向量表示，然后用于传统的推荐模型。这种方法结合了
LLM 的语义理解能力和传统推荐模型的高效性。</p>
<h3 id="基本思路-1">基本思路</h3>
<p>使用 LLM 提取特征的基本流程：</p>
<ol type="1">
<li><strong>文本编码</strong>：使用 LLM 将物品文本编码为向量</li>
<li><strong>特征融合</strong>：将 LLM
特征与传统特征（ID、类别等）融合</li>
<li><strong>推荐预测</strong>：使用融合后的特征进行推荐</li>
</ol>
<h3 id="实现代码-2">实现代码</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModel, AutoTokenizer</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Dict</span>, <span class="type">Optional</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LLMFeatureExtractor</span>:</span><br><span class="line">    <span class="string">"""使用 LLM 提取物品特征"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_name: <span class="built_in">str</span> = <span class="string">"bert-base-chinese"</span>, device: <span class="built_in">str</span> = <span class="string">"cuda"</span></span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            model_name: LLM 模型名称</span></span><br><span class="line"><span class="string">            device: 设备</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.device = device</span><br><span class="line">        self.model = AutoModel.from_pretrained(model_name).to(device)</span><br><span class="line">        self.tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br><span class="line">        self.model.<span class="built_in">eval</span>()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 冻结 LLM 参数（可选）</span></span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> self.model.parameters():</span><br><span class="line">            param.requires_grad = <span class="literal">False</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">extract_features</span>(<span class="params">self, texts: <span class="type">List</span>[<span class="built_in">str</span>], batch_size: <span class="built_in">int</span> = <span class="number">32</span></span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        提取文本特征</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            texts: 文本列表</span></span><br><span class="line"><span class="string">            batch_size: 批处理大小</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            特征向量，形状为 (n_texts, hidden_size)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        features = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(texts), batch_size):</span><br><span class="line">            batch_texts = texts[i:i+batch_size]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Tokenize</span></span><br><span class="line">            encoded = self.tokenizer(</span><br><span class="line">                batch_texts,</span><br><span class="line">                padding=<span class="literal">True</span>,</span><br><span class="line">                truncation=<span class="literal">True</span>,</span><br><span class="line">                max_length=<span class="number">512</span>,</span><br><span class="line">                return_tensors=<span class="string">"pt"</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 移动到设备</span></span><br><span class="line">            encoded = {k: v.to(self.device) <span class="keyword">for</span> k, v <span class="keyword">in</span> encoded.items()}</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 编码</span></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                outputs = self.model(**encoded)</span><br><span class="line">                <span class="comment"># 使用 [CLS] token 的表示</span></span><br><span class="line">                batch_features = outputs.last_hidden_state[:, <span class="number">0</span>, :].cpu().numpy()</span><br><span class="line">            </span><br><span class="line">            features.append(batch_features)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> np.vstack(features)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">extract_item_features</span>(<span class="params">self, items: <span class="type">List</span>[<span class="type">Dict</span>]</span>) -&gt; np.ndarray:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        提取物品特征</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            items: 物品列表，每个物品包含 text, description 等字段</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            物品特征矩阵</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 组合物品的文本信息</span></span><br><span class="line">        texts = []</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">            text_parts = []</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> <span class="string">'title'</span> <span class="keyword">in</span> item:</span><br><span class="line">                text_parts.append(item[<span class="string">'title'</span>])</span><br><span class="line">            <span class="keyword">if</span> <span class="string">'description'</span> <span class="keyword">in</span> item:</span><br><span class="line">                text_parts.append(item[<span class="string">'description'</span>])</span><br><span class="line">            <span class="keyword">if</span> <span class="string">'category'</span> <span class="keyword">in</span> item:</span><br><span class="line">                text_parts.append(<span class="string">f"类别：<span class="subst">{item[<span class="string">'category'</span>]}</span>"</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="string">'tags'</span> <span class="keyword">in</span> item:</span><br><span class="line">                tags_str = <span class="string">", "</span>.join(item[<span class="string">'tags'</span>])</span><br><span class="line">                text_parts.append(<span class="string">f"标签：<span class="subst">{tags_str}</span>"</span>)</span><br><span class="line">            </span><br><span class="line">            text = <span class="string">" | "</span>.join(text_parts)</span><br><span class="line">            texts.append(text)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> self.extract_features(texts)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EnhancedRecommendationModel</span>(nn.Module):</span><br><span class="line">    <span class="string">"""使用 LLM 特征增强的推荐模型"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        num_users: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        num_items: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        llm_feature_dim: <span class="built_in">int</span> = <span class="number">768</span>,</span></span><br><span class="line"><span class="params">        embedding_dim: <span class="built_in">int</span> = <span class="number">128</span>,</span></span><br><span class="line"><span class="params">        hidden_dims: <span class="type">List</span>[<span class="built_in">int</span>] = [<span class="number">256</span>, <span class="number">128</span>, <span class="number">64</span>]</span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            num_users: 用户数量</span></span><br><span class="line"><span class="string">            num_items: 物品数量</span></span><br><span class="line"><span class="string">            llm_feature_dim: LLM 特征维度</span></span><br><span class="line"><span class="string">            embedding_dim: ID 嵌入维度</span></span><br><span class="line"><span class="string">            hidden_dims: 隐藏层维度列表</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 用户和物品 ID 嵌入</span></span><br><span class="line">        self.user_embedding = nn.Embedding(num_users, embedding_dim)</span><br><span class="line">        self.item_embedding = nn.Embedding(num_items, embedding_dim)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># LLM 特征投影层（将 LLM 特征投影到与 ID 嵌入相同的维度）</span></span><br><span class="line">        self.llm_projection = nn.Linear(llm_feature_dim, embedding_dim)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 特征融合层</span></span><br><span class="line">        <span class="comment"># 用户特征：ID 嵌入</span></span><br><span class="line">        <span class="comment"># 物品特征：ID 嵌入 + LLM 特征</span></span><br><span class="line">        input_dim = embedding_dim * <span class="number">2</span> + embedding_dim  <span class="comment"># user_emb + item_emb + llm_feat</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># MLP 层</span></span><br><span class="line">        layers = []</span><br><span class="line">        prev_dim = input_dim</span><br><span class="line">        <span class="keyword">for</span> hidden_dim <span class="keyword">in</span> hidden_dims:</span><br><span class="line">            layers.append(nn.Linear(prev_dim, hidden_dim))</span><br><span class="line">            layers.append(nn.ReLU())</span><br><span class="line">            layers.append(nn.Dropout(<span class="number">0.2</span>))</span><br><span class="line">            prev_dim = hidden_dim</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 输出层</span></span><br><span class="line">        layers.append(nn.Linear(prev_dim, <span class="number">1</span>))</span><br><span class="line">        layers.append(nn.Sigmoid())</span><br><span class="line">        </span><br><span class="line">        self.mlp = nn.Sequential(*layers)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        user_ids: torch.Tensor,</span></span><br><span class="line"><span class="params">        item_ids: torch.Tensor,</span></span><br><span class="line"><span class="params">        item_llm_features: <span class="type">Optional</span>[torch.Tensor] = <span class="literal">None</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        前向传播</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_ids: 用户 ID，形状为 (batch_size,)</span></span><br><span class="line"><span class="string">            item_ids: 物品 ID，形状为 (batch_size,)</span></span><br><span class="line"><span class="string">            item_llm_features: 物品的 LLM 特征，形状为 (batch_size, llm_feature_dim)</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            预测分数，形状为 (batch_size, 1)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 用户嵌入</span></span><br><span class="line">        user_emb = self.user_embedding(user_ids)  <span class="comment"># (batch_size, embedding_dim)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 物品 ID 嵌入</span></span><br><span class="line">        item_emb = self.item_embedding(item_ids)  <span class="comment"># (batch_size, embedding_dim)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># LLM 特征</span></span><br><span class="line">        <span class="keyword">if</span> item_llm_features <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            llm_emb = self.llm_projection(item_llm_features)  <span class="comment"># (batch_size, embedding_dim)</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 如果没有 LLM 特征，使用零向量</span></span><br><span class="line">            llm_emb = torch.zeros_like(item_emb)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 拼接特征</span></span><br><span class="line">        combined = torch.cat([user_emb, item_emb, llm_emb], dim=<span class="number">1</span>)  <span class="comment"># (batch_size, embedding_dim * 3)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># MLP</span></span><br><span class="line">        score = self.mlp(combined)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> score</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用示例</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># 初始化特征提取器</span></span><br><span class="line">    feature_extractor = LLMFeatureExtractor()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 物品数据</span></span><br><span class="line">    items = [</span><br><span class="line">        {</span><br><span class="line">            <span class="string">"item_id"</span>: <span class="number">0</span>,</span><br><span class="line">            <span class="string">"title"</span>: <span class="string">"肖申克的救赎"</span>,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"一部关于希望和友谊的经典电影"</span>,</span><br><span class="line">            <span class="string">"category"</span>: <span class="string">"剧情"</span>,</span><br><span class="line">            <span class="string">"tags"</span>: [<span class="string">"剧情"</span>, <span class="string">"犯罪"</span>, <span class="string">"经典"</span>]</span><br><span class="line">        },</span><br><span class="line">        {</span><br><span class="line">            <span class="string">"item_id"</span>: <span class="number">1</span>,</span><br><span class="line">            <span class="string">"title"</span>: <span class="string">"阿甘正传"</span>,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"一个智障人士的传奇人生"</span>,</span><br><span class="line">            <span class="string">"category"</span>: <span class="string">"剧情"</span>,</span><br><span class="line">            <span class="string">"tags"</span>: [<span class="string">"剧情"</span>, <span class="string">"励志"</span>, <span class="string">"经典"</span>]</span><br><span class="line">        }</span><br><span class="line">    ]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 提取 LLM 特征</span></span><br><span class="line">    llm_features = feature_extractor.extract_item_features(items)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"LLM 特征形状: <span class="subst">{llm_features.shape}</span>"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 初始化推荐模型</span></span><br><span class="line">    model = EnhancedRecommendationModel(</span><br><span class="line">        num_users=<span class="number">1000</span>,</span><br><span class="line">        num_items=<span class="number">10000</span>,</span><br><span class="line">        llm_feature_dim=<span class="number">768</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 预测</span></span><br><span class="line">    user_ids = torch.tensor([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">    item_ids = torch.tensor([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">    item_llm_feats = torch.tensor(llm_features)</span><br><span class="line">    </span><br><span class="line">    scores = model(user_ids, item_ids, item_llm_feats)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"预测分数: <span class="subst">{scores}</span>"</span>)</span><br></pre></td></tr></table></figure>
<h3 id="优势分析-1">优势分析</h3>
<p>使用 LLM 作为特征增强器的优势：</p>
<ol type="1">
<li><strong>语义理解</strong>：LLM
能够理解物品的文本描述，提取丰富的语义特征</li>
<li><strong>冷启动友好</strong>：对于新物品，即使没有历史行为数据，也可以通过文本描述提取特征</li>
<li><strong>可解释性</strong>：LLM 特征往往对应语义概念，便于理解</li>
<li><strong>灵活性</strong>：可以轻松添加新的文本信息（评论、标签等）来增强特征</li>
</ol>
<h2 id="llm-作为重排序器">LLM 作为重排序器</h2>
<p>在推荐系统的多阶段架构中，重排序（Reranking）是最后一环。LLM
可以作为重排序器，对粗排后的候选进行精细排序，考虑用户意图、物品语义等复杂因素。</p>
<h3 id="架构设计-2">架构设计</h3>
<p>LLM 重排序器的基本流程：</p>
<ol type="1">
<li><strong>候选准备</strong>：从粗排阶段获得 Top-K 候选（例如
Top-100）</li>
<li><strong>上下文构建</strong>：构建包含用户历史、候选物品信息的上下文</li>
<li><strong>LLM 排序</strong>：使用 LLM 对候选进行排序</li>
<li><strong>结果输出</strong>：返回重排序后的 Top-N 结果</li>
</ol>
<h3 id="实现代码-3">实现代码</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Dict</span>, <span class="type">Tuple</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LLMReranker</span>:</span><br><span class="line">    <span class="string">"""使用 LLM 进行重排序"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model: <span class="built_in">str</span> = <span class="string">"gpt-3.5-turbo"</span>, max_candidates: <span class="built_in">int</span> = <span class="number">50</span></span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            model: LLM 模型名称</span></span><br><span class="line"><span class="string">            max_candidates: 最大候选数量（避免 Token 过多）</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.client = OpenAI(api_key=os.getenv(<span class="string">"OPENAI_API_KEY"</span>))</span><br><span class="line">        self.model = model</span><br><span class="line">        self.max_candidates = max_candidates</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">rerank</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        user_history: <span class="type">List</span>[<span class="type">Dict</span>],</span></span><br><span class="line"><span class="params">        candidates: <span class="type">List</span>[<span class="type">Dict</span>],</span></span><br><span class="line"><span class="params">        top_n: <span class="built_in">int</span> = <span class="number">10</span>,</span></span><br><span class="line"><span class="params">        strategy: <span class="built_in">str</span> = <span class="string">"pairwise"</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="type">List</span>[<span class="type">Dict</span>]:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        重排序候选物品</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_history: 用户历史行为</span></span><br><span class="line"><span class="string">            candidates: 候选物品列表（已按粗排分数排序）</span></span><br><span class="line"><span class="string">            top_n: 最终推荐数量</span></span><br><span class="line"><span class="string">            strategy: 排序策略（"pairwise", "listwise", "pointwise"）</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            重排序后的物品列表</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 限制候选数量</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(candidates) &gt; self.max_candidates:</span><br><span class="line">            candidates = candidates[:self.max_candidates]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> strategy == <span class="string">"pairwise"</span>:</span><br><span class="line">            <span class="keyword">return</span> self._pairwise_rerank(user_history, candidates, top_n)</span><br><span class="line">        <span class="keyword">elif</span> strategy == <span class="string">"listwise"</span>:</span><br><span class="line">            <span class="keyword">return</span> self._listwise_rerank(user_history, candidates, top_n)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self._pointwise_rerank(user_history, candidates, top_n)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_pointwise_rerank</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        user_history: <span class="type">List</span>[<span class="type">Dict</span>],</span></span><br><span class="line"><span class="params">        candidates: <span class="type">List</span>[<span class="type">Dict</span>],</span></span><br><span class="line"><span class="params">        top_n: <span class="built_in">int</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="type">List</span>[<span class="type">Dict</span>]:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Pointwise 重排序：为每个候选物品单独评分</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 格式化用户历史</span></span><br><span class="line">        history_str = self._format_history(user_history)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 为每个候选生成评分</span></span><br><span class="line">        scored_candidates = []</span><br><span class="line">        <span class="keyword">for</span> candidate <span class="keyword">in</span> candidates:</span><br><span class="line">            score = self._score_candidate(history_str, candidate)</span><br><span class="line">            scored_candidates.append({</span><br><span class="line">                **candidate,</span><br><span class="line">                <span class="string">"llm_score"</span>: score</span><br><span class="line">            })</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 按 LLM 分数排序</span></span><br><span class="line">        scored_candidates.sort(key=<span class="keyword">lambda</span> x: x[<span class="string">"llm_score"</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> scored_candidates[:top_n]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_pairwise_rerank</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        user_history: <span class="type">List</span>[<span class="type">Dict</span>],</span></span><br><span class="line"><span class="params">        candidates: <span class="type">List</span>[<span class="type">Dict</span>],</span></span><br><span class="line"><span class="params">        top_n: <span class="built_in">int</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="type">List</span>[<span class="type">Dict</span>]:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Pairwise 重排序：通过两两比较进行排序</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 使用冒泡排序的思想，但用 LLM 进行比较</span></span><br><span class="line">        n = <span class="built_in">len</span>(candidates)</span><br><span class="line">        ranked = candidates.copy()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 简化版：只进行有限次比较</span></span><br><span class="line">        max_comparisons = <span class="built_in">min</span>(n * (n - <span class="number">1</span>) // <span class="number">2</span>, <span class="number">100</span>)  <span class="comment"># 限制比较次数</span></span><br><span class="line">        </span><br><span class="line">        comparison_count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> comparison_count &gt;= max_comparisons:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">            swapped = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n - i - <span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> comparison_count &gt;= max_comparisons:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 比较两个候选</span></span><br><span class="line">                better = self._compare_candidates(</span><br><span class="line">                    user_history,</span><br><span class="line">                    ranked[j],</span><br><span class="line">                    ranked[j + <span class="number">1</span>]</span><br><span class="line">                )</span><br><span class="line">                </span><br><span class="line">                comparison_count += <span class="number">1</span></span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> better == <span class="number">1</span>:  <span class="comment"># ranked[j+1] 更好</span></span><br><span class="line">                    ranked[j], ranked[j + <span class="number">1</span>] = ranked[j + <span class="number">1</span>], ranked[j]</span><br><span class="line">                    swapped = <span class="literal">True</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> swapped:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> ranked[:top_n]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_listwise_rerank</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        user_history: <span class="type">List</span>[<span class="type">Dict</span>],</span></span><br><span class="line"><span class="params">        candidates: <span class="type">List</span>[<span class="type">Dict</span>],</span></span><br><span class="line"><span class="params">        top_n: <span class="built_in">int</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="type">List</span>[<span class="type">Dict</span>]:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Listwise 重排序：一次性对所有候选进行排序</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        history_str = self._format_history(user_history)</span><br><span class="line">        candidates_str = self._format_candidates(candidates)</span><br><span class="line">        </span><br><span class="line">        prompt = <span class="string">f"""你是一个专业的推荐系统。请根据用户的历史偏好，对以下候选物品进行排序。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">用户历史：</span></span><br><span class="line"><span class="string"><span class="subst">{history_str}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">候选物品：</span></span><br><span class="line"><span class="string"><span class="subst">{candidates_str}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">请按照用户可能喜欢的程度，对这些物品进行排序（从最喜欢到最不喜欢）。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">输出格式（JSON）：</span></span><br><span class="line"><span class="string">{{</span></span><br><span class="line"><span class="string">    "ranking": [</span></span><br><span class="line"><span class="string">        {{"item_id": 1, "rank": 1}},</span></span><br><span class="line"><span class="string">        {{"item_id": 2, "rank": 2}},</span></span><br><span class="line"><span class="string">        ...</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">}}</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">只输出 JSON，不要输出其他内容。"""</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = self.client.chat.completions.create(</span><br><span class="line">                model=self.model,</span><br><span class="line">                messages=[</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"system"</span>, <span class="string">"content"</span>: <span class="string">"你是一个专业的推荐系统排序器。"</span>},</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: prompt}</span><br><span class="line">                ],</span><br><span class="line">                temperature=<span class="number">0.1</span>,  <span class="comment"># 低温度保证一致性</span></span><br><span class="line">                max_tokens=<span class="number">2000</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            content = response.choices[<span class="number">0</span>].message.content.strip()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 解析 JSON</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">"```json"</span> <span class="keyword">in</span> content:</span><br><span class="line">                content = content.split(<span class="string">"```json"</span>)[<span class="number">1</span>].split(<span class="string">"```"</span>)[<span class="number">0</span>].strip()</span><br><span class="line">            <span class="keyword">elif</span> <span class="string">"```"</span> <span class="keyword">in</span> content:</span><br><span class="line">                content = content.split(<span class="string">"```"</span>)[<span class="number">1</span>].split(<span class="string">"```"</span>)[<span class="number">0</span>].strip()</span><br><span class="line">            </span><br><span class="line">            result = json.loads(content)</span><br><span class="line">            ranking = result.get(<span class="string">"ranking"</span>, [])</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 构建 item_id 到 rank 的映射</span></span><br><span class="line">            id_to_rank = {item[<span class="string">"item_id"</span>]: item[<span class="string">"rank"</span>] <span class="keyword">for</span> item <span class="keyword">in</span> ranking}</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 按 rank 排序</span></span><br><span class="line">            ranked_candidates = <span class="built_in">sorted</span>(</span><br><span class="line">                candidates,</span><br><span class="line">                key=<span class="keyword">lambda</span> x: id_to_rank.get(x.get(<span class="string">"item_id"</span>, -<span class="number">1</span>), <span class="number">999</span>)</span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">return</span> ranked_candidates[:top_n]</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"Listwise 重排序错误: <span class="subst">{e}</span>"</span>)</span><br><span class="line">            <span class="comment"># 降级到 pointwise</span></span><br><span class="line">            <span class="keyword">return</span> self._pointwise_rerank(user_history, candidates, top_n)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_score_candidate</span>(<span class="params">self, history_str: <span class="built_in">str</span>, candidate: <span class="type">Dict</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">"""为单个候选物品评分"""</span></span><br><span class="line">        prompt = <span class="string">f"""用户历史：</span></span><br><span class="line"><span class="string"><span class="subst">{history_str}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">候选物品：</span></span><br><span class="line"><span class="string">- 名称：《<span class="subst">{candidate.get(<span class="string">'item_name'</span>, <span class="string">'未知'</span>)}</span>》</span></span><br><span class="line"><span class="string">- 类别：<span class="subst">{candidate.get(<span class="string">'category'</span>, <span class="string">''</span>)}</span></span></span><br><span class="line"><span class="string">- 描述：<span class="subst">{candidate.get(<span class="string">'description'</span>, <span class="string">''</span>)}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">请评估用户对这个物品的喜欢程度，给出 0-10 分的分数。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">只输出一个数字（0-10），不要输出其他内容。"""</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = self.client.chat.completions.create(</span><br><span class="line">                model=self.model,</span><br><span class="line">                messages=[</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"system"</span>, <span class="string">"content"</span>: <span class="string">"你是一个专业的推荐评分器。"</span>},</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: prompt}</span><br><span class="line">                ],</span><br><span class="line">                temperature=<span class="number">0.1</span>,</span><br><span class="line">                max_tokens=<span class="number">10</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            score_str = response.choices[<span class="number">0</span>].message.content.strip()</span><br><span class="line">            score = <span class="built_in">float</span>(score_str)</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">max</span>(<span class="number">0</span>, <span class="built_in">min</span>(<span class="number">10</span>, score))  <span class="comment"># 限制在 0-10 范围</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"评分错误: <span class="subst">{e}</span>"</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">5.0</span>  <span class="comment"># 默认分数</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_compare_candidates</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        user_history: <span class="type">List</span>[<span class="type">Dict</span>],</span></span><br><span class="line"><span class="params">        candidate1: <span class="type">Dict</span>,</span></span><br><span class="line"><span class="params">        candidate2: <span class="type">Dict</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        比较两个候选物品</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            0: candidate1 更好</span></span><br><span class="line"><span class="string">            1: candidate2 更好</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        history_str = self._format_history(user_history)</span><br><span class="line">        </span><br><span class="line">        prompt = <span class="string">f"""用户历史：</span></span><br><span class="line"><span class="string"><span class="subst">{history_str}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">请比较以下两个物品，判断用户更可能喜欢哪一个：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">物品 A：</span></span><br><span class="line"><span class="string">- 名称：《<span class="subst">{candidate1.get(<span class="string">'item_name'</span>, <span class="string">'未知'</span>)}</span>》</span></span><br><span class="line"><span class="string">- 类别：<span class="subst">{candidate1.get(<span class="string">'category'</span>, <span class="string">''</span>)}</span></span></span><br><span class="line"><span class="string">- 描述：<span class="subst">{candidate1.get(<span class="string">'description'</span>, <span class="string">''</span>)}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">物品 B：</span></span><br><span class="line"><span class="string">- 名称：《<span class="subst">{candidate2.get(<span class="string">'item_name'</span>, <span class="string">'未知'</span>)}</span>》</span></span><br><span class="line"><span class="string">- 类别：<span class="subst">{candidate2.get(<span class="string">'category'</span>, <span class="string">''</span>)}</span></span></span><br><span class="line"><span class="string">- 描述：<span class="subst">{candidate2.get(<span class="string">'description'</span>, <span class="string">''</span>)}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">只输出 "A" 或 "B"，表示用户更可能喜欢哪一个。"""</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = self.client.chat.completions.create(</span><br><span class="line">                model=self.model,</span><br><span class="line">                messages=[</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"system"</span>, <span class="string">"content"</span>: <span class="string">"你是一个专业的推荐比较器。"</span>},</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: prompt}</span><br><span class="line">                ],</span><br><span class="line">                temperature=<span class="number">0.1</span>,</span><br><span class="line">                max_tokens=<span class="number">5</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            result = response.choices[<span class="number">0</span>].message.content.strip().upper()</span><br><span class="line">            <span class="keyword">if</span> <span class="string">"A"</span> <span class="keyword">in</span> result:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">            <span class="keyword">elif</span> <span class="string">"B"</span> <span class="keyword">in</span> result:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span>  <span class="comment"># 默认返回第一个</span></span><br><span class="line">                </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"比较错误: <span class="subst">{e}</span>"</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_format_history</span>(<span class="params">self, user_history: <span class="type">List</span>[<span class="type">Dict</span>]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""格式化用户历史"""</span></span><br><span class="line">        history_str = <span class="string">"用户历史行为：\n"</span></span><br><span class="line">        <span class="keyword">for</span> i, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(user_history[:<span class="number">10</span>], <span class="number">1</span>):</span><br><span class="line">            item_name = item.get(<span class="string">'item_name'</span>, <span class="string">'未知'</span>)</span><br><span class="line">            rating = item.get(<span class="string">'rating'</span>, <span class="string">'N/A'</span>)</span><br><span class="line">            history_str += <span class="string">f"<span class="subst">{i}</span>. 《<span class="subst">{item_name}</span>》"</span></span><br><span class="line">            <span class="keyword">if</span> rating != <span class="string">'N/A'</span>:</span><br><span class="line">                history_str += <span class="string">f"（评分：<span class="subst">{rating}</span>/5）"</span></span><br><span class="line">            history_str += <span class="string">"\n"</span></span><br><span class="line">        <span class="keyword">return</span> history_str</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_format_candidates</span>(<span class="params">self, candidates: <span class="type">List</span>[<span class="type">Dict</span>]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""格式化候选物品"""</span></span><br><span class="line">        candidates_str = <span class="string">""</span></span><br><span class="line">        <span class="keyword">for</span> i, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(candidates, <span class="number">1</span>):</span><br><span class="line">            item_name = item.get(<span class="string">'item_name'</span>, <span class="string">'未知'</span>)</span><br><span class="line">            category = item.get(<span class="string">'category'</span>, <span class="string">''</span>)</span><br><span class="line">            description = item.get(<span class="string">'description'</span>, <span class="string">''</span>)</span><br><span class="line">            item_id = item.get(<span class="string">'item_id'</span>, i)</span><br><span class="line">            </span><br><span class="line">            candidates_str += <span class="string">f"<span class="subst">{i}</span>. [ID: <span class="subst">{item_id}</span>] 《<span class="subst">{item_name}</span>》"</span></span><br><span class="line">            <span class="keyword">if</span> category:</span><br><span class="line">                candidates_str += <span class="string">f" - <span class="subst">{category}</span>"</span></span><br><span class="line">            <span class="keyword">if</span> description:</span><br><span class="line">                candidates_str += <span class="string">f"\n   描述：<span class="subst">{description}</span>"</span></span><br><span class="line">            candidates_str += <span class="string">"\n"</span></span><br><span class="line">        <span class="keyword">return</span> candidates_str</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用示例</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    reranker = LLMReranker()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 用户历史</span></span><br><span class="line">    user_history = [</span><br><span class="line">        {<span class="string">"item_name"</span>: <span class="string">"肖申克的救赎"</span>, <span class="string">"rating"</span>: <span class="number">5</span>},</span><br><span class="line">        {<span class="string">"item_name"</span>: <span class="string">"阿甘正传"</span>, <span class="string">"rating"</span>: <span class="number">5</span>},</span><br><span class="line">        {<span class="string">"item_name"</span>: <span class="string">"当幸福来敲门"</span>, <span class="string">"rating"</span>: <span class="number">4</span>}</span><br><span class="line">    ]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 候选物品（已粗排）</span></span><br><span class="line">    candidates = [</span><br><span class="line">        {<span class="string">"item_id"</span>: <span class="number">1</span>, <span class="string">"item_name"</span>: <span class="string">"美丽人生"</span>, <span class="string">"category"</span>: <span class="string">"剧情"</span>, <span class="string">"description"</span>: <span class="string">"感人的战争片"</span>},</span><br><span class="line">        {<span class="string">"item_id"</span>: <span class="number">2</span>, <span class="string">"item_name"</span>: <span class="string">"教父"</span>, <span class="string">"category"</span>: <span class="string">"犯罪"</span>, <span class="string">"description"</span>: <span class="string">"黑帮经典"</span>},</span><br><span class="line">        {<span class="string">"item_id"</span>: <span class="number">3</span>, <span class="string">"item_name"</span>: <span class="string">"海上钢琴师"</span>, <span class="string">"category"</span>: <span class="string">"剧情"</span>, <span class="string">"description"</span>: <span class="string">"音乐传记"</span>},</span><br><span class="line">        {<span class="string">"item_id"</span>: <span class="number">4</span>, <span class="string">"item_name"</span>: <span class="string">"楚门的世界"</span>, <span class="string">"category"</span>: <span class="string">"科幻"</span>, <span class="string">"description"</span>: <span class="string">"哲学思考"</span>},</span><br><span class="line">        {<span class="string">"item_id"</span>: <span class="number">5</span>, <span class="string">"item_name"</span>: <span class="string">"辛德勒的名单"</span>, <span class="string">"category"</span>: <span class="string">"历史"</span>, <span class="string">"description"</span>: <span class="string">"二战题材"</span>}</span><br><span class="line">    ]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 重排序</span></span><br><span class="line">    reranked = reranker.rerank(</span><br><span class="line">        user_history=user_history,</span><br><span class="line">        candidates=candidates,</span><br><span class="line">        top_n=<span class="number">3</span>,</span><br><span class="line">        strategy=<span class="string">"listwise"</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"重排序结果："</span>)</span><br><span class="line">    <span class="keyword">for</span> i, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(reranked, <span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"<span class="subst">{i}</span>. 《<span class="subst">{item[<span class="string">'item_name'</span>]}</span>》"</span>)</span><br></pre></td></tr></table></figure>
<p>LLM
作为重排序器的优势在于能够考虑复杂的语义匹配和用户意图，但需要注意 Token
消耗和延迟问题。</p>
<h2 id="对话式推荐chatrec">对话式推荐：ChatREC</h2>
<p>对话式推荐（Conversational
Recommendation）允许用户通过自然语言对话与推荐系统交互，系统可以理解用户意图、询问澄清问题、提供推荐并解释理由。ChatREC
是这一领域的代表性架构。</p>
<h3 id="架构设计-3">架构设计</h3>
<p>ChatREC 的核心组件：</p>
<ol type="1">
<li><strong>对话管理器</strong>：管理多轮对话状态</li>
<li><strong>意图理解器</strong>：理解用户意图（搜索、浏览、澄清等）</li>
<li><strong>推荐引擎</strong>：基于对话历史生成推荐</li>
<li><strong>响应生成器</strong>：生成自然语言响应</li>
</ol>
<h3 id="实现代码-4">实现代码</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Dict</span>, <span class="type">Optional</span>, <span class="type">Tuple</span></span><br><span class="line"><span class="keyword">from</span> enum <span class="keyword">import</span> Enum</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UserIntent</span>(<span class="title class_ inherited__">Enum</span>):</span><br><span class="line">    <span class="string">"""用户意图类型"""</span></span><br><span class="line">    SEARCH = <span class="string">"search"</span>  <span class="comment"># 搜索特定物品</span></span><br><span class="line">    BROWSE = <span class="string">"browse"</span>  <span class="comment"># 浏览推荐</span></span><br><span class="line">    CLARIFY = <span class="string">"clarify"</span>  <span class="comment"># 澄清需求</span></span><br><span class="line">    COMPARE = <span class="string">"compare"</span>  <span class="comment"># 比较物品</span></span><br><span class="line">    EXPLAIN = <span class="string">"explain"</span>  <span class="comment"># 询问推荐理由</span></span><br><span class="line">    FEEDBACK = <span class="string">"feedback"</span>  <span class="comment"># 提供反馈</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatREC</span>:</span><br><span class="line">    <span class="string">"""对话式推荐系统"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model: <span class="built_in">str</span> = <span class="string">"gpt-3.5-turbo"</span></span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            model: LLM 模型名称</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.client = OpenAI(api_key=os.getenv(<span class="string">"OPENAI_API_KEY"</span>))</span><br><span class="line">        self.model = model</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 对话历史</span></span><br><span class="line">        self.conversation_history: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">List</span>[<span class="type">Dict</span>]] = {}</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 用户状态</span></span><br><span class="line">        self.user_states: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Dict</span>] = {}</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">chat</span>(<span class="params">self, user_id: <span class="built_in">str</span>, message: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        处理用户消息并生成响应</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_id: 用户 ID</span></span><br><span class="line"><span class="string">            message: 用户消息</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            系统响应</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 初始化对话历史</span></span><br><span class="line">        <span class="keyword">if</span> user_id <span class="keyword">not</span> <span class="keyword">in</span> self.conversation_history:</span><br><span class="line">            self.conversation_history[user_id] = []</span><br><span class="line">            self.user_states[user_id] = {</span><br><span class="line">                <span class="string">"preferences"</span>: [],</span><br><span class="line">                <span class="string">"current_recommendations"</span>: [],</span><br><span class="line">                <span class="string">"context"</span>: {}</span><br><span class="line">            }</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 添加用户消息</span></span><br><span class="line">        self.conversation_history[user_id].append({</span><br><span class="line">            <span class="string">"role"</span>: <span class="string">"user"</span>,</span><br><span class="line">            <span class="string">"content"</span>: message</span><br><span class="line">        })</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 理解用户意图</span></span><br><span class="line">        intent = self._detect_intent(user_id, message)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 根据意图处理</span></span><br><span class="line">        <span class="keyword">if</span> intent == UserIntent.SEARCH:</span><br><span class="line">            response = self._handle_search(user_id, message)</span><br><span class="line">        <span class="keyword">elif</span> intent == UserIntent.BROWSE:</span><br><span class="line">            response = self._handle_browse(user_id)</span><br><span class="line">        <span class="keyword">elif</span> intent == UserIntent.CLARIFY:</span><br><span class="line">            response = self._handle_clarify(user_id, message)</span><br><span class="line">        <span class="keyword">elif</span> intent == UserIntent.COMPARE:</span><br><span class="line">            response = self._handle_compare(user_id, message)</span><br><span class="line">        <span class="keyword">elif</span> intent == UserIntent.EXPLAIN:</span><br><span class="line">            response = self._handle_explain(user_id, message)</span><br><span class="line">        <span class="keyword">elif</span> intent == UserIntent.FEEDBACK:</span><br><span class="line">            response = self._handle_feedback(user_id, message)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            response = self._handle_general(user_id, message)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 添加系统响应</span></span><br><span class="line">        self.conversation_history[user_id].append({</span><br><span class="line">            <span class="string">"role"</span>: <span class="string">"assistant"</span>,</span><br><span class="line">            <span class="string">"content"</span>: response</span><br><span class="line">        })</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_detect_intent</span>(<span class="params">self, user_id: <span class="built_in">str</span>, message: <span class="built_in">str</span></span>) -&gt; UserIntent:</span><br><span class="line">        <span class="string">"""检测用户意图"""</span></span><br><span class="line">        prompt = <span class="string">f"""分析以下用户消息的意图：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">用户消息："<span class="subst">{message}</span>"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">对话历史：</span></span><br><span class="line"><span class="string"><span class="subst">{self._format_history(self.conversation_history.get(user_id, []))}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">可能的意图类型：</span></span><br><span class="line"><span class="string">1. search - 搜索特定物品（如"我想看动作片"）</span></span><br><span class="line"><span class="string">2. browse - 浏览推荐（如"给我推荐一些电影"）</span></span><br><span class="line"><span class="string">3. clarify - 澄清需求（如"不要太暴力的"）</span></span><br><span class="line"><span class="string">4. compare - 比较物品（如"这两个电影哪个更好"）</span></span><br><span class="line"><span class="string">5. explain - 询问推荐理由（如"为什么推荐这个"）</span></span><br><span class="line"><span class="string">6. feedback - 提供反馈（如"我不喜欢这个"）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">只输出意图类型（search/browse/clarify/compare/explain/feedback），不要输出其他内容。"""</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = self.client.chat.completions.create(</span><br><span class="line">                model=self.model,</span><br><span class="line">                messages=[</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"system"</span>, <span class="string">"content"</span>: <span class="string">"你是一个意图识别系统。"</span>},</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: prompt}</span><br><span class="line">                ],</span><br><span class="line">                temperature=<span class="number">0.1</span>,</span><br><span class="line">                max_tokens=<span class="number">20</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            intent_str = response.choices[<span class="number">0</span>].message.content.strip().lower()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 映射到枚举</span></span><br><span class="line">            intent_map = {</span><br><span class="line">                <span class="string">"search"</span>: UserIntent.SEARCH,</span><br><span class="line">                <span class="string">"browse"</span>: UserIntent.BROWSE,</span><br><span class="line">                <span class="string">"clarify"</span>: UserIntent.CLARIFY,</span><br><span class="line">                <span class="string">"compare"</span>: UserIntent.COMPARE,</span><br><span class="line">                <span class="string">"explain"</span>: UserIntent.EXPLAIN,</span><br><span class="line">                <span class="string">"feedback"</span>: UserIntent.FEEDBACK</span><br><span class="line">            }</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">return</span> intent_map.get(intent_str, UserIntent.BROWSE)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"意图检测错误: <span class="subst">{e}</span>"</span>)</span><br><span class="line">            <span class="keyword">return</span> UserIntent.BROWSE</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_handle_search</span>(<span class="params">self, user_id: <span class="built_in">str</span>, message: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""处理搜索意图"""</span></span><br><span class="line">        <span class="comment"># 提取搜索关键词</span></span><br><span class="line">        prompt = <span class="string">f"""从以下用户消息中提取搜索需求：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">用户消息："<span class="subst">{message}</span>"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">请提取：</span></span><br><span class="line"><span class="string">1. 物品类型（如"电影"、"书籍"）</span></span><br><span class="line"><span class="string">2. 关键词或特征（如"动作片"、"悬疑"）</span></span><br><span class="line"><span class="string">3. 其他约束（如"不要太长"、"评分高的"）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">输出 JSON 格式：</span></span><br><span class="line"><span class="string">{{</span></span><br><span class="line"><span class="string">    "item_type": "...",</span></span><br><span class="line"><span class="string">    "keywords": ["..."],</span></span><br><span class="line"><span class="string">    "constraints": ["..."]</span></span><br><span class="line"><span class="string">}}"""</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = self.client.chat.completions.create(</span><br><span class="line">                model=self.model,</span><br><span class="line">                messages=[</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"system"</span>, <span class="string">"content"</span>: <span class="string">"你是一个需求提取系统。"</span>},</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: prompt}</span><br><span class="line">                ],</span><br><span class="line">                temperature=<span class="number">0.1</span>,</span><br><span class="line">                max_tokens=<span class="number">200</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            content = response.choices[<span class="number">0</span>].message.content.strip()</span><br><span class="line">            <span class="keyword">if</span> <span class="string">"```json"</span> <span class="keyword">in</span> content:</span><br><span class="line">                content = content.split(<span class="string">"```json"</span>)[<span class="number">1</span>].split(<span class="string">"```"</span>)[<span class="number">0</span>].strip()</span><br><span class="line">            </span><br><span class="line">            search_info = json.loads(content)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 更新用户状态</span></span><br><span class="line">            self.user_states[user_id][<span class="string">"context"</span>].update(search_info)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 生成推荐</span></span><br><span class="line">            recommendations = self._generate_recommendations(user_id, search_info)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 格式化响应</span></span><br><span class="line">            response_text = <span class="string">f"根据您的需求，我为您推荐以下内容：\n\n"</span></span><br><span class="line">            <span class="keyword">for</span> i, rec <span class="keyword">in</span> <span class="built_in">enumerate</span>(recommendations[:<span class="number">5</span>], <span class="number">1</span>):</span><br><span class="line">                response_text += <span class="string">f"<span class="subst">{i}</span>. 《<span class="subst">{rec[<span class="string">'item_name'</span>]}</span>》\n"</span></span><br><span class="line">                <span class="keyword">if</span> rec.get(<span class="string">'description'</span>):</span><br><span class="line">                    response_text += <span class="string">f"   <span class="subst">{rec[<span class="string">'description'</span>]}</span>\n"</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">return</span> response_text</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"搜索处理错误: <span class="subst">{e}</span>"</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"抱歉，我理解您的需求时遇到了问题。请再试一次。"</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_handle_browse</span>(<span class="params">self, user_id: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""处理浏览意图"""</span></span><br><span class="line">        <span class="comment"># 基于用户历史生成推荐</span></span><br><span class="line">        user_state = self.user_states[user_id]</span><br><span class="line">        preferences = user_state.get(<span class="string">"preferences"</span>, [])</span><br><span class="line">        </span><br><span class="line">        recommendations = self._generate_recommendations(user_id, {})</span><br><span class="line">        </span><br><span class="line">        response_text = <span class="string">"为您推荐以下内容：\n\n"</span></span><br><span class="line">        <span class="keyword">for</span> i, rec <span class="keyword">in</span> <span class="built_in">enumerate</span>(recommendations[:<span class="number">5</span>], <span class="number">1</span>):</span><br><span class="line">            response_text += <span class="string">f"<span class="subst">{i}</span>. 《<span class="subst">{rec[<span class="string">'item_name'</span>]}</span>》\n"</span></span><br><span class="line">            <span class="keyword">if</span> rec.get(<span class="string">'description'</span>):</span><br><span class="line">                response_text += <span class="string">f"   <span class="subst">{rec[<span class="string">'description'</span>]}</span>\n"</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存当前推荐</span></span><br><span class="line">        self.user_states[user_id][<span class="string">"current_recommendations"</span>] = recommendations[:<span class="number">5</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> response_text</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_handle_clarify</span>(<span class="params">self, user_id: <span class="built_in">str</span>, message: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""处理澄清意图"""</span></span><br><span class="line">        <span class="comment"># 更新用户偏好</span></span><br><span class="line">        user_state = self.user_states[user_id]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 提取澄清信息</span></span><br><span class="line">        prompt = <span class="string">f"""从以下消息中提取用户的偏好或约束：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">用户消息："<span class="subst">{message}</span>"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">输出 JSON 格式：</span></span><br><span class="line"><span class="string">{{</span></span><br><span class="line"><span class="string">    "preferences": ["..."],</span></span><br><span class="line"><span class="string">    "constraints": ["..."]</span></span><br><span class="line"><span class="string">}}"""</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = self.client.chat.completions.create(</span><br><span class="line">                model=self.model,</span><br><span class="line">                messages=[</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"system"</span>, <span class="string">"content"</span>: <span class="string">"你是一个偏好提取系统。"</span>},</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: prompt}</span><br><span class="line">                ],</span><br><span class="line">                temperature=<span class="number">0.1</span>,</span><br><span class="line">                max_tokens=<span class="number">200</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            content = response.choices[<span class="number">0</span>].message.content.strip()</span><br><span class="line">            <span class="keyword">if</span> <span class="string">"```json"</span> <span class="keyword">in</span> content:</span><br><span class="line">                content = content.split(<span class="string">"```json"</span>)[<span class="number">1</span>].split(<span class="string">"```"</span>)[<span class="number">0</span>].strip()</span><br><span class="line">            </span><br><span class="line">            clarify_info = json.loads(content)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 更新偏好</span></span><br><span class="line">            user_state[<span class="string">"preferences"</span>].extend(clarify_info.get(<span class="string">"preferences"</span>, []))</span><br><span class="line">            user_state[<span class="string">"context"</span>].update(clarify_info)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 重新生成推荐</span></span><br><span class="line">            recommendations = self._generate_recommendations(user_id, user_state[<span class="string">"context"</span>])</span><br><span class="line">            </span><br><span class="line">            response_text = <span class="string">"好的，我理解了您的偏好。根据更新后的需求，为您推荐：\n\n"</span></span><br><span class="line">            <span class="keyword">for</span> i, rec <span class="keyword">in</span> <span class="built_in">enumerate</span>(recommendations[:<span class="number">5</span>], <span class="number">1</span>):</span><br><span class="line">                response_text += <span class="string">f"<span class="subst">{i}</span>. 《<span class="subst">{rec[<span class="string">'item_name'</span>]}</span>》\n"</span></span><br><span class="line">            </span><br><span class="line">            self.user_states[user_id][<span class="string">"current_recommendations"</span>] = recommendations[:<span class="number">5</span>]</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">return</span> response_text</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"澄清处理错误: <span class="subst">{e}</span>"</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"好的，我已经记下了您的偏好。"</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_handle_explain</span>(<span class="params">self, user_id: <span class="built_in">str</span>, message: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""处理解释意图"""</span></span><br><span class="line">        current_recs = self.user_states[user_id].get(<span class="string">"current_recommendations"</span>, [])</span><br><span class="line">        preferences = self.user_states[user_id].get(<span class="string">"preferences"</span>, [])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> current_recs:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"目前没有正在推荐的物品。请先让我为您推荐一些内容。"</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 生成解释</span></span><br><span class="line">        prompt = <span class="string">f"""用户偏好：</span></span><br><span class="line"><span class="string"><span class="subst">{json.dumps(preferences, ensure_ascii=<span class="literal">False</span>)}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">当前推荐：</span></span><br><span class="line"><span class="string"><span class="subst">{json.dumps(current_recs[:<span class="number">3</span>], ensure_ascii=<span class="literal">False</span>, indent=<span class="number">2</span>)}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">请解释为什么推荐这些物品。说明：</span></span><br><span class="line"><span class="string">1. 与用户偏好的关联</span></span><br><span class="line"><span class="string">2. 每个推荐的特点</span></span><br><span class="line"><span class="string">3. 为什么用户可能会喜欢</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">用自然语言回答，100-200字。"""</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = self.client.chat.completions.create(</span><br><span class="line">                model=self.model,</span><br><span class="line">                messages=[</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"system"</span>, <span class="string">"content"</span>: <span class="string">"你是一个推荐解释生成器。"</span>},</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: prompt}</span><br><span class="line">                ],</span><br><span class="line">                temperature=<span class="number">0.7</span>,</span><br><span class="line">                max_tokens=<span class="number">500</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            explanation = response.choices[<span class="number">0</span>].message.content.strip()</span><br><span class="line">            <span class="keyword">return</span> explanation</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"解释生成错误: <span class="subst">{e}</span>"</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"这些推荐是基于您的历史偏好和当前需求生成的。"</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_handle_feedback</span>(<span class="params">self, user_id: <span class="built_in">str</span>, message: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""处理反馈"""</span></span><br><span class="line">        <span class="comment"># 提取反馈信息</span></span><br><span class="line">        prompt = <span class="string">f"""从以下消息中提取用户的反馈：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">用户消息："<span class="subst">{message}</span>"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">判断：</span></span><br><span class="line"><span class="string">1. 是正面反馈（喜欢）还是负面反馈（不喜欢）</span></span><br><span class="line"><span class="string">2. 针对哪个物品（如果有）</span></span><br><span class="line"><span class="string">3. 具体原因（如果有）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">输出 JSON：</span></span><br><span class="line"><span class="string">{{</span></span><br><span class="line"><span class="string">    "sentiment": "positive/negative",</span></span><br><span class="line"><span class="string">    "item_name": "...",</span></span><br><span class="line"><span class="string">    "reason": "..."</span></span><br><span class="line"><span class="string">}}"""</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = self.client.chat.completions.create(</span><br><span class="line">                model=self.model,</span><br><span class="line">                messages=[</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"system"</span>, <span class="string">"content"</span>: <span class="string">"你是一个反馈分析系统。"</span>},</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: prompt}</span><br><span class="line">                ],</span><br><span class="line">                temperature=<span class="number">0.1</span>,</span><br><span class="line">                max_tokens=<span class="number">200</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            content = response.choices[<span class="number">0</span>].message.content.strip()</span><br><span class="line">            <span class="keyword">if</span> <span class="string">"```json"</span> <span class="keyword">in</span> content:</span><br><span class="line">                content = content.split(<span class="string">"```json"</span>)[<span class="number">1</span>].split(<span class="string">"```"</span>)[<span class="number">0</span>].strip()</span><br><span class="line">            </span><br><span class="line">            feedback = json.loads(content)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 更新用户偏好</span></span><br><span class="line">            <span class="keyword">if</span> feedback.get(<span class="string">"sentiment"</span>) == <span class="string">"positive"</span>:</span><br><span class="line">                <span class="keyword">if</span> feedback.get(<span class="string">"item_name"</span>):</span><br><span class="line">                    self.user_states[user_id][<span class="string">"preferences"</span>].append({</span><br><span class="line">                        <span class="string">"item"</span>: feedback[<span class="string">"item_name"</span>],</span><br><span class="line">                        <span class="string">"type"</span>: <span class="string">"liked"</span></span><br><span class="line">                    })</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> feedback.get(<span class="string">"item_name"</span>):</span><br><span class="line">                    self.user_states[user_id][<span class="string">"preferences"</span>].append({</span><br><span class="line">                        <span class="string">"item"</span>: feedback[<span class="string">"item_name"</span>],</span><br><span class="line">                        <span class="string">"type"</span>: <span class="string">"disliked"</span></span><br><span class="line">                    })</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">return</span> <span class="string">"谢谢您的反馈！我会根据您的意见调整推荐。"</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"反馈处理错误: <span class="subst">{e}</span>"</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"谢谢您的反馈！"</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_handle_compare</span>(<span class="params">self, user_id: <span class="built_in">str</span>, message: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""处理比较意图"""</span></span><br><span class="line">        <span class="comment"># 提取要比较的物品</span></span><br><span class="line">        current_recs = self.user_states[user_id].get(<span class="string">"current_recommendations"</span>, [])</span><br><span class="line">        </span><br><span class="line">        prompt = <span class="string">f"""从以下消息中提取用户要比较的物品：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">用户消息："<span class="subst">{message}</span>"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">当前推荐：</span></span><br><span class="line"><span class="string"><span class="subst">{json.dumps(current_recs, ensure_ascii=<span class="literal">False</span>, indent=<span class="number">2</span>)}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">输出要比较的物品名称列表（JSON数组）。"""</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = self.client.chat.completions.create(</span><br><span class="line">                model=self.model,</span><br><span class="line">                messages=[</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"system"</span>, <span class="string">"content"</span>: <span class="string">"你是一个物品提取系统。"</span>},</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: prompt}</span><br><span class="line">                ],</span><br><span class="line">                temperature=<span class="number">0.1</span>,</span><br><span class="line">                max_tokens=<span class="number">100</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            content = response.choices[<span class="number">0</span>].message.content.strip()</span><br><span class="line">            <span class="keyword">if</span> <span class="string">"["</span> <span class="keyword">in</span> content:</span><br><span class="line">                items = json.loads(content)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                items = [content]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 生成比较</span></span><br><span class="line">            comparison_prompt = <span class="string">f"""请比较以下物品：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"><span class="subst">{json.dumps(items, ensure_ascii=<span class="literal">False</span>)}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">从以下角度比较：</span></span><br><span class="line"><span class="string">1. 类型和风格</span></span><br><span class="line"><span class="string">2. 适合的观众</span></span><br><span class="line"><span class="string">3. 优缺点</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">用自然语言回答，150-250字。"""</span></span><br><span class="line">            </span><br><span class="line">            comp_response = self.client.chat.completions.create(</span><br><span class="line">                model=self.model,</span><br><span class="line">                messages=[</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"system"</span>, <span class="string">"content"</span>: <span class="string">"你是一个物品比较系统。"</span>},</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: comparison_prompt}</span><br><span class="line">                ],</span><br><span class="line">                temperature=<span class="number">0.7</span>,</span><br><span class="line">                max_tokens=<span class="number">500</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            comparison = comp_response.choices[<span class="number">0</span>].message.content.strip()</span><br><span class="line">            <span class="keyword">return</span> comparison</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"比较处理错误: <span class="subst">{e}</span>"</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"抱歉，我无法比较这些物品。"</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_handle_general</span>(<span class="params">self, user_id: <span class="built_in">str</span>, message: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""处理一般消息"""</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">"我是您的推荐助手。您可以：\n1. 搜索特定内容\n2. 浏览推荐\n3. 询问推荐理由\n4. 提供反馈\n\n请告诉我您需要什么帮助？"</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_generate_recommendations</span>(<span class="params">self, user_id: <span class="built_in">str</span>, context: <span class="type">Dict</span></span>) -&gt; <span class="type">List</span>[<span class="type">Dict</span>]:</span><br><span class="line">        <span class="string">"""生成推荐（简化版，实际应该调用推荐模型）"""</span></span><br><span class="line">        <span class="comment"># 这里是示例，实际应该调用真实的推荐模型</span></span><br><span class="line">        <span class="keyword">return</span> [</span><br><span class="line">            {<span class="string">"item_name"</span>: <span class="string">"示例电影1"</span>, <span class="string">"description"</span>: <span class="string">"示例描述1"</span>},</span><br><span class="line">            {<span class="string">"item_name"</span>: <span class="string">"示例电影2"</span>, <span class="string">"description"</span>: <span class="string">"示例描述2"</span>},</span><br><span class="line">            {<span class="string">"item_name"</span>: <span class="string">"示例电影3"</span>, <span class="string">"description"</span>: <span class="string">"示例描述3"</span>}</span><br><span class="line">        ]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_format_history</span>(<span class="params">self, history: <span class="type">List</span>[<span class="type">Dict</span>], max_turns: <span class="built_in">int</span> = <span class="number">5</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""格式化对话历史"""</span></span><br><span class="line">        recent_history = history[-max_turns * <span class="number">2</span>:]  <span class="comment"># 最近几轮</span></span><br><span class="line">        history_str = <span class="string">""</span></span><br><span class="line">        <span class="keyword">for</span> msg <span class="keyword">in</span> recent_history:</span><br><span class="line">            role = msg[<span class="string">"role"</span>]</span><br><span class="line">            content = msg[<span class="string">"content"</span>]</span><br><span class="line">            history_str += <span class="string">f"<span class="subst">{role}</span>: <span class="subst">{content}</span>\n"</span></span><br><span class="line">        <span class="keyword">return</span> history_str</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用示例</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    chatrec = ChatREC()</span><br><span class="line">    </span><br><span class="line">    user_id = <span class="string">"user123"</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 第一轮：浏览推荐</span></span><br><span class="line">    response1 = chatrec.chat(user_id, <span class="string">"给我推荐一些电影"</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"系统: <span class="subst">{response1}</span>\n"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 第二轮：澄清需求</span></span><br><span class="line">    response2 = chatrec.chat(user_id, <span class="string">"我想要感人的剧情片"</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"系统: <span class="subst">{response2}</span>\n"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 第三轮：询问理由</span></span><br><span class="line">    response3 = chatrec.chat(user_id, <span class="string">"为什么推荐这些？"</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"系统: <span class="subst">{response3}</span>\n"</span>)</span><br></pre></td></tr></table></figure>
<p>ChatREC
实现了自然语言交互的推荐系统，大大提升了用户体验和系统的灵活性。</p>
<h2 id="ra-rec检索增强的推荐架构">RA-Rec：检索增强的推荐架构</h2>
<p>RA-Rec（Retrieval-Augmented
Recommendation）结合了检索和生成的优势。它使用检索模块快速找到相关候选，然后使用
LLM 进行精细排序和解释生成。</p>
<h3 id="架构设计-4">架构设计</h3>
<p>RA-Rec 包含以下组件：</p>
<ol type="1">
<li><strong>检索模块</strong>：使用向量检索快速找到相关候选</li>
<li><strong>LLM 排序器</strong>：对检索结果进行精细排序</li>
<li><strong>解释生成器</strong>：生成推荐理由</li>
</ol>
<h3 id="实现代码-5">实现代码</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Dict</span>, <span class="type">Tuple</span></span><br><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer</span><br><span class="line"><span class="keyword">import</span> faiss</span><br><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RARec</span>:</span><br><span class="line">    <span class="string">"""检索增强的推荐系统"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        embedding_model: <span class="built_in">str</span> = <span class="string">"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"</span>,</span></span><br><span class="line"><span class="params">        llm_model: <span class="built_in">str</span> = <span class="string">"gpt-3.5-turbo"</span></span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            embedding_model: 用于检索的嵌入模型</span></span><br><span class="line"><span class="string">            llm_model: 用于排序和解释的 LLM 模型</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 初始化嵌入模型</span></span><br><span class="line">        self.embedding_model = SentenceTransformer(embedding_model)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 初始化 LLM</span></span><br><span class="line">        self.llm_client = OpenAI(api_key=os.getenv(<span class="string">"OPENAI_API_KEY"</span>))</span><br><span class="line">        self.llm_model = llm_model</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 物品索引</span></span><br><span class="line">        self.item_index = <span class="literal">None</span></span><br><span class="line">        self.items = []</span><br><span class="line">        self.item_embeddings = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">build_index</span>(<span class="params">self, items: <span class="type">List</span>[<span class="type">Dict</span>]</span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        构建物品索引</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            items: 物品列表，每个物品包含 text, item_id 等字段</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.items = items</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 提取物品文本</span></span><br><span class="line">        texts = []</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">            text_parts = []</span><br><span class="line">            <span class="keyword">if</span> <span class="string">'title'</span> <span class="keyword">in</span> item:</span><br><span class="line">                text_parts.append(item[<span class="string">'title'</span>])</span><br><span class="line">            <span class="keyword">if</span> <span class="string">'description'</span> <span class="keyword">in</span> item:</span><br><span class="line">                text_parts.append(item[<span class="string">'description'</span>])</span><br><span class="line">            <span class="keyword">if</span> <span class="string">'category'</span> <span class="keyword">in</span> item:</span><br><span class="line">                text_parts.append(item[<span class="string">'category'</span>])</span><br><span class="line">            text = <span class="string">" | "</span>.join(text_parts)</span><br><span class="line">            texts.append(text)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 生成嵌入</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"生成物品嵌入..."</span>)</span><br><span class="line">        self.item_embeddings = self.embedding_model.encode(texts, show_progress_bar=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 构建 FAISS 索引</span></span><br><span class="line">        dimension = self.item_embeddings.shape[<span class="number">1</span>]</span><br><span class="line">        self.item_index = faiss.IndexFlatIP(dimension)  <span class="comment"># 内积索引（用于余弦相似度）</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 归一化嵌入（用于余弦相似度）</span></span><br><span class="line">        faiss.normalize_L2(self.item_embeddings)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 添加向量到索引</span></span><br><span class="line">        self.item_index.add(self.item_embeddings.astype(<span class="string">'float32'</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"索引构建完成，包含 <span class="subst">{<span class="built_in">len</span>(items)}</span> 个物品"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">retrieve</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        query: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">        top_k: <span class="built_in">int</span> = <span class="number">50</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="type">List</span>[<span class="type">Dict</span>]:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        检索相关物品</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            query: 查询文本（用户需求或历史偏好）</span></span><br><span class="line"><span class="string">            top_k: 检索数量</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            检索到的物品列表</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> self.item_index <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"请先调用 build_index() 构建索引"</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 生成查询嵌入</span></span><br><span class="line">        query_embedding = self.embedding_model.encode([query])</span><br><span class="line">        faiss.normalize_L2(query_embedding)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 检索</span></span><br><span class="line">        distances, indices = self.item_index.search(</span><br><span class="line">            query_embedding.astype(<span class="string">'float32'</span>),</span><br><span class="line">            top_k</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 构建结果</span></span><br><span class="line">        results = []</span><br><span class="line">        <span class="keyword">for</span> idx, dist <span class="keyword">in</span> <span class="built_in">zip</span>(indices[<span class="number">0</span>], distances[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">if</span> idx &lt; <span class="built_in">len</span>(self.items):</span><br><span class="line">                item = self.items[idx].copy()</span><br><span class="line">                item[<span class="string">'retrieval_score'</span>] = <span class="built_in">float</span>(dist)</span><br><span class="line">                results.append(item)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> results</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">rerank_with_llm</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        user_context: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">        candidates: <span class="type">List</span>[<span class="type">Dict</span>],</span></span><br><span class="line"><span class="params">        top_n: <span class="built_in">int</span> = <span class="number">10</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="type">List</span>[<span class="type">Dict</span>]:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        使用 LLM 对检索结果进行重排序</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_context: 用户上下文（历史偏好、当前需求等）</span></span><br><span class="line"><span class="string">            candidates: 候选物品列表</span></span><br><span class="line"><span class="string">            top_n: 最终推荐数量</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            重排序后的物品列表</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 格式化候选</span></span><br><span class="line">        candidates_str = <span class="string">""</span></span><br><span class="line">        <span class="keyword">for</span> i, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(candidates[:<span class="number">30</span>], <span class="number">1</span>):  <span class="comment"># 限制候选数量</span></span><br><span class="line">            candidates_str += <span class="string">f"<span class="subst">{i}</span>. 《<span class="subst">{item.get(<span class="string">'title'</span>, <span class="string">'未知'</span>)}</span>》"</span></span><br><span class="line">            <span class="keyword">if</span> item.get(<span class="string">'description'</span>):</span><br><span class="line">                candidates_str += <span class="string">f" - <span class="subst">{item[<span class="string">'description'</span>][:<span class="number">100</span>]}</span>"</span></span><br><span class="line">            candidates_str += <span class="string">f" (检索分数: <span class="subst">{item.get(<span class="string">'retrieval_score'</span>, <span class="number">0</span>):<span class="number">.3</span>f}</span>)\n"</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 构建 Prompt</span></span><br><span class="line">        prompt = <span class="string">f"""用户上下文：</span></span><br><span class="line"><span class="string"><span class="subst">{user_context}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">检索到的候选物品：</span></span><br><span class="line"><span class="string"><span class="subst">{candidates_str}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">请根据用户上下文，对这些候选物品进行排序。考虑：</span></span><br><span class="line"><span class="string">1. 与用户需求的匹配度</span></span><br><span class="line"><span class="string">2. 物品的质量和相关性</span></span><br><span class="line"><span class="string">3. 多样性（避免推荐过于相似的内容）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">输出排序后的物品编号列表（JSON格式）：</span></span><br><span class="line"><span class="string">{{</span></span><br><span class="line"><span class="string">    "ranking": [1, 5, 3, ...]</span></span><br><span class="line"><span class="string">}}</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">只输出 JSON，不要输出其他内容。"""</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = self.llm_client.chat.completions.create(</span><br><span class="line">                model=self.llm_model,</span><br><span class="line">                messages=[</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"system"</span>, <span class="string">"content"</span>: <span class="string">"你是一个专业的推荐排序器。"</span>},</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: prompt}</span><br><span class="line">                ],</span><br><span class="line">                temperature=<span class="number">0.1</span>,</span><br><span class="line">                max_tokens=<span class="number">500</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            content = response.choices[<span class="number">0</span>].message.content.strip()</span><br><span class="line">            <span class="keyword">if</span> <span class="string">"```json"</span> <span class="keyword">in</span> content:</span><br><span class="line">                content = content.split(<span class="string">"```json"</span>)[<span class="number">1</span>].split(<span class="string">"```"</span>)[<span class="number">0</span>].strip()</span><br><span class="line">            </span><br><span class="line">            result = json.loads(content)</span><br><span class="line">            ranking = result.get(<span class="string">"ranking"</span>, [])</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 按排序结果重新组织</span></span><br><span class="line">            reranked = []</span><br><span class="line">            <span class="keyword">for</span> rank <span class="keyword">in</span> ranking[:top_n]:</span><br><span class="line">                <span class="keyword">if</span> <span class="number">1</span> &lt;= rank &lt;= <span class="built_in">len</span>(candidates):</span><br><span class="line">                    reranked.append(candidates[rank - <span class="number">1</span>])</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 如果 LLM 排序结果不足，补充剩余的候选</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(reranked) &lt; top_n:</span><br><span class="line">                remaining = [c <span class="keyword">for</span> c <span class="keyword">in</span> candidates <span class="keyword">if</span> c <span class="keyword">not</span> <span class="keyword">in</span> reranked]</span><br><span class="line">                reranked.extend(remaining[:top_n - <span class="built_in">len</span>(reranked)])</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">return</span> reranked</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"LLM 重排序错误: <span class="subst">{e}</span>"</span>)</span><br><span class="line">            <span class="comment"># 降级到按检索分数排序</span></span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">sorted</span>(candidates, key=<span class="keyword">lambda</span> x: x.get(<span class="string">'retrieval_score'</span>, <span class="number">0</span>), reverse=<span class="literal">True</span>)[:top_n]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">recommend</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        user_query: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">        user_history: <span class="type">List</span>[<span class="type">Dict</span>] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">        top_n: <span class="built_in">int</span> = <span class="number">10</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="type">List</span>[<span class="type">Dict</span>]:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        完整的推荐流程：检索 + LLM 重排序</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_query: 用户查询</span></span><br><span class="line"><span class="string">            user_history: 用户历史行为（可选）</span></span><br><span class="line"><span class="string">            top_n: 推荐数量</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            推荐结果列表</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 构建用户上下文</span></span><br><span class="line">        context_parts = [<span class="string">f"当前需求：<span class="subst">{user_query}</span>"</span>]</span><br><span class="line">        <span class="keyword">if</span> user_history:</span><br><span class="line">            history_str = <span class="string">"历史偏好：\n"</span></span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> user_history[:<span class="number">10</span>]:</span><br><span class="line">                history_str += <span class="string">f"- 《<span class="subst">{item.get(<span class="string">'item_name'</span>, <span class="string">'未知'</span>)}</span>》\n"</span></span><br><span class="line">            context_parts.append(history_str)</span><br><span class="line">        user_context = <span class="string">"\n"</span>.join(context_parts)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 检索</span></span><br><span class="line">        retrieved = self.retrieve(user_query, top_k=<span class="number">50</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># LLM 重排序</span></span><br><span class="line">        reranked = self.rerank_with_llm(user_context, retrieved, top_n)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> reranked</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">explain_recommendation</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        user_context: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">        recommended_item: <span class="type">Dict</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""生成推荐解释"""</span></span><br><span class="line">        prompt = <span class="string">f"""用户上下文：</span></span><br><span class="line"><span class="string"><span class="subst">{user_context}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">推荐物品：</span></span><br><span class="line"><span class="string">- 名称：《<span class="subst">{recommended_item.get(<span class="string">'title'</span>, <span class="string">'未知'</span>)}</span>》</span></span><br><span class="line"><span class="string">- 描述：<span class="subst">{recommended_item.get(<span class="string">'description'</span>, <span class="string">''</span>)}</span></span></span><br><span class="line"><span class="string">- 类别：<span class="subst">{recommended_item.get(<span class="string">'category'</span>, <span class="string">''</span>)}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">请生成一段100-150字的推荐解释，说明为什么推荐这个物品。"""</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = self.llm_client.chat.completions.create(</span><br><span class="line">                model=self.llm_model,</span><br><span class="line">                messages=[</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"system"</span>, <span class="string">"content"</span>: <span class="string">"你是一个推荐解释生成器。"</span>},</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: prompt}</span><br><span class="line">                ],</span><br><span class="line">                temperature=<span class="number">0.7</span>,</span><br><span class="line">                max_tokens=<span class="number">300</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            explanation = response.choices[<span class="number">0</span>].message.content.strip()</span><br><span class="line">            <span class="keyword">return</span> explanation</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"解释生成错误: <span class="subst">{e}</span>"</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"基于您的偏好，我们为您推荐了这个物品。"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用示例</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># 初始化系统</span></span><br><span class="line">    rarec = RARec()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 构建索引</span></span><br><span class="line">    items = [</span><br><span class="line">        {<span class="string">"item_id"</span>: <span class="number">1</span>, <span class="string">"title"</span>: <span class="string">"肖申克的救赎"</span>, <span class="string">"description"</span>: <span class="string">"关于希望和友谊的经典"</span>, <span class="string">"category"</span>: <span class="string">"剧情"</span>},</span><br><span class="line">        {<span class="string">"item_id"</span>: <span class="number">2</span>, <span class="string">"title"</span>: <span class="string">"阿甘正传"</span>, <span class="string">"description"</span>: <span class="string">"智障人士的传奇人生"</span>, <span class="string">"category"</span>: <span class="string">"剧情"</span>},</span><br><span class="line">        <span class="comment"># ... 更多物品</span></span><br><span class="line">    ]</span><br><span class="line">    rarec.build_index(items)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 推荐</span></span><br><span class="line">    recommendations = rarec.recommend(</span><br><span class="line">        user_query=<span class="string">"我想看感人的剧情片"</span>,</span><br><span class="line">        user_history=[</span><br><span class="line">            {<span class="string">"item_name"</span>: <span class="string">"当幸福来敲门"</span>}</span><br><span class="line">        ],</span><br><span class="line">        top_n=<span class="number">5</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"推荐结果："</span>)</span><br><span class="line">    <span class="keyword">for</span> i, rec <span class="keyword">in</span> <span class="built_in">enumerate</span>(recommendations, <span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"<span class="subst">{i}</span>. 《<span class="subst">{rec[<span class="string">'title'</span>]}</span>》"</span>)</span><br><span class="line">        explanation = rarec.explain_recommendation(</span><br><span class="line">            <span class="string">"我想看感人的剧情片"</span>,</span><br><span class="line">            rec</span><br><span class="line">        )</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"   理由：<span class="subst">{explanation}</span>\n"</span>)</span><br></pre></td></tr></table></figure>
<p>RA-Rec 结合了检索的高效性和 LLM
的语义理解能力，在效果和效率之间取得了平衡。</p>
<h2 id="chatcrs对话式推荐系统框架">ChatCRS：对话式推荐系统框架</h2>
<p>ChatCRS（Chat-based Conversational Recommendation
System）是一个完整的对话式推荐系统框架，集成了意图理解、推荐生成、解释生成等功能。</p>
<h3 id="架构特点">架构特点</h3>
<p>ChatCRS 的特点：</p>
<ol type="1">
<li><strong>多轮对话管理</strong>：维护对话状态和历史</li>
<li><strong>混合推荐策略</strong>：结合多种推荐方法</li>
<li><strong>自然语言生成</strong>：生成流畅的对话响应</li>
<li><strong>个性化适应</strong>：根据用户反馈调整推荐</li>
</ol>
<h3 id="核心实现">核心实现</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Dict</span>, <span class="type">Optional</span></span><br><span class="line"><span class="keyword">from</span> dataclasses <span class="keyword">import</span> dataclass</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConversationTurn</span>:</span><br><span class="line">    <span class="string">"""对话轮次"""</span></span><br><span class="line">    user_message: <span class="built_in">str</span></span><br><span class="line">    system_response: <span class="built_in">str</span></span><br><span class="line">    intent: <span class="built_in">str</span></span><br><span class="line">    timestamp: datetime</span><br><span class="line">    recommendations: <span class="type">List</span>[<span class="type">Dict</span>] = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatCRS</span>:</span><br><span class="line">    <span class="string">"""对话式推荐系统框架"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.conversations: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">List</span>[ConversationTurn]] = {}</span><br><span class="line">        self.user_profiles: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Dict</span>] = {}</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_message</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        user_id: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">        message: <span class="built_in">str</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="type">Dict</span>:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        处理用户消息</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            包含响应、推荐、解释等的字典</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 初始化用户会话</span></span><br><span class="line">        <span class="keyword">if</span> user_id <span class="keyword">not</span> <span class="keyword">in</span> self.conversations:</span><br><span class="line">            self.conversations[user_id] = []</span><br><span class="line">            self.user_profiles[user_id] = {</span><br><span class="line">                <span class="string">"preferences"</span>: [],</span><br><span class="line">                <span class="string">"history"</span>: [],</span><br><span class="line">                <span class="string">"feedback"</span>: []</span><br><span class="line">            }</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 理解意图</span></span><br><span class="line">        intent = self._understand_intent(user_id, message)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 更新用户状态</span></span><br><span class="line">        self._update_user_state(user_id, message, intent)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 生成推荐</span></span><br><span class="line">        recommendations = self._generate_recommendations(user_id, intent)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 生成响应</span></span><br><span class="line">        response = self._generate_response(user_id, message, intent, recommendations)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 生成解释</span></span><br><span class="line">        explanations = self._generate_explanations(user_id, recommendations)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 记录对话</span></span><br><span class="line">        turn = ConversationTurn(</span><br><span class="line">            user_message=message,</span><br><span class="line">            system_response=response,</span><br><span class="line">            intent=intent,</span><br><span class="line">            timestamp=datetime.now(),</span><br><span class="line">            recommendations=recommendations</span><br><span class="line">        )</span><br><span class="line">        self.conversations[user_id].append(turn)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> {</span><br><span class="line">            <span class="string">"response"</span>: response,</span><br><span class="line">            <span class="string">"recommendations"</span>: recommendations,</span><br><span class="line">            <span class="string">"explanations"</span>: explanations,</span><br><span class="line">            <span class="string">"intent"</span>: intent</span><br><span class="line">        }</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_understand_intent</span>(<span class="params">self, user_id: <span class="built_in">str</span>, message: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""理解用户意图（简化版）"""</span></span><br><span class="line">        <span class="comment"># 实际应该使用 LLM 或分类器</span></span><br><span class="line">        message_lower = message.lower()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">any</span>(word <span class="keyword">in</span> message_lower <span class="keyword">for</span> word <span class="keyword">in</span> [<span class="string">"推荐"</span>, <span class="string">"给我"</span>, <span class="string">"想看"</span>]):</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"browse"</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">any</span>(word <span class="keyword">in</span> message_lower <span class="keyword">for</span> word <span class="keyword">in</span> [<span class="string">"搜索"</span>, <span class="string">"找"</span>, <span class="string">"找找"</span>]):</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"search"</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">any</span>(word <span class="keyword">in</span> message_lower <span class="keyword">for</span> word <span class="keyword">in</span> [<span class="string">"为什么"</span>, <span class="string">"理由"</span>, <span class="string">"原因"</span>]):</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"explain"</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">any</span>(word <span class="keyword">in</span> message_lower <span class="keyword">for</span> word <span class="keyword">in</span> [<span class="string">"不喜欢"</span>, <span class="string">"讨厌"</span>, <span class="string">"不感兴趣"</span>]):</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"negative_feedback"</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">any</span>(word <span class="keyword">in</span> message_lower <span class="keyword">for</span> word <span class="keyword">in</span> [<span class="string">"喜欢"</span>, <span class="string">"不错"</span>, <span class="string">"很好"</span>]):</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"positive_feedback"</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"general"</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_update_user_state</span>(<span class="params">self, user_id: <span class="built_in">str</span>, message: <span class="built_in">str</span>, intent: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="string">"""更新用户状态"""</span></span><br><span class="line">        profile = self.user_profiles[user_id]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> intent == <span class="string">"positive_feedback"</span>:</span><br><span class="line">            <span class="comment"># 提取喜欢的物品</span></span><br><span class="line">            profile[<span class="string">"preferences"</span>].append({</span><br><span class="line">                <span class="string">"type"</span>: <span class="string">"liked"</span>,</span><br><span class="line">                <span class="string">"message"</span>: message,</span><br><span class="line">                <span class="string">"timestamp"</span>: datetime.now()</span><br><span class="line">            })</span><br><span class="line">        <span class="keyword">elif</span> intent == <span class="string">"negative_feedback"</span>:</span><br><span class="line">            profile[<span class="string">"preferences"</span>].append({</span><br><span class="line">                <span class="string">"type"</span>: <span class="string">"disliked"</span>,</span><br><span class="line">                <span class="string">"message"</span>: message,</span><br><span class="line">                <span class="string">"timestamp"</span>: datetime.now()</span><br><span class="line">            })</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_generate_recommendations</span>(<span class="params">self, user_id: <span class="built_in">str</span>, intent: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="type">Dict</span>]:</span><br><span class="line">        <span class="string">"""生成推荐（简化版）"""</span></span><br><span class="line">        <span class="comment"># 实际应该调用推荐模型</span></span><br><span class="line">        <span class="keyword">return</span> [</span><br><span class="line">            {<span class="string">"item_id"</span>: <span class="number">1</span>, <span class="string">"item_name"</span>: <span class="string">"示例1"</span>, <span class="string">"score"</span>: <span class="number">0.9</span>},</span><br><span class="line">            {<span class="string">"item_id"</span>: <span class="number">2</span>, <span class="string">"item_name"</span>: <span class="string">"示例2"</span>, <span class="string">"score"</span>: <span class="number">0.85</span>},</span><br><span class="line">            {<span class="string">"item_id"</span>: <span class="number">3</span>, <span class="string">"item_name"</span>: <span class="string">"示例3"</span>, <span class="string">"score"</span>: <span class="number">0.8</span>}</span><br><span class="line">        ]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_generate_response</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        user_id: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">        message: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">        intent: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">        recommendations: <span class="type">List</span>[<span class="type">Dict</span>]</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""生成系统响应"""</span></span><br><span class="line">        <span class="keyword">if</span> intent == <span class="string">"browse"</span>:</span><br><span class="line">            response = <span class="string">"为您推荐以下内容：\n\n"</span></span><br><span class="line">            <span class="keyword">for</span> i, rec <span class="keyword">in</span> <span class="built_in">enumerate</span>(recommendations[:<span class="number">5</span>], <span class="number">1</span>):</span><br><span class="line">                response += <span class="string">f"<span class="subst">{i}</span>. 《<span class="subst">{rec[<span class="string">'item_name'</span>]}</span>》\n"</span></span><br><span class="line">            <span class="keyword">return</span> response</span><br><span class="line">        <span class="keyword">elif</span> intent == <span class="string">"search"</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">f"根据您的需求，我找到了以下相关内容：\n\n"</span> + \</span><br><span class="line">                   <span class="string">"\n"</span>.join([<span class="string">f"<span class="subst">{i}</span>. 《<span class="subst">{r[<span class="string">'item_name'</span>]}</span>》"</span> <span class="keyword">for</span> i, r <span class="keyword">in</span> <span class="built_in">enumerate</span>(recommendations[:<span class="number">5</span>], <span class="number">1</span>)])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"我理解您的需求，正在为您处理..."</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_generate_explanations</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        user_id: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">        recommendations: <span class="type">List</span>[<span class="type">Dict</span>]</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span><br><span class="line">        <span class="string">"""生成推荐解释"""</span></span><br><span class="line">        <span class="comment"># 实际应该使用 LLM 生成</span></span><br><span class="line">        <span class="keyword">return</span> [<span class="string">f"推荐《<span class="subst">{r[<span class="string">'item_name'</span>]}</span>》是因为它符合您的偏好。"</span> <span class="keyword">for</span> r <span class="keyword">in</span> recommendations]</span><br></pre></td></tr></table></figure>
<p>ChatCRS
提供了一个完整的对话式推荐框架，可以根据具体需求进行扩展和定制。</p>
<h2 id="token-效率优化">Token 效率优化</h2>
<p>LLM 在推荐系统中的应用面临一个关键挑战：Token 消耗。每次调用 LLM
都需要消耗大量 Token，成本高昂。我们需要优化策略来减少 Token 使用。</p>
<h3 id="优化策略">优化策略</h3>
<p><strong>1. 文本摘要</strong></p>
<p>对于长文本（如物品描述、用户评论），先进行摘要再输入 LLM：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">summarize_text</span>(<span class="params">text: <span class="built_in">str</span>, max_length: <span class="built_in">int</span> = <span class="number">100</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">"""摘要文本"""</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(text) &lt;= max_length:</span><br><span class="line">        <span class="keyword">return</span> text</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 使用 LLM 摘要（或简单的截断）</span></span><br><span class="line">    <span class="comment"># 这里简化处理</span></span><br><span class="line">    sentences = text.split(<span class="string">'。'</span>)</span><br><span class="line">    summary = <span class="string">""</span></span><br><span class="line">    <span class="keyword">for</span> sent <span class="keyword">in</span> sentences:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(summary) + <span class="built_in">len</span>(sent) &lt;= max_length:</span><br><span class="line">            summary += sent + <span class="string">"。"</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> summary <span class="keyword">if</span> summary <span class="keyword">else</span> text[:max_length] + <span class="string">"..."</span></span><br></pre></td></tr></table></figure>
<p><strong>2. 批量处理</strong></p>
<p>将多个请求合并为批量请求，减少 API 调用次数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">batch_recommend</span>(<span class="params">queries: <span class="type">List</span>[<span class="built_in">str</span>], batch_size: <span class="built_in">int</span> = <span class="number">10</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="type">Dict</span>]]:</span><br><span class="line">    <span class="string">"""批量推荐"""</span></span><br><span class="line">    results = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(queries), batch_size):</span><br><span class="line">        batch_queries = queries[i:i+batch_size]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 构建批量 Prompt</span></span><br><span class="line">        batch_prompt = <span class="string">"请为以下用户生成推荐：\n\n"</span></span><br><span class="line">        <span class="keyword">for</span> j, query <span class="keyword">in</span> <span class="built_in">enumerate</span>(batch_queries):</span><br><span class="line">            batch_prompt += <span class="string">f"用户<span class="subst">{j+<span class="number">1</span>}</span>: <span class="subst">{query}</span>\n"</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 调用 LLM（需要支持批量输出）</span></span><br><span class="line">        <span class="comment"># ...</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>
<p><strong>3. 缓存机制</strong></p>
<p>缓存常见查询的结果，避免重复调用 LLM：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> lru_cache</span><br><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CachedLLMRecommender</span>:</span><br><span class="line">    <span class="string">"""带缓存的 LLM 推荐器"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.cache = {}</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_cache_key</span>(<span class="params">self, query: <span class="built_in">str</span>, context: <span class="type">Dict</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""生成缓存键"""</span></span><br><span class="line">        key_str = json.dumps({<span class="string">"query"</span>: query, <span class="string">"context"</span>: context}, sort_keys=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> hashlib.md5(key_str.encode()).hexdigest()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">recommend</span>(<span class="params">self, query: <span class="built_in">str</span>, context: <span class="type">Dict</span></span>) -&gt; <span class="type">List</span>[<span class="type">Dict</span>]:</span><br><span class="line">        <span class="string">"""带缓存的推荐"""</span></span><br><span class="line">        cache_key = self._get_cache_key(query, context)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> cache_key <span class="keyword">in</span> self.cache:</span><br><span class="line">            <span class="keyword">return</span> self.cache[cache_key]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 调用 LLM</span></span><br><span class="line">        result = self._call_llm(query, context)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 缓存结果</span></span><br><span class="line">        self.cache[cache_key] = result</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p><strong>4. 使用更小的模型</strong></p>
<p>对于某些任务，可以使用更小的模型（如 GPT-3.5-turbo 而不是
GPT-4），在效果和成本之间平衡。</p>
<p><strong>5. 结构化 Prompt</strong></p>
<p>使用结构化的 Prompt 格式，减少冗余信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_efficient_prompt</span>(<span class="params">user_history: <span class="type">List</span>[<span class="type">Dict</span>], candidates: <span class="type">List</span>[<span class="type">Dict</span>]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">"""构建高效的 Prompt"""</span></span><br><span class="line">    <span class="comment"># 只包含关键信息</span></span><br><span class="line">    history_summary = <span class="string">"; "</span>.join([item[<span class="string">'name'</span>] <span class="keyword">for</span> item <span class="keyword">in</span> user_history[:<span class="number">5</span>]])</span><br><span class="line">    candidates_list = <span class="string">"\n"</span>.join([<span class="string">f"<span class="subst">{i}</span>. <span class="subst">{c[<span class="string">'name'</span>]}</span>"</span> <span class="keyword">for</span> i, c <span class="keyword">in</span> <span class="built_in">enumerate</span>(candidates[:<span class="number">20</span>], <span class="number">1</span>)])</span><br><span class="line">    </span><br><span class="line">    prompt = <span class="string">f"""H: <span class="subst">{history_summary}</span></span></span><br><span class="line"><span class="string">C: <span class="subst">{candidates_list}</span></span></span><br><span class="line"><span class="string">R: Top 5"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> prompt</span><br></pre></td></tr></table></figure>
<p><strong>6. 两阶段策略</strong></p>
<p>先用小模型/快速方法筛选，再用大模型精细处理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">two_stage_recommend</span>(<span class="params">user_query: <span class="built_in">str</span>, all_items: <span class="type">List</span>[<span class="type">Dict</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">Dict</span>]:</span><br><span class="line">    <span class="string">"""两阶段推荐"""</span></span><br><span class="line">    <span class="comment"># 第一阶段：快速筛选（使用向量检索）</span></span><br><span class="line">    stage1_results = vector_search(user_query, all_items, top_k=<span class="number">50</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 第二阶段：LLM 精细排序（只处理少量候选）</span></span><br><span class="line">    stage2_results = llm_rerank(user_query, stage1_results, top_k=<span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> stage2_results</span><br></pre></td></tr></table></figure>
<p>通过这些优化策略，可以显著降低 Token
消耗和成本，同时保持推荐效果。</p>
<h2 id="完整代码示例端到端-llm-推荐系统">完整代码示例：端到端 LLM
推荐系统</h2>
<p>下面是一个完整的端到端 LLM
推荐系统实现，整合了前面提到的各种技术：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModel, AutoTokenizer</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Dict</span>, <span class="type">Optional</span>, <span class="type">Tuple</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> dataclasses <span class="keyword">import</span> dataclass</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RecommendationResult</span>:</span><br><span class="line">    <span class="string">"""推荐结果"""</span></span><br><span class="line">    item_id: <span class="built_in">int</span></span><br><span class="line">    item_name: <span class="built_in">str</span></span><br><span class="line">    score: <span class="built_in">float</span></span><br><span class="line">    explanation: <span class="built_in">str</span></span><br><span class="line">    metadata: <span class="type">Dict</span> = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EndToEndLLMRecommender</span>:</span><br><span class="line">    <span class="string">"""端到端 LLM 推荐系统"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        embedding_model: <span class="built_in">str</span> = <span class="string">"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"</span>,</span></span><br><span class="line"><span class="params">        llm_model: <span class="built_in">str</span> = <span class="string">"gpt-3.5-turbo"</span>,</span></span><br><span class="line"><span class="params">        use_cache: <span class="built_in">bool</span> = <span class="literal">True</span></span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            embedding_model: 嵌入模型（用于检索）</span></span><br><span class="line"><span class="string">            llm_model: LLM 模型（用于排序和解释）</span></span><br><span class="line"><span class="string">            use_cache: 是否使用缓存</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 初始化组件</span></span><br><span class="line">        <span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer</span><br><span class="line">        self.embedding_model = SentenceTransformer(embedding_model)</span><br><span class="line">        </span><br><span class="line">        self.llm_client = OpenAI(api_key=os.getenv(<span class="string">"OPENAI_API_KEY"</span>))</span><br><span class="line">        self.llm_model = llm_model</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 数据存储</span></span><br><span class="line">        self.items: <span class="type">List</span>[<span class="type">Dict</span>] = []</span><br><span class="line">        self.item_embeddings: <span class="type">Optional</span>[np.ndarray] = <span class="literal">None</span></span><br><span class="line">        self.item_index = <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 缓存</span></span><br><span class="line">        self.cache = {} <span class="keyword">if</span> use_cache <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_items</span>(<span class="params">self, items: <span class="type">List</span>[<span class="type">Dict</span>]</span>):</span><br><span class="line">        <span class="string">"""加载物品数据"""</span></span><br><span class="line">        self.items = items</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 生成嵌入</span></span><br><span class="line">        texts = []</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">            text = self._item_to_text(item)</span><br><span class="line">            texts.append(text)</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"生成物品嵌入..."</span>)</span><br><span class="line">        self.item_embeddings = self.embedding_model.encode(texts, show_progress_bar=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 构建索引</span></span><br><span class="line">        <span class="keyword">import</span> faiss</span><br><span class="line">        dimension = self.item_embeddings.shape[<span class="number">1</span>]</span><br><span class="line">        self.item_index = faiss.IndexFlatIP(dimension)</span><br><span class="line">        faiss.normalize_L2(self.item_embeddings)</span><br><span class="line">        self.item_index.add(self.item_embeddings.astype(<span class="string">'float32'</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"加载了 <span class="subst">{<span class="built_in">len</span>(items)}</span> 个物品"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_item_to_text</span>(<span class="params">self, item: <span class="type">Dict</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""将物品转换为文本"""</span></span><br><span class="line">        parts = []</span><br><span class="line">        <span class="keyword">if</span> <span class="string">'title'</span> <span class="keyword">in</span> item:</span><br><span class="line">            parts.append(item[<span class="string">'title'</span>])</span><br><span class="line">        <span class="keyword">if</span> <span class="string">'description'</span> <span class="keyword">in</span> item:</span><br><span class="line">            parts.append(item[<span class="string">'description'</span>])</span><br><span class="line">        <span class="keyword">if</span> <span class="string">'category'</span> <span class="keyword">in</span> item:</span><br><span class="line">            parts.append(<span class="string">f"类别：<span class="subst">{item[<span class="string">'category'</span>]}</span>"</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">" | "</span>.join(parts)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">recommend</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        user_query: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">        user_history: <span class="type">Optional</span>[<span class="type">List</span>[<span class="type">Dict</span>]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">        top_k: <span class="built_in">int</span> = <span class="number">10</span>,</span></span><br><span class="line"><span class="params">        generate_explanation: <span class="built_in">bool</span> = <span class="literal">True</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="type">List</span>[RecommendationResult]:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        生成推荐</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user_query: 用户查询</span></span><br><span class="line"><span class="string">            user_history: 用户历史行为</span></span><br><span class="line"><span class="string">            top_k: 推荐数量</span></span><br><span class="line"><span class="string">            generate_explanation: 是否生成解释</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            推荐结果列表</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 检查缓存</span></span><br><span class="line">        cache_key = self._get_cache_key(user_query, user_history)</span><br><span class="line">        <span class="keyword">if</span> self.cache <span class="keyword">and</span> cache_key <span class="keyword">in</span> self.cache:</span><br><span class="line">            <span class="keyword">return</span> self.cache[cache_key]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 第一阶段：检索</span></span><br><span class="line">        retrieved = self._retrieve(user_query, top_k=<span class="number">50</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 第二阶段：LLM 重排序</span></span><br><span class="line">        reranked = self._llm_rerank(user_query, user_history, retrieved, top_k)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 第三阶段：生成解释</span></span><br><span class="line">        results = []</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> reranked:</span><br><span class="line">            explanation = <span class="string">""</span></span><br><span class="line">            <span class="keyword">if</span> generate_explanation:</span><br><span class="line">                explanation = self._generate_explanation(user_query, user_history, item)</span><br><span class="line">            </span><br><span class="line">            result = RecommendationResult(</span><br><span class="line">                item_id=item.get(<span class="string">'item_id'</span>, <span class="number">0</span>),</span><br><span class="line">                item_name=item.get(<span class="string">'title'</span>, <span class="string">'未知'</span>),</span><br><span class="line">                score=item.get(<span class="string">'llm_score'</span>, <span class="number">0.0</span>),</span><br><span class="line">                explanation=explanation,</span><br><span class="line">                metadata=item</span><br><span class="line">            )</span><br><span class="line">            results.append(result)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 缓存结果</span></span><br><span class="line">        <span class="keyword">if</span> self.cache:</span><br><span class="line">            self.cache[cache_key] = results</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> results</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_retrieve</span>(<span class="params">self, query: <span class="built_in">str</span>, top_k: <span class="built_in">int</span> = <span class="number">50</span></span>) -&gt; <span class="type">List</span>[<span class="type">Dict</span>]:</span><br><span class="line">        <span class="string">"""检索相关物品"""</span></span><br><span class="line">        <span class="keyword">if</span> self.item_index <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"请先调用 load_items() 加载物品"</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 生成查询嵌入</span></span><br><span class="line">        query_embedding = self.embedding_model.encode([query])</span><br><span class="line">        faiss.normalize_L2(query_embedding)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 检索</span></span><br><span class="line">        distances, indices = self.item_index.search(</span><br><span class="line">            query_embedding.astype(<span class="string">'float32'</span>),</span><br><span class="line">            top_k</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 构建结果</span></span><br><span class="line">        results = []</span><br><span class="line">        <span class="keyword">for</span> idx, dist <span class="keyword">in</span> <span class="built_in">zip</span>(indices[<span class="number">0</span>], distances[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">if</span> idx &lt; <span class="built_in">len</span>(self.items):</span><br><span class="line">                item = self.items[idx].copy()</span><br><span class="line">                item[<span class="string">'retrieval_score'</span>] = <span class="built_in">float</span>(dist)</span><br><span class="line">                results.append(item)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> results</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_llm_rerank</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        query: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">        user_history: <span class="type">Optional</span>[<span class="type">List</span>[<span class="type">Dict</span>]],</span></span><br><span class="line"><span class="params">        candidates: <span class="type">List</span>[<span class="type">Dict</span>],</span></span><br><span class="line"><span class="params">        top_k: <span class="built_in">int</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="type">List</span>[<span class="type">Dict</span>]:</span><br><span class="line">        <span class="string">"""使用 LLM 重排序"""</span></span><br><span class="line">        <span class="comment"># 构建上下文</span></span><br><span class="line">        context = self._build_context(query, user_history)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 格式化候选</span></span><br><span class="line">        candidates_str = self._format_candidates(candidates[:<span class="number">30</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 构建 Prompt</span></span><br><span class="line">        prompt = <span class="string">f"""用户需求：<span class="subst">{query}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"><span class="subst">{context}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">候选物品：</span></span><br><span class="line"><span class="string"><span class="subst">{candidates_str}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">请根据用户需求，对这些候选物品进行排序。输出排序后的编号列表（JSON格式）：</span></span><br><span class="line"><span class="string">{{"ranking": [1, 5, 3, ...]}}</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">只输出 JSON。"""</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = self.llm_client.chat.completions.create(</span><br><span class="line">                model=self.llm_model,</span><br><span class="line">                messages=[</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"system"</span>, <span class="string">"content"</span>: <span class="string">"你是一个专业的推荐排序器。"</span>},</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: prompt}</span><br><span class="line">                ],</span><br><span class="line">                temperature=<span class="number">0.1</span>,</span><br><span class="line">                max_tokens=<span class="number">500</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            content = response.choices[<span class="number">0</span>].message.content.strip()</span><br><span class="line">            <span class="keyword">if</span> <span class="string">"```json"</span> <span class="keyword">in</span> content:</span><br><span class="line">                content = content.split(<span class="string">"```json"</span>)[<span class="number">1</span>].split(<span class="string">"```"</span>)[<span class="number">0</span>].strip()</span><br><span class="line">            </span><br><span class="line">            result = json.loads(content)</span><br><span class="line">            ranking = result.get(<span class="string">"ranking"</span>, [])</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 重新组织</span></span><br><span class="line">            reranked = []</span><br><span class="line">            <span class="keyword">for</span> rank <span class="keyword">in</span> ranking[:top_k]:</span><br><span class="line">                <span class="keyword">if</span> <span class="number">1</span> &lt;= rank &lt;= <span class="built_in">len</span>(candidates):</span><br><span class="line">                    item = candidates[rank - <span class="number">1</span>].copy()</span><br><span class="line">                    item[<span class="string">'llm_score'</span>] = <span class="number">1.0</span> - (ranking.index(rank) / <span class="built_in">len</span>(ranking))</span><br><span class="line">                    reranked.append(item)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 补充不足的</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(reranked) &lt; top_k:</span><br><span class="line">                remaining = [c <span class="keyword">for</span> c <span class="keyword">in</span> candidates <span class="keyword">if</span> c <span class="keyword">not</span> <span class="keyword">in</span> reranked]</span><br><span class="line">                reranked.extend(remaining[:top_k - <span class="built_in">len</span>(reranked)])</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">return</span> reranked</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"LLM 重排序错误: <span class="subst">{e}</span>"</span>)</span><br><span class="line">            <span class="keyword">return</span> candidates[:top_k]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_generate_explanation</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        query: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">        user_history: <span class="type">Optional</span>[<span class="type">List</span>[<span class="type">Dict</span>]],</span></span><br><span class="line"><span class="params">        item: <span class="type">Dict</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""生成推荐解释"""</span></span><br><span class="line">        context = self._build_context(query, user_history)</span><br><span class="line">        </span><br><span class="line">        prompt = <span class="string">f"""用户需求：<span class="subst">{query}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"><span class="subst">{context}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">推荐物品：《<span class="subst">{item.get(<span class="string">'title'</span>, <span class="string">'未知'</span>)}</span>》</span></span><br><span class="line"><span class="string">描述：<span class="subst">{item.get(<span class="string">'description'</span>, <span class="string">''</span>)}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">请生成一段100-150字的推荐解释。"""</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = self.llm_client.chat.completions.create(</span><br><span class="line">                model=self.llm_model,</span><br><span class="line">                messages=[</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"system"</span>, <span class="string">"content"</span>: <span class="string">"你是一个推荐解释生成器。"</span>},</span><br><span class="line">                    {<span class="string">"role"</span>: <span class="string">"user"</span>, <span class="string">"content"</span>: prompt}</span><br><span class="line">                ],</span><br><span class="line">                temperature=<span class="number">0.7</span>,</span><br><span class="line">                max_tokens=<span class="number">300</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">return</span> response.choices[<span class="number">0</span>].message.content.strip()</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"解释生成错误: <span class="subst">{e}</span>"</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"基于您的需求，我们为您推荐了这个物品。"</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_context</span>(<span class="params">self, query: <span class="built_in">str</span>, user_history: <span class="type">Optional</span>[<span class="type">List</span>[<span class="type">Dict</span>]]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""构建用户上下文"""</span></span><br><span class="line">        context_parts = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> user_history:</span><br><span class="line">            history_str = <span class="string">"用户历史：\n"</span></span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> user_history[:<span class="number">10</span>]:</span><br><span class="line">                history_str += <span class="string">f"- 《<span class="subst">{item.get(<span class="string">'item_name'</span>, <span class="string">'未知'</span>)}</span>》\n"</span></span><br><span class="line">            context_parts.append(history_str)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="string">"\n"</span>.join(context_parts) <span class="keyword">if</span> context_parts <span class="keyword">else</span> <span class="string">""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_format_candidates</span>(<span class="params">self, candidates: <span class="type">List</span>[<span class="type">Dict</span>]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""格式化候选物品"""</span></span><br><span class="line">        candidates_str = <span class="string">""</span></span><br><span class="line">        <span class="keyword">for</span> i, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(candidates, <span class="number">1</span>):</span><br><span class="line">            candidates_str += <span class="string">f"<span class="subst">{i}</span>. 《<span class="subst">{item.get(<span class="string">'title'</span>, <span class="string">'未知'</span>)}</span>》"</span></span><br><span class="line">            <span class="keyword">if</span> item.get(<span class="string">'description'</span>):</span><br><span class="line">                candidates_str += <span class="string">f" - <span class="subst">{item[<span class="string">'description'</span>][:<span class="number">80</span>]}</span>"</span></span><br><span class="line">            candidates_str += <span class="string">"\n"</span></span><br><span class="line">        <span class="keyword">return</span> candidates_str</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_cache_key</span>(<span class="params">self, query: <span class="built_in">str</span>, user_history: <span class="type">Optional</span>[<span class="type">List</span>[<span class="type">Dict</span>]]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">"""生成缓存键"""</span></span><br><span class="line">        <span class="keyword">import</span> hashlib</span><br><span class="line">        key_data = {<span class="string">"query"</span>: query, <span class="string">"history"</span>: user_history}</span><br><span class="line">        key_str = json.dumps(key_data, sort_keys=<span class="literal">True</span>, ensure_ascii=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">return</span> hashlib.md5(key_str.encode()).hexdigest()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用示例</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># 初始化推荐器</span></span><br><span class="line">    recommender = EndToEndLLMRecommender()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 加载物品数据</span></span><br><span class="line">    items = [</span><br><span class="line">        {</span><br><span class="line">            <span class="string">"item_id"</span>: <span class="number">1</span>,</span><br><span class="line">            <span class="string">"title"</span>: <span class="string">"肖申克的救赎"</span>,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"关于希望和友谊的经典电影"</span>,</span><br><span class="line">            <span class="string">"category"</span>: <span class="string">"剧情"</span></span><br><span class="line">        },</span><br><span class="line">        {</span><br><span class="line">            <span class="string">"item_id"</span>: <span class="number">2</span>,</span><br><span class="line">            <span class="string">"title"</span>: <span class="string">"阿甘正传"</span>,</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"智障人士的传奇人生"</span>,</span><br><span class="line">            <span class="string">"category"</span>: <span class="string">"剧情"</span></span><br><span class="line">        },</span><br><span class="line">        <span class="comment"># ... 更多物品</span></span><br><span class="line">    ]</span><br><span class="line">    recommender.load_items(items)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 生成推荐</span></span><br><span class="line">    results = recommender.recommend(</span><br><span class="line">        user_query=<span class="string">"我想看感人的剧情片"</span>,</span><br><span class="line">        user_history=[</span><br><span class="line">            {<span class="string">"item_name"</span>: <span class="string">"当幸福来敲门"</span>}</span><br><span class="line">        ],</span><br><span class="line">        top_k=<span class="number">5</span>,</span><br><span class="line">        generate_explanation=<span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 输出结果</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"推荐结果：\n"</span>)</span><br><span class="line">    <span class="keyword">for</span> i, result <span class="keyword">in</span> <span class="built_in">enumerate</span>(results, <span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"<span class="subst">{i}</span>. 《<span class="subst">{result.item_name}</span>》"</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"   分数：<span class="subst">{result.score:<span class="number">.3</span>f}</span>"</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"   理由：<span class="subst">{result.explanation}</span>\n"</span>)</span><br></pre></td></tr></table></figure>
<h2 id="常见问题解答qa">常见问题解答（Q&amp;A）</h2>
<h3 id="q1-llm-推荐系统相比传统推荐系统有什么优势">Q1: LLM
推荐系统相比传统推荐系统有什么优势？</h3>
<p><strong>A:</strong> LLM 推荐系统的主要优势包括：</p>
<ol type="1">
<li><strong>语义理解能力</strong>：LLM
能够理解物品的文本描述、用户评论等语义信息，而传统方法主要依赖数值特征</li>
<li><strong>零样本能力</strong>：对于新物品或新用户，LLM
可以在没有训练数据的情况下进行推理</li>
<li><strong>可解释性</strong>：LLM
可以生成自然语言的推荐理由，提升用户体验和信任度</li>
<li><strong>跨域迁移</strong>：LLM 的预训练知识可以迁移到不同领域</li>
<li><strong>自然语言交互</strong>：支持对话式推荐，用户体验更好</li>
</ol>
<p>但也要注意 LLM 的劣势：延迟高、成本高、需要大量 Token。</p>
<h3 id="q2-如何平衡-llm-推荐的效果和效率">Q2: 如何平衡 LLM
推荐的效果和效率？</h3>
<p><strong>A:</strong> 可以采用以下策略：</p>
<ol type="1">
<li><strong>混合架构</strong>：使用传统方法进行粗排，LLM
只用于重排序和解释生成</li>
<li><strong>检索增强</strong>：先用向量检索快速筛选候选，再用 LLM
精细处理</li>
<li><strong>缓存机制</strong>：缓存常见查询的结果</li>
<li><strong>批量处理</strong>：将多个请求合并处理</li>
<li><strong>模型选择</strong>：根据任务复杂度选择合适大小的模型（小任务用小模型）</li>
</ol>
<h3 id="q3-llm-推荐系统如何处理冷启动问题">Q3: LLM
推荐系统如何处理冷启动问题？</h3>
<p><strong>A:</strong> LLM 推荐系统在冷启动方面有明显优势：</p>
<ol type="1">
<li><strong>新物品冷启动</strong>：只需要提供物品的文本描述，LLM
就能理解其特性并做出推荐</li>
<li><strong>新用户冷启动</strong>：可以通过对话了解用户需求，或者使用
LLM 理解用户的自然语言描述</li>
<li><strong>零样本推荐</strong>：LLM
的预训练知识使其能够在没有领域特定数据的情况下工作</li>
</ol>
<h3 id="q4-prompt-工程在-llm-推荐中有多重要">Q4: Prompt 工程在 LLM
推荐中有多重要？</h3>
<p><strong>A:</strong> Prompt 工程非常关键，直接影响推荐效果：</p>
<ol type="1">
<li><strong>结构化输入</strong>：清晰的组织用户历史和候选物品信息</li>
<li><strong>明确输出格式</strong>：指定 JSON 等格式，便于解析</li>
<li><strong>Few-shot 示例</strong>：提供示例引导 LLM 输出正确格式</li>
<li><strong>约束条件</strong>：明确约束（如"不要推荐已看过的"）</li>
<li><strong>上下文管理</strong>：合理控制上下文长度，避免 Token
浪费</li>
</ol>
<h3 id="q5-如何评估-llm-推荐系统的效果">Q5: 如何评估 LLM
推荐系统的效果？</h3>
<p><strong>A:</strong> 评估可以从多个维度进行：</p>
<ol type="1">
<li><strong>离线指标</strong>：
<ul>
<li>准确率（Precision）、召回率（Recall）</li>
<li>NDCG、MAP 等排序指标</li>
<li>多样性、新颖性等指标</li>
</ul></li>
<li><strong>在线指标</strong>：
<ul>
<li>点击率（CTR）</li>
<li>转化率</li>
<li>用户满意度</li>
</ul></li>
<li><strong>LLM 特定指标</strong>：
<ul>
<li>解释质量（人工评估或自动评估）</li>
<li>对话流畅度</li>
<li>Token 效率</li>
</ul></li>
<li><strong>A/B 测试</strong>：与基线系统对比，评估实际业务指标</li>
</ol>
<h3 id="q6-llm-推荐系统的成本如何控制">Q6: LLM
推荐系统的成本如何控制？</h3>
<p><strong>A:</strong> 成本控制策略：</p>
<ol type="1">
<li><strong>Token 优化</strong>：
<ul>
<li>文本摘要，减少输入长度</li>
<li>结构化 Prompt，避免冗余</li>
<li>批量处理，提高效率</li>
</ul></li>
<li><strong>缓存策略</strong>：
<ul>
<li>缓存常见查询</li>
<li>缓存物品特征（避免重复编码）</li>
</ul></li>
<li><strong>模型选择</strong>：
<ul>
<li>简单任务用小模型</li>
<li>复杂任务用大模型</li>
<li>考虑使用开源模型（如 LLaMA）</li>
</ul></li>
<li><strong>架构优化</strong>：
<ul>
<li>只在关键环节使用 LLM</li>
<li>其他环节用传统方法</li>
</ul></li>
</ol>
<h3 id="q7-llm-推荐系统如何处理用户隐私">Q7: LLM
推荐系统如何处理用户隐私？</h3>
<p><strong>A:</strong> 隐私保护措施：</p>
<ol type="1">
<li><strong>数据脱敏</strong>：移除敏感信息（如真实姓名、地址）</li>
<li><strong>本地部署</strong>：使用开源模型本地部署，避免数据上传</li>
<li><strong>差分隐私</strong>：在训练或推理时添加噪声</li>
<li><strong>访问控制</strong>：限制对用户数据的访问</li>
<li><strong>数据加密</strong>：传输和存储时加密</li>
</ol>
<h3 id="q8-如何将-llm-推荐系统集成到现有系统中">Q8: 如何将 LLM
推荐系统集成到现有系统中？</h3>
<p><strong>A:</strong> 集成策略：</p>
<ol type="1">
<li><strong>渐进式集成</strong>：
<ul>
<li>先作为补充模块（如解释生成）</li>
<li>逐步扩展到更多环节</li>
<li>A/B 测试验证效果</li>
</ul></li>
<li><strong>API 封装</strong>：
<ul>
<li>将 LLM 推荐封装为独立服务</li>
<li>通过 API 调用，降低耦合</li>
</ul></li>
<li><strong>降级策略</strong>：
<ul>
<li>LLM 服务失败时，降级到传统方法</li>
<li>设置超时和重试机制</li>
</ul></li>
<li><strong>监控和日志</strong>：
<ul>
<li>监控延迟、错误率、Token 消耗</li>
<li>记录推荐结果，便于分析和优化</li>
</ul></li>
</ol>
<h3 id="q9-llm-推荐系统在哪些场景下效果最好">Q9: LLM
推荐系统在哪些场景下效果最好？</h3>
<p><strong>A:</strong> LLM 推荐系统在以下场景效果较好：</p>
<ol type="1">
<li><strong>文本丰富的领域</strong>：如书籍、电影、新闻等，有丰富的文本描述</li>
<li><strong>冷启动场景</strong>：新用户或新物品，缺乏历史数据</li>
<li><strong>需要解释的场景</strong>：用户希望理解推荐理由</li>
<li><strong>对话式交互</strong>：用户通过自然语言表达需求</li>
<li><strong>跨域推荐</strong>：需要在不同领域间迁移知识</li>
</ol>
<p>但在以下场景可能不如传统方法： - 大规模实时推荐（延迟要求高） -
纯数值特征（如价格、评分） - 成本敏感的场景</p>
<h3 id="q10-未来-llm-推荐系统的发展方向是什么">Q10: 未来 LLM
推荐系统的发展方向是什么？</h3>
<p><strong>A:</strong> 未来发展方向：</p>
<ol type="1">
<li><strong>多模态融合</strong>：结合文本、图像、音频等多种模态</li>
<li><strong>个性化微调</strong>：为每个用户微调模型</li>
<li><strong>强化学习</strong>：使用 RL 优化长期用户满意度</li>
<li><strong>知识图谱集成</strong>：结合知识图谱提供更丰富的语义信息</li>
<li><strong>效率优化</strong>：模型压缩、量化、蒸馏等技术</li>
<li><strong>可解释性增强</strong>：更自然、更准确的解释生成</li>
<li><strong>隐私保护</strong>：联邦学习、差分隐私等技术</li>
</ol>
<h2 id="总结">总结</h2>
<p>LLM 为推荐系统带来了新的可能性，从简单的 Prompt-based
推荐到复杂的端到端架构，从特征增强到对话式交互，LLM
正在改变推荐系统的面貌。</p>
<p><strong>关键要点</strong>：</p>
<ol type="1">
<li><strong>LLM
的角色多样</strong>：可以是特征增强器、重排序器、解释生成器或端到端推荐器</li>
<li><strong>架构设计重要</strong>：需要平衡效果和效率，合理使用 LLM</li>
<li><strong>Prompt 工程关键</strong>：好的 Prompt 能显著提升效果</li>
<li><strong>成本需要控制</strong>：通过缓存、批量处理、模型选择等策略降低成本</li>
<li><strong>评估要全面</strong>：不仅要看准确率，还要看解释质量、用户体验等</li>
</ol>
<p><strong>实践建议</strong>：</p>
<ol type="1">
<li>从小规模开始，逐步扩展</li>
<li>结合传统方法，发挥各自优势</li>
<li>重视 Prompt 工程和上下文管理</li>
<li>建立完善的监控和评估体系</li>
<li>关注成本控制，确保可持续性</li>
</ol>
<p>LLM
推荐系统仍处于快速发展阶段，新的架构和方法不断涌现。作为推荐系统工程师，我们需要持续学习，在实践中不断优化和改进。</p>
<p>希望这篇文章能帮助你理解 LLM
在推荐系统中的应用，并为你的实践提供参考。如果你有任何问题或想法，欢迎交流讨论！</p>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    
    
    
    
    
    
    <ul>
        <li>本文标题：推荐系统（十二）—— 大语言模型与推荐系统</li>
        <li>本文作者：Chen Kai</li>
        <li>创建时间：2025-10-31 00:00:00</li>
        <li>
            本文链接：https://www.chenk.top/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/
        </li>
        <li>
            版权声明：本博客所有文章除特别声明外，均采用 <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> 许可协议。转载请注明出处！
        </li>
    </ul>
</div>

            </div>
        

        
            <ul class="post-tags-box">
                
                    <li class="tag-item">
                        <a href="/tags/LLM/">#LLM</a>&nbsp;
                    </li>
                
                    <li class="tag-item">
                        <a href="/tags/Recommendation-Systems/">#Recommendation Systems</a>&nbsp;
                    </li>
                
                    <li class="tag-item">
                        <a href="/tags/Large-Language-Models/">#Large Language Models</a>&nbsp;
                    </li>
                
            </ul>
        

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%88%E5%8D%81%E4%BA%94%EF%BC%89%E2%80%94%E2%80%94-%E5%AE%9E%E6%97%B6%E6%8E%A8%E8%8D%90%E4%B8%8E%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">推荐系统（十五）—— 实时推荐与在线学习</span>
                                <span class="post-nav-item">上一篇</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">推荐系统（三）—— 深度学习基础模型</span>
                                <span class="post-nav-item">下一篇</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
            <div class="comment-container">
                <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fas fa-comments">&nbsp;评论</i>
    </div>
    

        
            
    <div class="valine-container">
        <script data-pjax
                src="//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script>
        <div id="vcomments"></div>
        <script data-pjax>
            function loadValine() {
                new Valine({
                    el: '#vcomments',
                    appId: 'p2Cu9MgjoKzo3VmulhNLIusH-gzGzoHsz',
                    appKey: 'QThQHg3c8sVwGpzg9lu8zEG3',
                    meta: ['nick', 'mail', 'link'],
                    avatar: 'wavatar',
                    enableQQ: true,
                    placeholder: '😜 尽情赞美帅气伟大的ck吧~',
                    lang: 'zh-CN'.toLowerCase()
                });

                function getAuthor(language) {
                    switch (language) {
                        case 'en':
                            return 'Author';
                        case 'zh-CN':
                            return '博主';
                        default:
                            return 'Master';
                    }
                }

                // Add "Author" identify
                const getValineDomTimer = setInterval(() => {
                    const vcards = document.querySelectorAll('#vcomments .vcards .vcard');
                    if (vcards.length > 0) {
                        let author = 'Chen Kai';

                        if (author) {
                            for (let vcard of vcards) {
                                const vnick_dom = vcard.querySelector('.vhead .vnick');
                                const vnick = vnick_dom.innerHTML;
                                if (vnick === author) {
                                    vnick_dom.innerHTML = `${vnick} <span class="author">${getAuthor(KEEP.hexo_config.language)}</span>`
                                }
                            }
                        }
                        clearInterval(getValineDomTimer);
                    } else {
                        clearInterval(getValineDomTimer);
                    }
                }, 2000);
            }

            if ('true') {
                const loadValineTimeout = setTimeout(() => {
                    loadValine();
                    clearTimeout(loadValineTimeout);
                }, 1000);
            } else {
                window.addEventListener('DOMContentLoaded', loadValine);
            }
        </script>
    </div>



        
    
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2020</span>
              -
            
            2026&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Chen Kai</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        访问人数&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
            </div>
        
        <div class="theme-info info-item">
            <!-- 由 <a target="_blank" href="https://hexo.io">Hexo</a> 驱动&nbsp;|&nbsp;主题&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.5</a> -->
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fas fa-comment"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        
            <li class="tools-item rss flex-center">
                <a class="flex-center"
                   href="/atom.xml"
                   target="_blank"
                >
                    <i class="fas fa-rss"></i>
                </a>
            </li>
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#llm-%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2%E5%AE%9A%E4%BD%8D"><span class="nav-number">1.</span> <span class="nav-text">LLM 在推荐系统中的角色定位</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%A0%E7%BB%9F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%B1%80%E9%99%90"><span class="nav-number">1.1.</span> <span class="nav-text">传统推荐系统的局限</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#llm-%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%96%B0%E8%83%BD%E5%8A%9B"><span class="nav-number">1.2.</span> <span class="nav-text">LLM 带来的新能力</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#llm-%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2"><span class="nav-number">1.3.</span> <span class="nav-text">LLM 在推荐系统中的角色</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#prompt-based-%E6%8E%A8%E8%8D%90%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84-llm-%E5%BA%94%E7%94%A8"><span class="nav-number">2.</span> <span class="nav-text">Prompt-based 推荐：最简单的
LLM 应用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E6%80%9D%E8%B7%AF"><span class="nav-number">2.1.</span> <span class="nav-text">基本思路</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81"><span class="nav-number">2.2.</span> <span class="nav-text">实现代码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#prompt-%E5%B7%A5%E7%A8%8B%E6%8A%80%E5%B7%A7"><span class="nav-number">2.3.</span> <span class="nav-text">Prompt 工程技巧</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%98%E7%BC%BA%E7%82%B9%E5%88%86%E6%9E%90"><span class="nav-number">2.4.</span> <span class="nav-text">优缺点分析</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#a-llmrec%E9%80%82%E9%85%8D%E5%99%A8%E5%A2%9E%E5%BC%BA%E7%9A%84-llm-%E6%8E%A8%E8%8D%90%E6%9E%B6%E6%9E%84"><span class="nav-number">3.</span> <span class="nav-text">A-LLMRec：适配器增强的 LLM
推荐架构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1"><span class="nav-number">3.1.</span> <span class="nav-text">架构设计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%82%E9%85%8D%E5%99%A8%E6%9C%BA%E5%88%B6"><span class="nav-number">3.2.</span> <span class="nav-text">适配器机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%8C%E6%95%B4%E5%AE%9E%E7%8E%B0"><span class="nav-number">3.3.</span> <span class="nav-text">完整实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%98%E5%8A%BF%E5%88%86%E6%9E%90"><span class="nav-number">3.4.</span> <span class="nav-text">优势分析</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#xrec%E5%8F%AF%E8%A7%A3%E9%87%8A%E7%9A%84-llm-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F"><span class="nav-number">4.</span> <span class="nav-text">XRec：可解释的 LLM 推荐系统</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1-1"><span class="nav-number">4.1.</span> <span class="nav-text">架构设计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81-1"><span class="nav-number">4.2.</span> <span class="nav-text">实现代码</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#llm-%E4%BD%9C%E4%B8%BA%E7%89%B9%E5%BE%81%E5%A2%9E%E5%BC%BA%E5%99%A8"><span class="nav-number">5.</span> <span class="nav-text">LLM 作为特征增强器</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E6%80%9D%E8%B7%AF-1"><span class="nav-number">5.1.</span> <span class="nav-text">基本思路</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81-2"><span class="nav-number">5.2.</span> <span class="nav-text">实现代码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%98%E5%8A%BF%E5%88%86%E6%9E%90-1"><span class="nav-number">5.3.</span> <span class="nav-text">优势分析</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#llm-%E4%BD%9C%E4%B8%BA%E9%87%8D%E6%8E%92%E5%BA%8F%E5%99%A8"><span class="nav-number">6.</span> <span class="nav-text">LLM 作为重排序器</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1-2"><span class="nav-number">6.1.</span> <span class="nav-text">架构设计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81-3"><span class="nav-number">6.2.</span> <span class="nav-text">实现代码</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%B9%E8%AF%9D%E5%BC%8F%E6%8E%A8%E8%8D%90chatrec"><span class="nav-number">7.</span> <span class="nav-text">对话式推荐：ChatREC</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1-3"><span class="nav-number">7.1.</span> <span class="nav-text">架构设计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81-4"><span class="nav-number">7.2.</span> <span class="nav-text">实现代码</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ra-rec%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%9A%84%E6%8E%A8%E8%8D%90%E6%9E%B6%E6%9E%84"><span class="nav-number">8.</span> <span class="nav-text">RA-Rec：检索增强的推荐架构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1-4"><span class="nav-number">8.1.</span> <span class="nav-text">架构设计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81-5"><span class="nav-number">8.2.</span> <span class="nav-text">实现代码</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#chatcrs%E5%AF%B9%E8%AF%9D%E5%BC%8F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%A1%86%E6%9E%B6"><span class="nav-number">9.</span> <span class="nav-text">ChatCRS：对话式推荐系统框架</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9E%B6%E6%9E%84%E7%89%B9%E7%82%B9"><span class="nav-number">9.1.</span> <span class="nav-text">架构特点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A0%B8%E5%BF%83%E5%AE%9E%E7%8E%B0"><span class="nav-number">9.2.</span> <span class="nav-text">核心实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#token-%E6%95%88%E7%8E%87%E4%BC%98%E5%8C%96"><span class="nav-number">10.</span> <span class="nav-text">Token 效率优化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5"><span class="nav-number">10.1.</span> <span class="nav-text">优化策略</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B%E7%AB%AF%E5%88%B0%E7%AB%AF-llm-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F"><span class="nav-number">11.</span> <span class="nav-text">完整代码示例：端到端 LLM
推荐系统</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%A7%A3%E7%AD%94qa"><span class="nav-number">12.</span> <span class="nav-text">常见问题解答（Q&amp;A）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#q1-llm-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E6%AF%94%E4%BC%A0%E7%BB%9F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%9C%89%E4%BB%80%E4%B9%88%E4%BC%98%E5%8A%BF"><span class="nav-number">12.1.</span> <span class="nav-text">Q1: LLM
推荐系统相比传统推荐系统有什么优势？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q2-%E5%A6%82%E4%BD%95%E5%B9%B3%E8%A1%A1-llm-%E6%8E%A8%E8%8D%90%E7%9A%84%E6%95%88%E6%9E%9C%E5%92%8C%E6%95%88%E7%8E%87"><span class="nav-number">12.2.</span> <span class="nav-text">Q2: 如何平衡 LLM
推荐的效果和效率？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q3-llm-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E5%86%B7%E5%90%AF%E5%8A%A8%E9%97%AE%E9%A2%98"><span class="nav-number">12.3.</span> <span class="nav-text">Q3: LLM
推荐系统如何处理冷启动问题？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q4-prompt-%E5%B7%A5%E7%A8%8B%E5%9C%A8-llm-%E6%8E%A8%E8%8D%90%E4%B8%AD%E6%9C%89%E5%A4%9A%E9%87%8D%E8%A6%81"><span class="nav-number">12.4.</span> <span class="nav-text">Q4: Prompt 工程在 LLM
推荐中有多重要？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q5-%E5%A6%82%E4%BD%95%E8%AF%84%E4%BC%B0-llm-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%95%88%E6%9E%9C"><span class="nav-number">12.5.</span> <span class="nav-text">Q5: 如何评估 LLM
推荐系统的效果？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q6-llm-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%88%90%E6%9C%AC%E5%A6%82%E4%BD%95%E6%8E%A7%E5%88%B6"><span class="nav-number">12.6.</span> <span class="nav-text">Q6: LLM
推荐系统的成本如何控制？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q7-llm-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E7%94%A8%E6%88%B7%E9%9A%90%E7%A7%81"><span class="nav-number">12.7.</span> <span class="nav-text">Q7: LLM
推荐系统如何处理用户隐私？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q8-%E5%A6%82%E4%BD%95%E5%B0%86-llm-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E9%9B%86%E6%88%90%E5%88%B0%E7%8E%B0%E6%9C%89%E7%B3%BB%E7%BB%9F%E4%B8%AD"><span class="nav-number">12.8.</span> <span class="nav-text">Q8: 如何将 LLM
推荐系统集成到现有系统中？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q9-llm-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9C%A8%E5%93%AA%E4%BA%9B%E5%9C%BA%E6%99%AF%E4%B8%8B%E6%95%88%E6%9E%9C%E6%9C%80%E5%A5%BD"><span class="nav-number">12.9.</span> <span class="nav-text">Q9: LLM
推荐系统在哪些场景下效果最好？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#q10-%E6%9C%AA%E6%9D%A5-llm-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%91%E5%B1%95%E6%96%B9%E5%90%91%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">12.10.</span> <span class="nav-text">Q10: 未来 LLM
推荐系统的发展方向是什么？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">13.</span> <span class="nav-text">总结</span></a></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="搜索..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>

<script src="/js/lang-switch.js"></script>



    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-copy.js"></script>





<div class="post-scripts pjax">
    
        
<script src="/js/left-side-toggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/toc.js"></script>

    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
