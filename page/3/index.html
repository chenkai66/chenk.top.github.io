<!DOCTYPE html>



<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Chen Kai">
    
    <title>
        
        Chen Kai Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/logo.svg">
    
<link rel="stylesheet" href="/css/font-awesome.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"chenk.top","root":"/","language":"zh-CN","default_language":"zh-CN","languages":["zh-CN","en"],"path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":true},"style":{"primary_color":"#0066CC","avatar":"/images/avatar.svg","favicon":"/images/logo.svg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":false,"scale":false},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"Keep writing and Keep loving."},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":true,"style":"default"},"pjax":{"enable":true},"lazyload":{"enable":false},"version":"3.4.5"};
    KEEP.language_ago = {"second":"%s 秒前","minute":"%s 分钟前","hour":"%s 小时前","day":"%s 天前","week":"%s 周前","month":"%s 个月前","year":"%s 年前"};
  </script>
<meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="Chen Kai Blog" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    
    
    
    
    

    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                Chen Kai Blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            
                            
                            <a class="active"
                               href="/"
                            >
                                首页
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/archives"
                            >
                                归档
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/categories"
                            >
                                分类
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/tags"
                            >
                                标签
                            </a>
                        </li>
                    
                    <li class="menu-item lang-switch lang-switch-trigger" title="Language">
                        <i class="fas fa-globe"></i>
                    </li>
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item lang-switch-trigger"><i class="fas fa-globe"></i></div>
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class="active"
                       href="/">首页</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/archives">归档</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/categories">分类</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/tags">标签</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="home-content-container fade-in-down-animation">
    
    
    

    <ul class="home-article-list">
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88%E5%8D%81%EF%BC%89%E2%80%94%E2%80%94-RAG%E4%B8%8E%E7%9F%A5%E8%AF%86%E5%A2%9E%E5%BC%BA%E7%B3%BB%E7%BB%9F/">
                        自然语言处理（十）—— RAG与知识增强系统
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>随着大语言模型的广泛应用，一个核心问题逐渐凸显：如何让模型访问和利用外部知识？传统的预训练模型虽然拥有海量参数和强大的语言理解能力，但其知识被"冻结"在训练时的数据中，无法获取最新信息，也无法访问私有知识库。检索增强生成（Retrieval-Augmented Generation, RAG）技术应运而生，通过将信息检索与生成模型相结合，让 LLM 能够动态地访问外部知识，从而生成更准确、更相关的回答。</p>
<p>RAG 系统的核心包括向量数据库的选择、Embedding 模型的优化、检索策略的设计、重排序技术的应用，以及查询重写与扩展等关键技术。一个优秀的 RAG 系统不仅需要高效的检索机制，还需要精心设计的查询优化和结果融合策略。本文将深入探讨 RAG 系统的各个组件，从基础架构到高级优化技术，并通过实战案例展示如何构建企业级 RAG 系统。</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Fri Feb 28 2025 00:00:00 GMT+0800">2025-02-28</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/categories/Natural-Language-Processing/">Natural Language Processing</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/tags/LLM/">LLM</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/tags/RAG/">RAG</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/tags/NLP/">NLP</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88%E5%8D%81%EF%BC%89%E2%80%94%E2%80%94-RAG%E4%B8%8E%E7%9F%A5%E8%AF%86%E5%A2%9E%E5%BC%BA%E7%B3%BB%E7%BB%9F/">阅读全文&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88%E4%B9%9D%EF%BC%89%E2%80%94%E2%80%94-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/">
                        自然语言处理（九）—— 大语言模型架构深度解析
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>随着 ChatGPT 的横空出世，大语言模型（LLM）已经成为人工智能领域最炙手可热的技术。然而，要真正理解 LLM 的工作原理，我们需要深入探讨其架构设计、长文本处理技术、模型压缩方法以及推理优化策略。不同的架构选择（Encoder-only、Decoder-only、Encoder-Decoder）决定了模型的应用场景；长文本处理技术（ALiBi、RoPE、Flash Attention）让模型能够处理更长的上下文；MoE（Mixture of Experts）架构通过稀疏激活大幅提升了模型容量；而量化、KV Cache 优化等技术则让大模型能够在资源受限的环境中高效运行。</p>
<p>本文将系统性地解析大语言模型的核心架构技术，从架构选择到长文本处理，从 MoE 到模型压缩，从 KV Cache 到推理优化，并通过实战案例展示如何部署和优化 LLM。无论你是研究者、工程师还是技术爱好者，都能从本文中获得深入而实用的知识。</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Tue Feb 25 2025 00:00:00 GMT+0800">2025-02-25</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/categories/Natural-Language-Processing/">Natural Language Processing</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/tags/LLM/">LLM</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/tags/RAG/">RAG</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/tags/NLP/">NLP</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88%E4%B9%9D%EF%BC%89%E2%80%94%E2%80%94-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/">阅读全文&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88%E5%85%AB%EF%BC%89%E2%80%94%E2%80%94-%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%8EPEFT/">
                        自然语言处理（八）—— 模型微调与PEFT
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>随着大语言模型规模的不断增长，全量微调（Full Fine-tuning）的成本变得越来越高。一个拥有数十亿参数的模型，全量微调需要更新所有参数，这不仅需要巨大的计算资源，还可能导致灾难性遗忘（Catastrophic Forgetting）。为了解决这些问题，参数高效微调（Parameter-Efficient Fine-Tuning, PEFT）技术应运而生。</p>
<p>PEFT 技术通过只更新模型的一小部分参数，就能达到接近全量微调的效果。LoRA（Low-Rank Adaptation）、QLoRA、Adapter、Prefix-Tuning 等方法是其中的代表。这些方法不仅大幅降低了计算成本，还使得在消费级硬件上微调大模型成为可能。</p>
<p>本文将深入探讨全量微调与冻结微调的区别，详细解析 LoRA、QLoRA、Adapter、Prefix-Tuning、P-Tuning v2 等 PEFT 技术的原理，介绍指令微调（Instruction Tuning）和 RLHF（Reinforcement Learning from Human Feedback）等对齐技术，并通过实战案例展示如何使用 HuggingFace PEFT 库微调大模型。</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Sat Feb 22 2025 00:00:00 GMT+0800">2025-02-22</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/categories/Natural-Language-Processing/">Natural Language Processing</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/tags/LLM/">LLM</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/tags/PEFT/">PEFT</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/tags/NLP/">NLP</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88%E5%85%AB%EF%BC%89%E2%80%94%E2%80%94-%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%8EPEFT/">阅读全文&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88%E4%B8%83%EF%BC%89%E2%80%94%E2%80%94-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E4%B8%8EIn-Context-Learning/">
                        自然语言处理（七）—— 提示工程与In-Context Learning
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>在大语言模型时代，如何与模型"对话"成了一门艺术。同样的模型，不同的提示（Prompt）可能产生截然不同的结果。提示工程（Prompt Engineering）正是研究如何设计有效的输入，让模型发挥出最佳性能的技术。从简单的零样本提示到复杂的思维链推理，从角色设定到模板设计，提示工程已经成为使用大模型的核心技能。</p>
<p>In-Context Learning（上下文学习）是提示工程的理论基础。它揭示了模型如何通过示例学习，如何在推理时动态调整行为，以及为什么少样本提示往往比零样本提示效果更好。理解这些机制不仅能帮助我们写出更好的提示，更能深入理解大语言模型的工作方式。</p>
<p>本文将系统介绍提示工程的核心概念与实践技巧，包括零样本、少样本、思维链提示，角色设定与格式化技巧，提示模板设计，Self-Consistency 和 ReAct 等高级技术，并通过实战案例展示如何构建高效的提示系统。</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Wed Feb 19 2025 00:00:00 GMT+0800">2025-02-19</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/categories/Natural-Language-Processing/">Natural Language Processing</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/tags/LLM/">LLM</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/tags/Prompt-Engineering/">Prompt Engineering</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/tags/NLP/">NLP</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88%E4%B8%83%EF%BC%89%E2%80%94%E2%80%94-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E4%B8%8EIn-Context-Learning/">阅读全文&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88%E5%85%AD%EF%BC%89%E2%80%94%E2%80%94-GPT%E4%B8%8E%E7%94%9F%E6%88%90%E5%BC%8F%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">
                        自然语言处理（六）—— GPT与生成式语言模型
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>如果说 BERT 开启了理解式 NLP 的黄金时代，那么 GPT 系列则代表了生成式 NLP 的巅峰。从 2018 年的 GPT-1 到 2023 年的 GPT-4，OpenAI 通过不断放大模型规模和优化训练策略，证明了自回归语言模型可以成为通用人工智能的基础。GPT 的成功不仅在于其强大的文本生成能力，更在于它展示了<strong>上下文学习</strong>（In-Context Learning）的神奇力量：模型可以在不更新参数的情况下，仅通过几个示例就学会新任务。</p>
<p>GPT 的核心是自回归语言建模：给定前面的 token，预测下一个 token。这种看似简单的目标，配合 Transformer 解码器架构和大规模数据训练，产生了令人惊叹的涌现能力。理解 GPT 不仅是理解现代大语言模型的关键，更是探索 AI 通用智能的起点。</p>
<p>本文将深入探讨 GPT 系列的演进历程、自回归语言建模的原理、各种解码策略、上下文学习机制，以及如何评估生成质量。我们还将通过实战代码构建一个对话系统，展示 GPT 在实际应用中的强大能力。</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Sun Feb 16 2025 00:00:00 GMT+0800">2025-02-16</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/categories/Natural-Language-Processing/">Natural Language Processing</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/tags/Deep-Learning/">Deep Learning</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/tags/NLP/">NLP</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/tags/GPT/">GPT</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88%E5%85%AD%EF%BC%89%E2%80%94%E2%80%94-GPT%E4%B8%8E%E7%94%9F%E6%88%90%E5%BC%8F%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">阅读全文&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
    </ul>

    <div class="home-paginator">
        <div class="paginator">
    
        <a class="prev btn"
           href="/page/2/"
        >上一页</a>
    

    
        <a class="next btn"
           href="/page/4/"
        >下一页</a>
    
</div>

    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2020</span>
              -
            
            2026&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Chen Kai</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        访问人数&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
            </div>
        
        <div class="theme-info info-item">
            <!-- 由 <a target="_blank" href="https://hexo.io">Hexo</a> 驱动&nbsp;|&nbsp;主题&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.5</a> -->
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        
            <li class="tools-item rss flex-center">
                <a class="flex-center"
                   href="/atom.xml"
                   target="_blank"
                >
                    <i class="fas fa-rss"></i>
                </a>
            </li>
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="搜索..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>





<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>

<script src="/js/lang-switch.js"></script>



    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-copy.js"></script>





<div class="post-scripts pjax">
    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
