<!DOCTYPE html>



<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Chen Kai">
    
    <title>
        
        Chen Kai Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/logo.svg">
    
<link rel="stylesheet" href="/css/font-awesome.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"chenk.top","root":"/","language":"zh-CN","default_language":"zh-CN","languages":["zh-CN","en"],"path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":true},"style":{"primary_color":"#0066CC","avatar":"/images/avatar.svg","favicon":"/images/logo.svg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":false,"scale":false},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"Keep writing and Keep loving."},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":true,"style":"default"},"pjax":{"enable":true},"lazyload":{"enable":false},"version":"3.4.5"};
    KEEP.language_ago = {"second":"%s 秒前","minute":"%s 分钟前","hour":"%s 小时前","day":"%s 天前","week":"%s 周前","month":"%s 个月前","year":"%s 年前"};
  </script>
<meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="Chen Kai Blog" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    
    
    
    
    

    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                Chen Kai Blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            
                            
                            <a class="active"
                               href="/"
                            >
                                首页
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/archives"
                            >
                                归档
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/categories"
                            >
                                分类
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/tags"
                            >
                                标签
                            </a>
                        </li>
                    
                    <li class="menu-item lang-switch lang-switch-trigger" title="Language">
                        <i class="fas fa-globe"></i>
                    </li>
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item lang-switch-trigger"><i class="fas fa-globe"></i></div>
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class="active"
                       href="/">首页</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/archives">归档</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/categories">分类</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/tags">标签</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="home-content-container fade-in-down-animation">
    
    
    

    <ul class="home-article-list">
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/%E8%BF%91%E7%AB%AF%E7%AE%97%E5%AD%90/">
                        近端算子
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>当目标函数带有不可导项（比如 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="1.931ex" height="1.934ex" role="img" focusable="false" viewbox="0 -705 853.6 855"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="2113" d="M345 104T349 104T361 95T369 80T352 59Q268 -20 206 -20Q170 -20 146 3T113 53T99 104L94 129Q94 130 79 116T48 86T28 70Q22 70 15 79T7 94Q7 98 12 103T58 147L91 179V185Q91 186 91 191T92 200Q92 282 128 400T223 612T336 705Q397 705 397 636V627Q397 453 194 233Q185 223 180 218T174 211T171 208T165 201L163 186Q159 142 159 123Q159 17 208 17Q228 17 253 30T293 56T335 94Q345 104 349 104ZM360 634Q360 655 354 661T336 668Q328 668 322 666T302 645T272 592Q252 547 229 467T192 330L179 273Q179 272 186 280T204 300T221 322Q327 453 355 590Q360 612 360 634Z"/></g><g data-mml-node="mn" transform="translate(450,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g></g></g></g></svg></mjx-container></span> 稀疏正则、TV
正则）或约束难以直接处理时，“直接做梯度下降”常常会卡住：要么没有梯度，要么每一步都很难保证可行。近端算子提供了一种非常工程化、也非常漂亮的解决方式——可以把更新理解成“先按光滑部分走一步，再用一个带惩罚的最小化把解拉回到更合理的结构上”。本文会从凸分析与子梯度的最小必要背景出发，逐步引出
Moreau 包络与近端映射的性质、常见近端的闭式解与计算技巧，并把它们放回到
ISTA/FISTA、ADMM、SVM
与稀疏优化这些具体算法里解释：为什么它们能工作、什么时候会收敛得更快、实现时最容易错在哪里；最后配合习题把关键推导走一遍，确保你不仅“看懂”，还能“用起来”。</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Sun Sep 01 2024 00:00:00 GMT+0800">2024-09-01</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/categories/Algorithm/">Algorithm</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/tags/Optimization/">Optimization</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/%E8%BF%91%E7%AB%AF%E7%AE%97%E5%AD%90/">阅读全文&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/Graph-Contextualized-Self-Attention-Network-for-Session-based-Recommendation/">
                        Graph Contextualized Self-Attention Network for Session-based Recommendation
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>GC-SAN
是一种新型的会话推荐模型，旨在通过结合图神经网络（GNN）和自注意力机制（Self-Attention），有效捕捉用户当前会话中的物品转移模式。模型首先利用
GNN
处理局部的物品依赖关系，再通过多层自注意力网络捕捉会话中的全局偏好。最终，模型将会话中的局部兴趣和全局兴趣加权融合，生成用户的最终会话表示，以预测下一步的点击物品。实验结果表明，GC-SAN
在多个真实数据集上优于现有的会话推荐方法，尤其在建模长距离物品依赖和捕捉复杂物品关系上表现突出。</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Tue Aug 27 2024 00:00:00 GMT+0800">2024-08-27</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/categories/Paper/">Paper</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/tags/GNN/">GNN</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/tags/Recommend-System/">Recommend System</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/Graph-Contextualized-Self-Attention-Network-for-Session-based-Recommendation/">阅读全文&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/%E5%8F%8D%E5%BA%94%E6%89%A9%E6%95%A3%E7%B3%BB%E7%BB%9F%E4%B8%8E%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
                        反应扩散系统与图神经网络
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>图神经网络（GNN）在节点分类、链接预测、图生成等任务中展现出强大能力。然而，深层GNN面临一个根本性问题：<strong>过度平滑</strong>（over-smoothing）——随着层数增加，节点特征逐渐趋于相同，丢失了局部结构信息。这一现象与偏微分方程中的扩散过程有着深刻的数学联系：扩散项使信息在图上"流动"，而反应项则保持局部差异。反应扩散方程（Reaction-Diffusion
Equation, RDE）正是描述这种"扩散与反应平衡"的经典模型。</p>
<p>反应扩散方程在生物学、化学、物理学中有着悠久历史。从Turing的形态发生理论，到Gray-Scott的化学振荡，再到FitzHugh-Nagumo的神经脉冲模型，这些方程揭示了<strong>模式如何从均匀状态自发涌现</strong>。近年来，研究者发现：将反应扩散动力学嵌入图神经网络，不仅可以缓解过度平滑，还能让网络学习到更丰富的图结构模式。</p>
<p>本文将系统性地建立反应扩散系统与图神经网络的数学桥梁。我们从经典反应扩散方程出发，介绍Gray-Scott、FitzHugh-Nagumo模型和Turing不稳定性理论；然后建立图拉普拉斯算子与离散扩散的框架；接着深入模式形成的数学机制，包括线性稳定性分析和分叉理论；最后聚焦图神经网络，展示GRAND、PDE-GCN等扩散解释，并详细介绍图神经反应扩散模型（RDGNN）的架构与实验。</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Thu Aug 22 2024 00:00:00 GMT+0800">2024-08-22</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/categories/%E6%95%B0%E5%AD%A6%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">数学与机器学习</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/tags/GNN/">GNN</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/tags/PDE/">PDE</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/tags/%E5%8F%8D%E5%BA%94%E6%89%A9%E6%95%A3/">反应扩散</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">图神经网络</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/tags/Turing%E4%B8%8D%E7%A8%B3%E5%AE%9A%E6%80%A7/">Turing不稳定性</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/%E5%8F%8D%E5%BA%94%E6%89%A9%E6%95%A3%E7%B3%BB%E7%BB%9F%E4%B8%8E%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">阅读全文&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/%E5%AD%A6%E4%B9%A0%E7%8E%87%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E7%9A%84%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97%EF%BC%882026%EF%BC%89/">
                        学习率：从入门到大模型训练的终极指南
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>学习率（Learning Rate,
LR）是深度学习里<strong>最重要、也最容易“看起来像玄学”的超参数</strong>。它既像汽车的油门（决定你每一步走多快），也像方向盘的灵敏度（太敏感会蛇形走位甚至翻车，太迟钝又永远到不了目的地）。</p>
<p>这篇文章会从最简单的二次函数出发，把“学习率为什么会影响稳定性、为什么训练后期要降学习率、为什么
warmup 常见”讲清楚。</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Tue Aug 20 2024 00:00:00 GMT+0800">2024-08-20</span></span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/tags/LLM/">LLM</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/tags/Optimization/">Optimization</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/tags/ML-Basics/">ML-Basics</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/%E5%AD%A6%E4%B9%A0%E7%8E%87%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E7%9A%84%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97%EF%BC%882026%EF%BC%89/">阅读全文&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/Mixture-of-Subspaces-in-Low-Rank-Adaptation-MoSLoRA/">
                        Mixture-of-Subspaces in Low-Rank Adaptation (MoSLoRA)
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>LoRA
把“全量微调”压缩成一个低秩更新，但它也引入了一个直觉上的限制：单个低秩子空间未必足以覆盖任务所需的多样变化；而
MoE
虽然能增加容量，却常带来路由开销、训练不充分与推理不可合并等工程代价。MoSLoRA
的思路更像是把“多专家”做成“多子空间”：把 LoRA
的更新拆成多个小子空间，再用一个可学习的 Mixer
在这些子空间之间做融合，从而在几乎不增加推理复杂度的前提下提升表达能力，并尽量保留
LoRA
的可合并性。下面我会按“动机—结构—训练/推理行为—实验结论”的顺序拆解这篇工作，重点看它的
Mixer 设计到底带来了哪些收益，以及它与 LoRA/MoE 的边界在哪里。</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Mon Aug 19 2024 00:00:00 GMT+0800">2024-08-19</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/categories/Paper/">Paper</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/tags/PEFT/">PEFT</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/Mixture-of-Subspaces-in-Low-Rank-Adaptation-MoSLoRA/">阅读全文&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/%E7%9F%A9%E9%98%B5%E4%BD%8E%E7%A7%A9%E8%BF%91%E4%BC%BC-%E2%80%94%E2%80%94-%E4%BC%AA%E9%80%86/">
                        矩阵低秩近似 —— 伪逆
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>在真实数据里，矩阵往往既不方、也不满秩：特征相关、样本不足、噪声导致的病态都会让“求逆”这件事变得不稳定甚至不存在。伪逆（Moore–Penrose
inverse）可以把“逆”的直觉保留下来：它不追求完美解，而是把线性方程组的解定义成一个最合理的最小二乘解（并在多解时选最小范数那一个），因此在回归、控制、信号处理里非常常见。本文会从最小二乘视角给出伪逆的定义与四个
Penrose 条件，再用 SVD
把它的计算与低秩近似联系起来，解释为什么截断奇异值能让解更稳、什么时候需要正则化，以及这些结论在机器学习里怎么落地使用。</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Sun Aug 18 2024 00:00:00 GMT+0800">2024-08-18</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/categories/Algorithm/">Algorithm</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/tags/Matrix/">Matrix</a>&nbsp;
                        </li>
                    
                        <li>
                            | 
                            <a href="/tags/ML-Basics/">ML Basics</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/%E7%9F%A9%E9%98%B5%E4%BD%8E%E7%A7%A9%E8%BF%91%E4%BC%BC-%E2%80%94%E2%80%94-%E4%BC%AA%E9%80%86/">阅读全文&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90%E9%9D%9E%E7%BA%BF%E6%80%A7%E4%BC%98%E5%8C%96%E4%B8%AD%E7%9A%84Lipschitz%E8%BF%9E%E7%BB%AD%E6%80%A7%E3%80%81%E5%BC%BA%E5%87%B8%E6%80%A7%E4%B8%8E%E5%8A%A0%E9%80%9F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/">
                        深入解析非线性优化中的Lipschitz连续性、强凸性与加速梯度下降算法
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>很多优化“玄学”其实都能被三个概念讲清楚：梯度有多“陡”（Lipschitz/光滑性决定步长上限）、谷底有多“硬”（强凸性决定收敛能有多快、解是否唯一）、以及我们能不能在不牺牲稳定性的前提下更快到达谷底（Nesterov
加速与重启策略）。这篇文章把它们放在同一条逻辑链上：先用最小必要的定义与不等式把直觉钉牢，再给出关键定理与证明，最后落到可复现实验（最小二乘）里对比普通梯度下降与加速法的收敛行为。目标不是堆公式，而是让你在看到一个新问题时，能用这三件事快速判断“该用多大步长、预期什么收敛速度、加速是否值得”。</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Sat Aug 17 2024 00:00:00 GMT+0800">2024-08-17</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/categories/Algorithm/">Algorithm</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/tags/Optimization/">Optimization</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90%E9%9D%9E%E7%BA%BF%E6%80%A7%E4%BC%98%E5%8C%96%E4%B8%AD%E7%9A%84Lipschitz%E8%BF%9E%E7%BB%AD%E6%80%A7%E3%80%81%E5%BC%BA%E5%87%B8%E6%80%A7%E4%B8%8E%E5%8A%A0%E9%80%9F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/">阅读全文&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
    </ul>

    <div class="home-paginator">
        <div class="paginator">
    
        <a class="prev btn"
           href="/page/10/"
        >上一页</a>
    

    
        <a class="next btn"
           href="/page/12/"
        >下一页</a>
    
</div>

    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2020</span>
              -
            
            2026&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Chen Kai</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        访问人数&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
            </div>
        
        <div class="theme-info info-item">
            <!-- 由 <a target="_blank" href="https://hexo.io">Hexo</a> 驱动&nbsp;|&nbsp;主题&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.5</a> -->
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        
            <li class="tools-item rss flex-center">
                <a class="flex-center"
                   href="/atom.xml"
                   target="_blank"
                >
                    <i class="fas fa-rss"></i>
                </a>
            </li>
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="搜索..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>





<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>

<script src="/js/lang-switch.js"></script>



    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-copy.js"></script>





<div class="post-scripts pjax">
    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
