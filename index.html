<!DOCTYPE html>



<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Chen Kai">
    
    <title>
        
        Chen Kai Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/logo.svg">
    
<link rel="stylesheet" href="/css/font-awesome.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"chenk.top","root":"/","language":"zh-CN","default_language":"zh-CN","languages":["zh-CN","en"],"path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":true},"style":{"primary_color":"#0066CC","avatar":"/images/avatar.svg","favicon":"/images/logo.svg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":false,"scale":false},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"Keep writing and Keep loving."},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":true,"style":"default"},"pjax":{"enable":true},"lazyload":{"enable":false},"version":"3.4.5"};
    KEEP.language_ago = {"second":"%s 秒前","minute":"%s 分钟前","hour":"%s 小时前","day":"%s 天前","week":"%s 周前","month":"%s 个月前","year":"%s 年前"};
  </script>
<meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="Chen Kai Blog" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    
        <div class="first-screen-container flex-center fade-in-down-animation">
    <div class="content flex-center">
        <div class="description">
            Keep writing and Keep loving.
        </div>
        
            <div class="s-icon-list">
                
                    
                        
                            <span class="s-icon-item github">
                                <a target="_blank" href="https://github.com/chenkai66">
                                    <i class="fab fa-github"></i>
                                </a>
                            </span>
                        
                    
                
                    
                        
                            <span class="s-icon-item weixin">
                                <a target="_blank" href="https://pic.imgdb.cn/item/66eb3235f21886ccc03a38b5.jpg">
                                    <i class="fab fa-weixin"></i>
                                </a>
                            </span>
                        
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                        
                            <span class="s-icon-item email">
                                <a href="mailto:chenkai.nb.666@gmail.com">
                                    <i class="fas fa-envelope"></i>
                                </a>
                            </span>
                        
                    
                
            </div>
        
    </div>
</div>

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    
    
    
    
    

    <div class="header-content has-first-screen">
        <div class="left">
            
            <a class="logo-title" href="/">
                Chen Kai Blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            
                            
                            <a class="active"
                               href="/"
                            >
                                首页
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/archives"
                            >
                                归档
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/categories"
                            >
                                分类
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            
                            
                            <a class=""
                               href="/tags"
                            >
                                标签
                            </a>
                        </li>
                    
                    <li class="menu-item lang-switch lang-switch-trigger" title="Language">
                        <i class="fas fa-globe"></i>
                    </li>
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item lang-switch-trigger"><i class="fas fa-globe"></i></div>
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class="active"
                       href="/">首页</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/archives">归档</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/categories">分类</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    
                    
                    <a class=""
                       href="/tags">标签</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="home-content-container fade-in-down-animation">
    
    
    

    <ul class="home-article-list">
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%EF%BC%88%E5%85%AB%EF%BC%89%E2%80%94%E2%80%94-Informer%E9%95%BF%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B/">
                        时间序列模型（八）—— Informer长序列预测
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>Transformer 在时间序列预测中展现出强大的能力，但当序列长度达到数千甚至数万时，标准 Transformer 的 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="6.015ex" height="2.452ex" role="img" focusable="false" viewbox="0 -833.9 2658.6 1083.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"/></g><g data-mml-node="mo" transform="translate(763,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="msup" transform="translate(1152,0)"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"/></g><g data-mml-node="mn" transform="translate(714,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"/></g></g><g data-mml-node="mo" transform="translate(2269.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g></g></g></svg></mjx-container> 复杂度成为瓶颈：注意力矩阵的内存占用随序列长度平方增长，训练时间急剧增加，甚至无法在单卡 GPU 上运行。Informer 通过三个核心创新解决了这个问题：ProbSparse Self-Attention 将复杂度降低到 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="10.213ex" height="2.262ex" role="img" focusable="false" viewbox="0 -750 4514.3 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"/></g><g data-mml-node="mo" transform="translate(763,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mi" transform="translate(1152,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"/></g><g data-mml-node="mi" transform="translate(1999.7,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"/><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)"/><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)"/></g><g data-mml-node="mo" transform="translate(3277.7,0)"><path data-c="2061" d=""/></g><g data-mml-node="mi" transform="translate(3444.3,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"/></g><g data-mml-node="mo" transform="translate(4125.3,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g></g></g></svg></mjx-container>，Self-Attention Distilling 通过降维操作进一步压缩序列长度，Generative Style Decoder 用一次前向传播完成所有未来时间步的预测。这些创新使得 Informer 能够处理长度超过 1000 的时间序列，在 ETT、Weather、Electricity 等数据集上显著超越 Vanilla Transformer 和 LSTM。本文将深入解析 ProbSparse 的查询稀疏性度量原理、蒸馏机制的设计动机、生成式解码器的实现细节，并提供完整的 PyTorch 实现和两个实战案例。</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Sun Jan 26 2025 00:00:00 GMT+0800">2025-01-26</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/categories/Algorithm/">Algorithm</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/tags/Time-Series/">Time Series</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%EF%BC%88%E5%85%AB%EF%BC%89%E2%80%94%E2%80%94-Informer%E9%95%BF%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B/">阅读全文&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%B8%83%EF%BC%89%E2%80%94%E2%80%94-N-BEATS%E6%B7%B1%E5%BA%A6%E6%9E%B6%E6%9E%84/">
                        时间序列模型（七）—— N-BEATS深度架构
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>在时间序列预测领域，大多数深度学习模型都像"黑盒"一样工作——我们能看到预测结果，却很难理解模型到底学到了什么。N-BEATS（Neural Basis Expansion Analysis for Time Series）的出现改变了这一现状。这个在M4时间序列竞赛中夺冠的模型，不仅预测精度高，更重要的是它通过可解释的架构设计，让我们能够清晰地看到模型是如何分解时间序列的趋势和季节性成分的。</p>
<p>N-BEATS的核心创新在于"基函数展开"（Basis Expansion）的思想。就像傅里叶变换将信号分解为正弦波和余弦波的组合一样，N-BEATS通过神经网络学习基函数，将时间序列分解为趋势和季节性成分。更巧妙的是，它通过"双残差堆叠"（Double Residual Stacking）的设计，让每个块都能专注于提取特定尺度的模式，最终实现多层次的模式识别。</p>
<p>本文将深入解析N-BEATS的架构设计，从可解释性架构到通用架构，从趋势块到季节性块，并附上完整的PyTorch实现和两个实战案例。无论你是时间序列预测的初学者，还是希望理解M4竞赛冠军方案的技术细节，这篇文章都能为你提供清晰的路径。</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Thu Jan 23 2025 00:00:00 GMT+0800">2025-01-23</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/categories/Algorithm/">Algorithm</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/tags/Time-Series/">Time Series</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%B8%83%EF%BC%89%E2%80%94%E2%80%94-N-BEATS%E6%B7%B1%E5%BA%A6%E6%9E%B6%E6%9E%84/">阅读全文&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%EF%BC%88%E5%85%AD%EF%BC%89%E2%80%94%E2%80%94-%E6%97%B6%E5%BA%8F%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9CTCN/">
                        时间序列模型（六）—— 时序卷积网络TCN
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>在时间序列建模中，LSTM 和 GRU 虽然能捕捉长期依赖，但训练速度慢、难以并行化，而且梯度在长序列中仍然可能消失。时序卷积网络（Temporal Convolutional Network, TCN）提供了一个不同的视角：用一维卷积配合因果卷积和膨胀卷积，既能保持序列的时间顺序，又能并行训练，还能通过残差连接稳定梯度。TCN 在多个时间序列任务上达到了与 LSTM 相当甚至更好的性能，同时训练速度更快。本文会从一维卷积的基础开始，解释因果卷积如何保证时间顺序、膨胀卷积如何扩大感受野、残差连接如何稳定训练，然后给出完整的 PyTorch 实现、两个实战案例（交通流量和传感器数据），以及 TCN 与 LSTM 的详细对比。</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Mon Jan 20 2025 00:00:00 GMT+0800">2025-01-20</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/categories/Algorithm/">Algorithm</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/tags/Time-Series/">Time Series</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%EF%BC%88%E5%85%AD%EF%BC%89%E2%80%94%E2%80%94-%E6%97%B6%E5%BA%8F%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9CTCN/">阅读全文&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%BA%94%EF%BC%89%E2%80%94%E2%80%94-Transformer%E6%9E%B6%E6%9E%84/">
                        时间序列模型（五）—— Transformer架构
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>Transformer 在 NLP 领域大放异彩后，时间序列研究者很快意识到：序列建模的本质问题——如何捕捉长期依赖、如何并行计算、如何理解全局模式——Transformer 的注意力机制都能给出更好的答案。相比 LSTM/GRU 需要一步步传递信息，Transformer 的自注意力可以直接“看到”序列中任意两点的关系；相比传统 RNN 的串行计算，Transformer 的矩阵运算天然支持并行，训练速度更快；相比固定窗口的卷积，注意力权重提供了可解释性，能告诉我们模型到底在关注哪些时间点。本文会从 Transformer 的核心组件（Self-Attention、Multi-Head、位置编码）开始，逐步深入到时间序列的特殊设计（时间位置编码、因果掩码、解码器结构），然后实现一个完整的 Vanilla Transformer，并介绍 Autoformer、FEDformer 等变体，最后通过股票预测和能耗预测的实战案例展示如何调优与部署。</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Fri Jan 17 2025 00:00:00 GMT+0800">2025-01-17</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/categories/Algorithm/">Algorithm</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/tags/Time-Series/">Time Series</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%BA%94%EF%BC%89%E2%80%94%E2%80%94-Transformer%E6%9E%B6%E6%9E%84/">阅读全文&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
            <li class="home-article-item">

                

                <h3 class="home-article-title">
                    <a href="/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%EF%BC%88%E5%9B%9B%EF%BC%89%E2%80%94%E2%80%94-Attention%E6%9C%BA%E5%88%B6/">
                        时间序列模型（四）—— Attention机制
                    </a>
                </h3>

                <div class="home-article-content markdown-body">
                    
                        <p>在时间序列里，很多关键信息并不在“最近一步”：可能是周期中的某个相位、某个突发后的回落，或是跨很长间隔的相似模式。Attention 的好处是它不需要按时间一步步把信息“传”过来，而是直接学会“该看历史里的哪几段、看多少权重”，从而更擅长处理长距离依赖与不规则相关性。本文会把自注意力的计算流程按公式拆开（<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="7.803ex" height="2.262ex" role="img" focusable="false" viewbox="0 -750 3449 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"/></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(791,0)"><g data-mml-node="mo"><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"/></g></g><g data-mml-node="mi" transform="translate(1291,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"/></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(2180,0)"><g data-mml-node="mo"><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"/></g></g><g data-mml-node="mi" transform="translate(2680,0)"><path data-c="1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"/></g></g></g></svg></mjx-container>、缩放点积、softmax 权重、加权求和），并结合代码层面的实现细节说明：这些矩阵运算到底在做什么、复杂度与序列长度的关系是什么，以及在时间序列任务里如何组织输入、如何解释注意力权重带来的可解释性。</p>
                    
                </div>

                <div class="home-article-meta-info-container">
    
    
    
    

    <div class="home-article-meta-info">
        <span><i class="fas fa-history"></i>&nbsp;<span class="home-article-date" data-date="Tue Jan 14 2025 00:00:00 GMT+0800">2025-01-14</span></span>
        
            <span class="home-article-category"><i class="fas fa-folder"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/categories/Algorithm/">Algorithm</a>&nbsp;
                        </li>
                    
                    
                </ul>
            </span>
        
        
            <span class="home-article-tag">
                <i class="fas fa-tags"></i>&nbsp;
                <ul>
                    
                        <li>
                            
                            <a href="/tags/Time-Series/">Time Series</a>&nbsp;
                        </li>
                    
                </ul>
            </span>
        
    </div>

    <a href="/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%EF%BC%88%E5%9B%9B%EF%BC%89%E2%80%94%E2%80%94-Attention%E6%9C%BA%E5%88%B6/">阅读全文&nbsp;<i class="fas fa-angle-right"></i></a>
</div>

            </li>
        
    </ul>

    <div class="home-paginator">
        <div class="paginator">
    

    
        <a class="next btn"
           href="/page/2/"
        >下一页</a>
    
</div>

    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2020</span>
              -
            
            2026&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Chen Kai</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        访问人数&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
            </div>
        
        <div class="theme-info info-item">
            <!-- 由 <a target="_blank" href="https://hexo.io">Hexo</a> 驱动&nbsp;|&nbsp;主题&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.5</a> -->
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        
            <li class="tools-item rss flex-center">
                <a class="flex-center"
                   href="/atom.xml"
                   target="_blank"
                >
                    <i class="fas fa-rss"></i>
                </a>
            </li>
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="搜索..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>





<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>

<script src="/js/lang-switch.js"></script>



    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-copy.js"></script>





<div class="post-scripts pjax">
    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
